{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> [CMSC 636] Drake Wong </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "# Note: If GPU memory in inadequate, uncomment os.environ statements to use system memory and CPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import keras \n",
    "import tensorflow \n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras.callbacks import History \n",
    "\n",
    "# Instructions:\n",
    "# Seperate histograms of each gene into folders, which are named after their category\n",
    "DATADIR=r\"C:\\Users\\drake\\Google Drive\\ILS Spring 2020 Semester\\CMSC 636 Deep Learning\\Project - Code\\02 Create Histograms\\20_04_18 10 categories large\"\n",
    "categories =[\"BMDC\",\"Brain\",\"CD4\",\"CD4memory\",\"CD8\",\"Haematopoietic\",\"intestinal\",\"Lung\",\"Mammery\",\"Olfactory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU has been found\n"
     ]
    }
   ],
   "source": [
    "# Check devince\n",
    "if tensorflow.test.gpu_device_name():\n",
    "    print('GPU has been found')\n",
    "else:\n",
    "    print(\"No GPU has been found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, 22990 samples have been loaded among the 10 categories\n"
     ]
    }
   ],
   "source": [
    "img_size= 125\n",
    "training_data=[]\n",
    "\n",
    "def create_training_data(): \n",
    "    for category in categories:\n",
    "        path= os.path.join(DATADIR, category) # path to different categories \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array= cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array= cv2.resize(img_array, (img_size, img_size))\n",
    "                training_data.append([new_array, category])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()\n",
    "random.shuffle(training_data)\n",
    "print(f\"In total, {len(training_data)} samples have been loaded among the {len(categories)} categories\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of training data and labels \n",
    "train_data=[]\n",
    "train_label=[]\n",
    "for features, label in training_data:\n",
    "    train_data.append(features)\n",
    "    train_label.append(label)\n",
    "train_data=np.array(train_data).reshape(-1,img_size, img_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categories to numeric representation\n",
    "convert_to_numeric = LabelEncoder()\n",
    "y_train_num = convert_to_numeric.fit_transform(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20691 samples, validate on 2299 samples\n",
      "Epoch 1/120\n",
      " - 22s - loss: 0.3753 - accuracy: 0.0996 - val_loss: 0.2039 - val_accuracy: 0.1000\n",
      "Epoch 2/120\n",
      " - 23s - loss: 0.1943 - accuracy: 0.1023 - val_loss: 0.1912 - val_accuracy: 0.1000\n",
      "Epoch 3/120\n",
      " - 22s - loss: 0.1904 - accuracy: 0.0994 - val_loss: 0.1900 - val_accuracy: 0.1000\n",
      "Epoch 4/120\n",
      " - 23s - loss: 0.1909 - accuracy: 0.1017 - val_loss: 0.1911 - val_accuracy: 0.1000\n",
      "Epoch 5/120\n",
      " - 23s - loss: 0.1396 - accuracy: 0.1663 - val_loss: 0.0905 - val_accuracy: 0.2388\n",
      "Epoch 6/120\n",
      " - 22s - loss: 0.0890 - accuracy: 0.2584 - val_loss: 0.0825 - val_accuracy: 0.3162\n",
      "Epoch 7/120\n",
      " - 24s - loss: 0.0847 - accuracy: 0.3056 - val_loss: 0.0796 - val_accuracy: 0.3662\n",
      "Epoch 8/120\n",
      " - 22s - loss: 0.0824 - accuracy: 0.3336 - val_loss: 0.0773 - val_accuracy: 0.4002\n",
      "Epoch 9/120\n",
      " - 23s - loss: 0.0807 - accuracy: 0.3618 - val_loss: 0.0774 - val_accuracy: 0.3989\n",
      "Epoch 10/120\n",
      " - 23s - loss: 0.0804 - accuracy: 0.3681 - val_loss: 0.0758 - val_accuracy: 0.4067\n",
      "Epoch 11/120\n",
      " - 22s - loss: 0.0792 - accuracy: 0.3763 - val_loss: 0.0774 - val_accuracy: 0.4202\n",
      "Epoch 12/120\n",
      " - 22s - loss: 0.0781 - accuracy: 0.3873 - val_loss: 0.0753 - val_accuracy: 0.4311\n",
      "Epoch 13/120\n",
      " - 22s - loss: 0.0779 - accuracy: 0.3968 - val_loss: 0.0758 - val_accuracy: 0.4245\n",
      "Epoch 14/120\n",
      " - 23s - loss: 0.0772 - accuracy: 0.3986 - val_loss: 0.0762 - val_accuracy: 0.4045\n",
      "Epoch 15/120\n",
      " - 22s - loss: 0.0772 - accuracy: 0.4023 - val_loss: 0.0749 - val_accuracy: 0.4237\n",
      "Epoch 16/120\n",
      " - 21s - loss: 0.0765 - accuracy: 0.4103 - val_loss: 0.0753 - val_accuracy: 0.4202\n",
      "Epoch 17/120\n",
      " - 23s - loss: 0.0767 - accuracy: 0.4077 - val_loss: 0.0750 - val_accuracy: 0.4197\n",
      "Epoch 18/120\n",
      " - 22s - loss: 0.0763 - accuracy: 0.4144 - val_loss: 0.0731 - val_accuracy: 0.4445\n",
      "Epoch 19/120\n",
      " - 23s - loss: 0.0765 - accuracy: 0.4099 - val_loss: 0.0770 - val_accuracy: 0.4028\n",
      "Epoch 20/120\n",
      " - 24s - loss: 0.0755 - accuracy: 0.4205 - val_loss: 0.0765 - val_accuracy: 0.4089\n",
      "Epoch 21/120\n",
      " - 23s - loss: 0.0755 - accuracy: 0.4246 - val_loss: 0.0761 - val_accuracy: 0.4089\n",
      "Epoch 22/120\n",
      " - 22s - loss: 0.0759 - accuracy: 0.4186 - val_loss: 0.0854 - val_accuracy: 0.3140\n",
      "Epoch 23/120\n",
      " - 22s - loss: 0.0755 - accuracy: 0.4232 - val_loss: 0.0763 - val_accuracy: 0.4110\n",
      "Epoch 24/120\n",
      " - 23s - loss: 0.0752 - accuracy: 0.4253 - val_loss: 0.0735 - val_accuracy: 0.4385\n",
      "Epoch 25/120\n",
      " - 23s - loss: 0.0750 - accuracy: 0.4280 - val_loss: 0.0748 - val_accuracy: 0.4341\n",
      "Epoch 26/120\n",
      " - 23s - loss: 0.0756 - accuracy: 0.4214 - val_loss: 0.0790 - val_accuracy: 0.4080\n",
      "Epoch 27/120\n",
      " - 22s - loss: 0.0748 - accuracy: 0.4341 - val_loss: 0.0748 - val_accuracy: 0.4358\n",
      "Epoch 28/120\n",
      " - 23s - loss: 0.0746 - accuracy: 0.4335 - val_loss: 0.0767 - val_accuracy: 0.4119\n",
      "Epoch 29/120\n",
      " - 22s - loss: 0.0744 - accuracy: 0.4381 - val_loss: 0.0717 - val_accuracy: 0.4593\n",
      "Epoch 30/120\n",
      " - 22s - loss: 0.0748 - accuracy: 0.4317 - val_loss: 0.0728 - val_accuracy: 0.4572\n",
      "Epoch 31/120\n",
      " - 22s - loss: 0.0742 - accuracy: 0.4405 - val_loss: 0.0729 - val_accuracy: 0.4585\n",
      "Epoch 32/120\n",
      " - 23s - loss: 0.0746 - accuracy: 0.4350 - val_loss: 0.0728 - val_accuracy: 0.4485\n",
      "Epoch 33/120\n",
      " - 23s - loss: 0.0741 - accuracy: 0.4429 - val_loss: 0.0727 - val_accuracy: 0.4515\n",
      "Epoch 34/120\n",
      " - 22s - loss: 0.0749 - accuracy: 0.4345 - val_loss: 0.0726 - val_accuracy: 0.4498\n",
      "Epoch 35/120\n",
      " - 22s - loss: 0.0738 - accuracy: 0.4439 - val_loss: 0.0728 - val_accuracy: 0.4506\n",
      "Epoch 36/120\n",
      " - 22s - loss: 0.0738 - accuracy: 0.4417 - val_loss: 0.0739 - val_accuracy: 0.4380\n",
      "Epoch 37/120\n",
      " - 22s - loss: 0.0737 - accuracy: 0.4423 - val_loss: 0.0742 - val_accuracy: 0.4315\n",
      "Epoch 38/120\n",
      " - 23s - loss: 0.0735 - accuracy: 0.4482 - val_loss: 0.0723 - val_accuracy: 0.4567\n",
      "Epoch 39/120\n",
      " - 24s - loss: 0.0733 - accuracy: 0.4528 - val_loss: 0.0719 - val_accuracy: 0.4545\n",
      "Epoch 40/120\n",
      " - 24s - loss: 0.0737 - accuracy: 0.4472 - val_loss: 0.0759 - val_accuracy: 0.4206\n",
      "Epoch 41/120\n",
      " - 23s - loss: 0.0734 - accuracy: 0.4487 - val_loss: 0.0748 - val_accuracy: 0.4337\n",
      "Epoch 42/120\n",
      " - 24s - loss: 0.0732 - accuracy: 0.4467 - val_loss: 0.0722 - val_accuracy: 0.4519\n",
      "Epoch 43/120\n",
      " - 23s - loss: 0.0735 - accuracy: 0.4475 - val_loss: 0.0716 - val_accuracy: 0.4615\n",
      "Epoch 44/120\n",
      " - 24s - loss: 0.0732 - accuracy: 0.4523 - val_loss: 0.0732 - val_accuracy: 0.4358\n",
      "Epoch 45/120\n",
      " - 24s - loss: 0.0731 - accuracy: 0.4566 - val_loss: 0.0757 - val_accuracy: 0.4306\n",
      "Epoch 46/120\n",
      " - 23s - loss: 0.0733 - accuracy: 0.4526 - val_loss: 0.0736 - val_accuracy: 0.4463\n",
      "Epoch 47/120\n",
      " - 24s - loss: 0.0729 - accuracy: 0.4564 - val_loss: 0.0747 - val_accuracy: 0.4302\n",
      "Epoch 48/120\n",
      " - 24s - loss: 0.0735 - accuracy: 0.4488 - val_loss: 0.0718 - val_accuracy: 0.4554\n",
      "Epoch 49/120\n",
      " - 23s - loss: 0.0727 - accuracy: 0.4564 - val_loss: 0.0726 - val_accuracy: 0.4480\n",
      "Epoch 50/120\n",
      " - 23s - loss: 0.0738 - accuracy: 0.4482 - val_loss: 0.0724 - val_accuracy: 0.4511\n",
      "Epoch 51/120\n",
      " - 23s - loss: 0.0726 - accuracy: 0.4594 - val_loss: 0.0733 - val_accuracy: 0.4376\n",
      "Epoch 52/120\n",
      " - 23s - loss: 0.0726 - accuracy: 0.4589 - val_loss: 0.0733 - val_accuracy: 0.4541\n",
      "Epoch 53/120\n",
      " - 23s - loss: 0.0725 - accuracy: 0.4579 - val_loss: 0.0751 - val_accuracy: 0.4445\n",
      "Epoch 54/120\n",
      " - 24s - loss: 0.0726 - accuracy: 0.4584 - val_loss: 0.0764 - val_accuracy: 0.4241\n",
      "Epoch 55/120\n",
      " - 23s - loss: 0.0752 - accuracy: 0.4494 - val_loss: 0.0718 - val_accuracy: 0.4585\n",
      "Epoch 56/120\n",
      " - 23s - loss: 0.0723 - accuracy: 0.4671 - val_loss: 0.0732 - val_accuracy: 0.4467\n",
      "Epoch 57/120\n",
      " - 22s - loss: 0.0726 - accuracy: 0.4605 - val_loss: 0.0734 - val_accuracy: 0.4402\n",
      "Epoch 58/120\n",
      " - 23s - loss: 0.0723 - accuracy: 0.4654 - val_loss: 0.0735 - val_accuracy: 0.4284\n",
      "Epoch 59/120\n",
      " - 23s - loss: 0.0723 - accuracy: 0.4635 - val_loss: 0.0727 - val_accuracy: 0.4567\n",
      "Epoch 60/120\n",
      " - 23s - loss: 0.0733 - accuracy: 0.4598 - val_loss: 0.0737 - val_accuracy: 0.4445\n",
      "Epoch 61/120\n",
      " - 23s - loss: 0.0725 - accuracy: 0.4643 - val_loss: 0.0712 - val_accuracy: 0.4602\n",
      "Epoch 62/120\n",
      " - 22s - loss: 0.0720 - accuracy: 0.4678 - val_loss: 0.0789 - val_accuracy: 0.3954\n",
      "Epoch 63/120\n",
      " - 23s - loss: 0.0731 - accuracy: 0.4569 - val_loss: 0.0735 - val_accuracy: 0.4354\n",
      "Epoch 64/120\n",
      " - 22s - loss: 0.0721 - accuracy: 0.4682 - val_loss: 0.0820 - val_accuracy: 0.3676\n",
      "Epoch 65/120\n",
      " - 23s - loss: 0.0721 - accuracy: 0.4658 - val_loss: 0.0717 - val_accuracy: 0.4589\n",
      "Epoch 66/120\n",
      " - 23s - loss: 0.0721 - accuracy: 0.4664 - val_loss: 0.0722 - val_accuracy: 0.4567\n",
      "Epoch 67/120\n",
      " - 23s - loss: 0.0720 - accuracy: 0.4710 - val_loss: 0.0755 - val_accuracy: 0.4341\n",
      "Epoch 68/120\n",
      " - 22s - loss: 0.0719 - accuracy: 0.4676 - val_loss: 0.0720 - val_accuracy: 0.4559\n",
      "Epoch 69/120\n",
      " - 23s - loss: 0.0716 - accuracy: 0.4732 - val_loss: 0.0727 - val_accuracy: 0.4489\n",
      "Epoch 70/120\n",
      " - 23s - loss: 0.0720 - accuracy: 0.4691 - val_loss: 0.0729 - val_accuracy: 0.4393\n",
      "Epoch 71/120\n",
      " - 23s - loss: 0.0724 - accuracy: 0.4695 - val_loss: 0.0742 - val_accuracy: 0.4532\n",
      "Epoch 72/120\n",
      " - 23s - loss: 0.0716 - accuracy: 0.4741 - val_loss: 0.0731 - val_accuracy: 0.4498\n",
      "Epoch 73/120\n",
      " - 23s - loss: 0.0716 - accuracy: 0.4750 - val_loss: 0.0739 - val_accuracy: 0.4489\n",
      "Epoch 74/120\n",
      " - 23s - loss: 0.0716 - accuracy: 0.4741 - val_loss: 0.0775 - val_accuracy: 0.4102\n",
      "Epoch 75/120\n",
      " - 24s - loss: 0.0715 - accuracy: 0.4774 - val_loss: 0.0756 - val_accuracy: 0.4345\n",
      "Epoch 76/120\n",
      " - 23s - loss: 0.0719 - accuracy: 0.4723 - val_loss: 0.0732 - val_accuracy: 0.4537\n",
      "Epoch 77/120\n",
      " - 23s - loss: 0.0715 - accuracy: 0.4771 - val_loss: 0.0741 - val_accuracy: 0.4367\n",
      "Epoch 78/120\n",
      " - 24s - loss: 0.0715 - accuracy: 0.4725 - val_loss: 0.0719 - val_accuracy: 0.4619\n",
      "Epoch 79/120\n",
      " - 23s - loss: 0.0715 - accuracy: 0.4789 - val_loss: 0.0717 - val_accuracy: 0.4654\n",
      "Epoch 80/120\n",
      " - 23s - loss: 0.0714 - accuracy: 0.4791 - val_loss: 0.0726 - val_accuracy: 0.4559\n",
      "Epoch 81/120\n",
      " - 23s - loss: 0.0714 - accuracy: 0.4754 - val_loss: 0.0729 - val_accuracy: 0.4493\n",
      "Epoch 82/120\n",
      " - 23s - loss: 0.0713 - accuracy: 0.4735 - val_loss: 0.0718 - val_accuracy: 0.4711\n",
      "Epoch 83/120\n",
      " - 23s - loss: 0.0710 - accuracy: 0.4774 - val_loss: 0.0738 - val_accuracy: 0.4306\n",
      "Epoch 84/120\n",
      " - 22s - loss: 0.0731 - accuracy: 0.4705 - val_loss: 0.0727 - val_accuracy: 0.4493\n",
      "Epoch 85/120\n",
      " - 23s - loss: 0.0711 - accuracy: 0.4788 - val_loss: 0.0718 - val_accuracy: 0.4576\n",
      "Epoch 86/120\n",
      " - 22s - loss: 0.0709 - accuracy: 0.4822 - val_loss: 0.0757 - val_accuracy: 0.4332\n",
      "Epoch 87/120\n",
      " - 23s - loss: 0.0714 - accuracy: 0.4761 - val_loss: 0.0725 - val_accuracy: 0.4593\n",
      "Epoch 88/120\n",
      " - 23s - loss: 0.0710 - accuracy: 0.4820 - val_loss: 0.0716 - val_accuracy: 0.4632\n",
      "Epoch 89/120\n",
      " - 23s - loss: 0.0715 - accuracy: 0.4784 - val_loss: 0.0720 - val_accuracy: 0.4619\n",
      "Epoch 90/120\n",
      " - 22s - loss: 0.0711 - accuracy: 0.4818 - val_loss: 0.0737 - val_accuracy: 0.4458\n",
      "Epoch 91/120\n",
      " - 23s - loss: 0.0708 - accuracy: 0.4833 - val_loss: 0.0766 - val_accuracy: 0.4324\n",
      "Epoch 92/120\n",
      " - 24s - loss: 0.0714 - accuracy: 0.4837 - val_loss: 0.0727 - val_accuracy: 0.4585\n",
      "Epoch 93/120\n",
      " - 23s - loss: 0.0707 - accuracy: 0.4842 - val_loss: 0.0743 - val_accuracy: 0.4376\n",
      "Epoch 94/120\n",
      " - 22s - loss: 0.0709 - accuracy: 0.4826 - val_loss: 0.0736 - val_accuracy: 0.4419\n",
      "Epoch 95/120\n",
      " - 23s - loss: 0.0706 - accuracy: 0.4863 - val_loss: 0.0747 - val_accuracy: 0.4358\n",
      "Epoch 96/120\n",
      " - 23s - loss: 0.0712 - accuracy: 0.4836 - val_loss: 0.0729 - val_accuracy: 0.4502\n",
      "Epoch 97/120\n",
      " - 23s - loss: 0.0715 - accuracy: 0.4762 - val_loss: 0.0736 - val_accuracy: 0.4480\n",
      "Epoch 98/120\n",
      " - 21s - loss: 0.0706 - accuracy: 0.4880 - val_loss: 0.0730 - val_accuracy: 0.4606\n",
      "Epoch 99/120\n",
      " - 23s - loss: 0.0704 - accuracy: 0.4890 - val_loss: 0.0732 - val_accuracy: 0.4528\n",
      "Epoch 100/120\n",
      " - 23s - loss: 0.0705 - accuracy: 0.4857 - val_loss: 0.0751 - val_accuracy: 0.4406\n",
      "Epoch 101/120\n",
      " - 23s - loss: 0.0708 - accuracy: 0.4811 - val_loss: 0.0764 - val_accuracy: 0.4224\n",
      "Epoch 102/120\n",
      " - 23s - loss: 0.0705 - accuracy: 0.4891 - val_loss: 0.0722 - val_accuracy: 0.4615\n",
      "Epoch 103/120\n",
      " - 22s - loss: 0.0703 - accuracy: 0.4862 - val_loss: 0.0747 - val_accuracy: 0.4511\n",
      "Epoch 104/120\n",
      " - 22s - loss: 0.0712 - accuracy: 0.4877 - val_loss: 0.0725 - val_accuracy: 0.4572\n",
      "Epoch 105/120\n",
      " - 22s - loss: 0.0703 - accuracy: 0.4896 - val_loss: 0.0725 - val_accuracy: 0.4619\n",
      "Epoch 106/120\n",
      " - 22s - loss: 0.0702 - accuracy: 0.4929 - val_loss: 0.0743 - val_accuracy: 0.4485\n",
      "Epoch 107/120\n",
      " - 22s - loss: 0.0703 - accuracy: 0.4931 - val_loss: 0.0724 - val_accuracy: 0.4659\n",
      "Epoch 108/120\n",
      " - 22s - loss: 0.0704 - accuracy: 0.4933 - val_loss: 0.0738 - val_accuracy: 0.4576\n",
      "Epoch 109/120\n",
      " - 23s - loss: 0.0704 - accuracy: 0.4924 - val_loss: 0.0728 - val_accuracy: 0.4532\n",
      "Epoch 110/120\n",
      " - 21s - loss: 0.0699 - accuracy: 0.4962 - val_loss: 0.0745 - val_accuracy: 0.4458\n",
      "Epoch 111/120\n",
      " - 22s - loss: 0.0705 - accuracy: 0.4902 - val_loss: 0.0736 - val_accuracy: 0.4585\n",
      "Epoch 112/120\n",
      " - 23s - loss: 0.0709 - accuracy: 0.4892 - val_loss: 0.0730 - val_accuracy: 0.4515\n",
      "Epoch 113/120\n",
      " - 22s - loss: 0.0696 - accuracy: 0.4947 - val_loss: 0.0740 - val_accuracy: 0.4398\n",
      "Epoch 114/120\n",
      " - 22s - loss: 0.0702 - accuracy: 0.4945 - val_loss: 0.0733 - val_accuracy: 0.4506\n",
      "Epoch 115/120\n",
      " - 22s - loss: 0.0699 - accuracy: 0.4956 - val_loss: 0.0729 - val_accuracy: 0.4511\n",
      "Epoch 116/120\n",
      " - 22s - loss: 0.0697 - accuracy: 0.5001 - val_loss: 0.0739 - val_accuracy: 0.4563\n",
      "Epoch 117/120\n",
      " - 23s - loss: 0.0699 - accuracy: 0.4980 - val_loss: 0.0743 - val_accuracy: 0.4458\n",
      "Epoch 118/120\n",
      " - 22s - loss: 0.0698 - accuracy: 0.4997 - val_loss: 0.0747 - val_accuracy: 0.4472\n",
      "Epoch 119/120\n",
      " - 22s - loss: 0.0701 - accuracy: 0.4950 - val_loss: 0.0743 - val_accuracy: 0.4411\n",
      "Epoch 120/120\n",
      " - 22s - loss: 0.0698 - accuracy: 0.5025 - val_loss: 0.0732 - val_accuracy: 0.4506\n",
      "Train on 20691 samples, validate on 2299 samples\n",
      "Epoch 1/120\n",
      " - 22s - loss: 0.2971 - accuracy: 0.1722 - val_loss: 0.0901 - val_accuracy: 0.2845\n",
      "Epoch 2/120\n",
      " - 22s - loss: 0.0873 - accuracy: 0.2691 - val_loss: 0.0850 - val_accuracy: 0.2906\n",
      "Epoch 3/120\n",
      " - 21s - loss: 0.0877 - accuracy: 0.2769 - val_loss: 0.0843 - val_accuracy: 0.3093\n",
      "Epoch 4/120\n",
      " - 22s - loss: 0.0879 - accuracy: 0.2898 - val_loss: 0.0849 - val_accuracy: 0.3206\n",
      "Epoch 5/120\n",
      " - 21s - loss: 0.0826 - accuracy: 0.3225 - val_loss: 0.0830 - val_accuracy: 0.3097\n",
      "Epoch 6/120\n",
      " - 21s - loss: 0.0834 - accuracy: 0.3176 - val_loss: 0.0849 - val_accuracy: 0.3232\n",
      "Epoch 7/120\n",
      " - 22s - loss: 0.0807 - accuracy: 0.3490 - val_loss: 0.0777 - val_accuracy: 0.3763\n",
      "Epoch 8/120\n",
      " - 21s - loss: 0.0810 - accuracy: 0.3526 - val_loss: 0.0798 - val_accuracy: 0.3693\n",
      "Epoch 9/120\n",
      " - 22s - loss: 0.0790 - accuracy: 0.3791 - val_loss: 0.0780 - val_accuracy: 0.3806\n",
      "Epoch 10/120\n",
      " - 22s - loss: 0.0790 - accuracy: 0.3744 - val_loss: 0.0815 - val_accuracy: 0.3419\n",
      "Epoch 11/120\n",
      " - 21s - loss: 0.0783 - accuracy: 0.3867 - val_loss: 0.0770 - val_accuracy: 0.3928\n",
      "Epoch 12/120\n",
      " - 22s - loss: 0.0773 - accuracy: 0.3970 - val_loss: 0.0760 - val_accuracy: 0.4006\n",
      "Epoch 13/120\n",
      " - 22s - loss: 0.0774 - accuracy: 0.3935 - val_loss: 0.0765 - val_accuracy: 0.4097\n",
      "Epoch 14/120\n",
      " - 22s - loss: 0.0771 - accuracy: 0.3994 - val_loss: 0.0755 - val_accuracy: 0.4132\n",
      "Epoch 15/120\n",
      " - 23s - loss: 0.0771 - accuracy: 0.3999 - val_loss: 0.0752 - val_accuracy: 0.4002\n",
      "Epoch 16/120\n",
      " - 22s - loss: 0.0782 - accuracy: 0.4014 - val_loss: 0.0752 - val_accuracy: 0.4141\n",
      "Epoch 17/120\n",
      " - 22s - loss: 0.0760 - accuracy: 0.4122 - val_loss: 0.0755 - val_accuracy: 0.4050\n",
      "Epoch 18/120\n",
      " - 22s - loss: 0.0760 - accuracy: 0.4110 - val_loss: 0.0746 - val_accuracy: 0.4306\n",
      "Epoch 19/120\n",
      " - 22s - loss: 0.0758 - accuracy: 0.4132 - val_loss: 0.0745 - val_accuracy: 0.4211\n",
      "Epoch 20/120\n",
      " - 23s - loss: 0.0799 - accuracy: 0.4059 - val_loss: 0.0763 - val_accuracy: 0.4019\n",
      "Epoch 21/120\n",
      " - 22s - loss: 0.0757 - accuracy: 0.4180 - val_loss: 0.0751 - val_accuracy: 0.4163\n",
      "Epoch 22/120\n",
      " - 22s - loss: 0.0751 - accuracy: 0.4202 - val_loss: 0.0732 - val_accuracy: 0.4472\n",
      "Epoch 23/120\n",
      " - 23s - loss: 0.0756 - accuracy: 0.4195 - val_loss: 0.0745 - val_accuracy: 0.4241\n",
      "Epoch 24/120\n",
      " - 23s - loss: 0.0747 - accuracy: 0.4329 - val_loss: 0.0748 - val_accuracy: 0.4337\n",
      "Epoch 25/120\n",
      " - 22s - loss: 0.0782 - accuracy: 0.4198 - val_loss: 0.0731 - val_accuracy: 0.4298\n",
      "Epoch 26/120\n",
      " - 22s - loss: 0.0740 - accuracy: 0.4336 - val_loss: 0.0758 - val_accuracy: 0.4028\n",
      "Epoch 27/120\n",
      " - 22s - loss: 0.0747 - accuracy: 0.4278 - val_loss: 0.0748 - val_accuracy: 0.4202\n",
      "Epoch 28/120\n",
      " - 22s - loss: 0.0743 - accuracy: 0.4348 - val_loss: 0.0760 - val_accuracy: 0.4284\n",
      "Epoch 29/120\n",
      " - 23s - loss: 0.0741 - accuracy: 0.4379 - val_loss: 0.0787 - val_accuracy: 0.3941\n",
      "Epoch 30/120\n",
      " - 23s - loss: 0.0741 - accuracy: 0.4399 - val_loss: 0.0721 - val_accuracy: 0.4532\n",
      "Epoch 31/120\n",
      " - 23s - loss: 0.0743 - accuracy: 0.4371 - val_loss: 0.0733 - val_accuracy: 0.4463\n",
      "Epoch 32/120\n",
      " - 23s - loss: 0.0738 - accuracy: 0.4424 - val_loss: 0.0726 - val_accuracy: 0.4428\n",
      "Epoch 33/120\n",
      " - 22s - loss: 0.0745 - accuracy: 0.4366 - val_loss: 0.0736 - val_accuracy: 0.4406\n",
      "Epoch 34/120\n",
      " - 22s - loss: 0.0737 - accuracy: 0.4411 - val_loss: 0.0734 - val_accuracy: 0.4493\n",
      "Epoch 35/120\n",
      " - 22s - loss: 0.0733 - accuracy: 0.4461 - val_loss: 0.0764 - val_accuracy: 0.3993\n",
      "Epoch 36/120\n",
      " - 22s - loss: 0.0739 - accuracy: 0.4428 - val_loss: 0.0729 - val_accuracy: 0.4493\n",
      "Epoch 37/120\n",
      " - 22s - loss: 0.0736 - accuracy: 0.4429 - val_loss: 0.0761 - val_accuracy: 0.4110\n",
      "Epoch 38/120\n",
      " - 23s - loss: 0.0732 - accuracy: 0.4507 - val_loss: 0.0732 - val_accuracy: 0.4498\n",
      "Epoch 39/120\n",
      " - 23s - loss: 0.0733 - accuracy: 0.4487 - val_loss: 0.0732 - val_accuracy: 0.4367\n",
      "Epoch 40/120\n",
      " - 21s - loss: 0.0733 - accuracy: 0.4470 - val_loss: 0.0719 - val_accuracy: 0.4585\n",
      "Epoch 41/120\n",
      " - 22s - loss: 0.0729 - accuracy: 0.4535 - val_loss: 0.0741 - val_accuracy: 0.4306\n",
      "Epoch 42/120\n",
      " - 23s - loss: 0.0730 - accuracy: 0.4574 - val_loss: 0.0731 - val_accuracy: 0.4519\n",
      "Epoch 43/120\n",
      " - 24s - loss: 0.0726 - accuracy: 0.4556 - val_loss: 0.0755 - val_accuracy: 0.4385\n",
      "Epoch 44/120\n",
      " - 22s - loss: 0.0725 - accuracy: 0.4598 - val_loss: 0.0721 - val_accuracy: 0.4537\n",
      "Epoch 45/120\n",
      " - 22s - loss: 0.0729 - accuracy: 0.4571 - val_loss: 0.0737 - val_accuracy: 0.4432\n",
      "Epoch 46/120\n",
      " - 23s - loss: 0.0725 - accuracy: 0.4576 - val_loss: 0.0725 - val_accuracy: 0.4580\n",
      "Epoch 47/120\n",
      " - 23s - loss: 0.0726 - accuracy: 0.4599 - val_loss: 0.0754 - val_accuracy: 0.4476\n",
      "Epoch 48/120\n",
      " - 23s - loss: 0.0726 - accuracy: 0.4571 - val_loss: 0.0736 - val_accuracy: 0.4302\n",
      "Epoch 49/120\n",
      " - 22s - loss: 0.0725 - accuracy: 0.4617 - val_loss: 0.0724 - val_accuracy: 0.4645\n",
      "Epoch 50/120\n",
      " - 22s - loss: 0.0723 - accuracy: 0.4616 - val_loss: 0.0732 - val_accuracy: 0.4485\n",
      "Epoch 51/120\n",
      " - 22s - loss: 0.0723 - accuracy: 0.4600 - val_loss: 0.0766 - val_accuracy: 0.4319\n",
      "Epoch 52/120\n",
      " - 22s - loss: 0.0722 - accuracy: 0.4632 - val_loss: 0.0729 - val_accuracy: 0.4419\n",
      "Epoch 53/120\n",
      " - 23s - loss: 0.0721 - accuracy: 0.4653 - val_loss: 0.0713 - val_accuracy: 0.4615\n",
      "Epoch 54/120\n",
      " - 23s - loss: 0.0720 - accuracy: 0.4656 - val_loss: 0.0737 - val_accuracy: 0.4363\n",
      "Epoch 55/120\n",
      " - 24s - loss: 0.0721 - accuracy: 0.4644 - val_loss: 0.0732 - val_accuracy: 0.4424\n",
      "Epoch 56/120\n",
      " - 23s - loss: 0.0719 - accuracy: 0.4721 - val_loss: 0.0717 - val_accuracy: 0.4606\n",
      "Epoch 57/120\n",
      " - 22s - loss: 0.0716 - accuracy: 0.4660 - val_loss: 0.0732 - val_accuracy: 0.4441\n",
      "Epoch 58/120\n",
      " - 23s - loss: 0.0718 - accuracy: 0.4703 - val_loss: 0.0732 - val_accuracy: 0.4458\n",
      "Epoch 59/120\n",
      " - 23s - loss: 0.0715 - accuracy: 0.4689 - val_loss: 0.0720 - val_accuracy: 0.4615\n",
      "Epoch 60/120\n",
      " - 23s - loss: 0.0715 - accuracy: 0.4706 - val_loss: 0.0743 - val_accuracy: 0.4376\n",
      "Epoch 61/120\n",
      " - 22s - loss: 0.0717 - accuracy: 0.4705 - val_loss: 0.0722 - val_accuracy: 0.4532\n",
      "Epoch 62/120\n",
      " - 21s - loss: 0.0713 - accuracy: 0.4733 - val_loss: 0.0749 - val_accuracy: 0.4437\n",
      "Epoch 63/120\n",
      " - 24s - loss: 0.0715 - accuracy: 0.4718 - val_loss: 0.0713 - val_accuracy: 0.4606\n",
      "Epoch 64/120\n",
      " - 22s - loss: 0.0715 - accuracy: 0.4774 - val_loss: 0.0724 - val_accuracy: 0.4598\n",
      "Epoch 65/120\n",
      " - 22s - loss: 0.0713 - accuracy: 0.4752 - val_loss: 0.0733 - val_accuracy: 0.4458\n",
      "Epoch 66/120\n",
      " - 23s - loss: 0.0709 - accuracy: 0.4799 - val_loss: 0.0736 - val_accuracy: 0.4363\n",
      "Epoch 67/120\n",
      " - 23s - loss: 0.0716 - accuracy: 0.4747 - val_loss: 0.0718 - val_accuracy: 0.4515\n",
      "Epoch 68/120\n",
      " - 22s - loss: 0.0711 - accuracy: 0.4762 - val_loss: 0.0722 - val_accuracy: 0.4598\n",
      "Epoch 69/120\n",
      " - 23s - loss: 0.0711 - accuracy: 0.4773 - val_loss: 0.0715 - val_accuracy: 0.4611\n",
      "Epoch 70/120\n",
      " - 23s - loss: 0.0709 - accuracy: 0.4780 - val_loss: 0.0754 - val_accuracy: 0.4345\n",
      "Epoch 71/120\n",
      " - 22s - loss: 0.0709 - accuracy: 0.4800 - val_loss: 0.0731 - val_accuracy: 0.4506\n",
      "Epoch 72/120\n",
      " - 24s - loss: 0.0716 - accuracy: 0.4713 - val_loss: 0.0722 - val_accuracy: 0.4559\n",
      "Epoch 73/120\n",
      " - 23s - loss: 0.0708 - accuracy: 0.4802 - val_loss: 0.0722 - val_accuracy: 0.4606\n",
      "Epoch 74/120\n",
      " - 22s - loss: 0.0707 - accuracy: 0.4845 - val_loss: 0.0737 - val_accuracy: 0.4489\n",
      "Epoch 75/120\n",
      " - 23s - loss: 0.0708 - accuracy: 0.4788 - val_loss: 0.0738 - val_accuracy: 0.4454\n",
      "Epoch 76/120\n",
      " - 23s - loss: 0.0704 - accuracy: 0.4853 - val_loss: 0.0742 - val_accuracy: 0.4463\n",
      "Epoch 77/120\n",
      " - 24s - loss: 0.0704 - accuracy: 0.4830 - val_loss: 0.0743 - val_accuracy: 0.4350\n",
      "Epoch 78/120\n",
      " - 22s - loss: 0.0706 - accuracy: 0.4864 - val_loss: 0.0731 - val_accuracy: 0.4524\n",
      "Epoch 79/120\n",
      " - 23s - loss: 0.0708 - accuracy: 0.4826 - val_loss: 0.0733 - val_accuracy: 0.4506\n",
      "Epoch 80/120\n",
      " - 23s - loss: 0.0704 - accuracy: 0.4822 - val_loss: 0.0727 - val_accuracy: 0.4537\n",
      "Epoch 81/120\n",
      " - 22s - loss: 0.0702 - accuracy: 0.4868 - val_loss: 0.0729 - val_accuracy: 0.4480\n",
      "Epoch 82/120\n",
      " - 23s - loss: 0.0700 - accuracy: 0.4889 - val_loss: 0.0767 - val_accuracy: 0.4258\n",
      "Epoch 83/120\n",
      " - 24s - loss: 0.0702 - accuracy: 0.4854 - val_loss: 0.0731 - val_accuracy: 0.4619\n",
      "Epoch 84/120\n",
      " - 23s - loss: 0.0703 - accuracy: 0.4910 - val_loss: 0.0720 - val_accuracy: 0.4685\n",
      "Epoch 85/120\n",
      " - 24s - loss: 0.0702 - accuracy: 0.4843 - val_loss: 0.0729 - val_accuracy: 0.4593\n",
      "Epoch 86/120\n",
      " - 23s - loss: 0.0701 - accuracy: 0.4891 - val_loss: 0.0746 - val_accuracy: 0.4615\n",
      "Epoch 87/120\n",
      " - 23s - loss: 0.0702 - accuracy: 0.4900 - val_loss: 0.0731 - val_accuracy: 0.4672\n",
      "Epoch 88/120\n",
      " - 23s - loss: 0.0697 - accuracy: 0.4946 - val_loss: 0.0743 - val_accuracy: 0.4676\n",
      "Epoch 89/120\n",
      " - 22s - loss: 0.0701 - accuracy: 0.4866 - val_loss: 0.0758 - val_accuracy: 0.4267\n",
      "Epoch 90/120\n",
      " - 21s - loss: 0.0700 - accuracy: 0.4955 - val_loss: 0.0725 - val_accuracy: 0.4650\n",
      "Epoch 91/120\n",
      " - 23s - loss: 0.0699 - accuracy: 0.4962 - val_loss: 0.0747 - val_accuracy: 0.4293\n",
      "Epoch 92/120\n",
      " - 23s - loss: 0.0698 - accuracy: 0.4943 - val_loss: 0.0727 - val_accuracy: 0.4659\n",
      "Epoch 93/120\n",
      " - 21s - loss: 0.0694 - accuracy: 0.4994 - val_loss: 0.0736 - val_accuracy: 0.4693\n",
      "Epoch 94/120\n",
      " - 22s - loss: 0.0697 - accuracy: 0.4940 - val_loss: 0.0721 - val_accuracy: 0.4641\n",
      "Epoch 95/120\n",
      " - 23s - loss: 0.0696 - accuracy: 0.4982 - val_loss: 0.0762 - val_accuracy: 0.4141\n",
      "Epoch 96/120\n",
      " - 23s - loss: 0.0696 - accuracy: 0.4935 - val_loss: 0.0755 - val_accuracy: 0.4367\n",
      "Epoch 97/120\n",
      " - 23s - loss: 0.0698 - accuracy: 0.4940 - val_loss: 0.0730 - val_accuracy: 0.4624\n",
      "Epoch 98/120\n",
      " - 23s - loss: 0.0694 - accuracy: 0.4990 - val_loss: 0.0748 - val_accuracy: 0.4463\n",
      "Epoch 99/120\n",
      " - 23s - loss: 0.0694 - accuracy: 0.4962 - val_loss: 0.0752 - val_accuracy: 0.4467\n",
      "Epoch 100/120\n",
      " - 22s - loss: 0.0696 - accuracy: 0.4990 - val_loss: 0.0747 - val_accuracy: 0.4589\n",
      "Epoch 101/120\n",
      " - 23s - loss: 0.0696 - accuracy: 0.4981 - val_loss: 0.0754 - val_accuracy: 0.4406\n",
      "Epoch 102/120\n",
      " - 24s - loss: 0.0695 - accuracy: 0.4976 - val_loss: 0.0724 - val_accuracy: 0.4689\n",
      "Epoch 103/120\n",
      " - 23s - loss: 0.0694 - accuracy: 0.5015 - val_loss: 0.0733 - val_accuracy: 0.4537\n",
      "Epoch 104/120\n",
      " - 23s - loss: 0.0692 - accuracy: 0.5018 - val_loss: 0.0761 - val_accuracy: 0.4254\n",
      "Epoch 105/120\n",
      " - 23s - loss: 0.0694 - accuracy: 0.5006 - val_loss: 0.0743 - val_accuracy: 0.4550\n",
      "Epoch 106/120\n",
      " - 23s - loss: 0.0692 - accuracy: 0.5036 - val_loss: 0.0745 - val_accuracy: 0.4532\n",
      "Epoch 107/120\n",
      " - 24s - loss: 0.0694 - accuracy: 0.5032 - val_loss: 0.0727 - val_accuracy: 0.4654\n",
      "Epoch 108/120\n",
      " - 24s - loss: 0.0690 - accuracy: 0.5055 - val_loss: 0.0731 - val_accuracy: 0.4537\n",
      "Epoch 109/120\n",
      " - 22s - loss: 0.0691 - accuracy: 0.5064 - val_loss: 0.0735 - val_accuracy: 0.4602\n",
      "Epoch 110/120\n",
      " - 22s - loss: 0.0704 - accuracy: 0.5032 - val_loss: 0.0775 - val_accuracy: 0.4019\n",
      "Epoch 111/120\n",
      " - 23s - loss: 0.0687 - accuracy: 0.5049 - val_loss: 0.0729 - val_accuracy: 0.4654\n",
      "Epoch 112/120\n",
      " - 22s - loss: 0.0689 - accuracy: 0.5045 - val_loss: 0.0732 - val_accuracy: 0.4528\n",
      "Epoch 113/120\n",
      " - 22s - loss: 0.0690 - accuracy: 0.5051 - val_loss: 0.0752 - val_accuracy: 0.4519\n",
      "Epoch 114/120\n",
      " - 23s - loss: 0.0689 - accuracy: 0.5094 - val_loss: 0.0722 - val_accuracy: 0.4737\n",
      "Epoch 115/120\n",
      " - 23s - loss: 0.0688 - accuracy: 0.5097 - val_loss: 0.0738 - val_accuracy: 0.4663\n",
      "Epoch 116/120\n",
      " - 23s - loss: 0.0686 - accuracy: 0.5078 - val_loss: 0.0765 - val_accuracy: 0.4406\n",
      "Epoch 117/120\n",
      " - 22s - loss: 0.0688 - accuracy: 0.5086 - val_loss: 0.0743 - val_accuracy: 0.4650\n",
      "Epoch 118/120\n",
      " - 22s - loss: 0.0689 - accuracy: 0.5073 - val_loss: 0.0742 - val_accuracy: 0.4563\n",
      "Epoch 119/120\n",
      " - 22s - loss: 0.0688 - accuracy: 0.5045 - val_loss: 0.0750 - val_accuracy: 0.4476\n",
      "Epoch 120/120\n",
      " - 23s - loss: 0.0687 - accuracy: 0.5098 - val_loss: 0.0735 - val_accuracy: 0.4672\n",
      "Train on 20691 samples, validate on 2299 samples\n",
      "Epoch 1/120\n",
      " - 23s - loss: 0.3550 - accuracy: 0.1004 - val_loss: 0.1977 - val_accuracy: 0.1000\n",
      "Epoch 2/120\n",
      " - 23s - loss: 0.1942 - accuracy: 0.1000 - val_loss: 0.1901 - val_accuracy: 0.1000\n",
      "Epoch 3/120\n",
      " - 24s - loss: 0.1900 - accuracy: 0.0982 - val_loss: 0.1903 - val_accuracy: 0.1000\n",
      "Epoch 4/120\n",
      " - 22s - loss: 0.1902 - accuracy: 0.0980 - val_loss: 0.1905 - val_accuracy: 0.0996\n",
      "Epoch 5/120\n",
      " - 23s - loss: 0.1912 - accuracy: 0.1008 - val_loss: 0.1940 - val_accuracy: 0.1000\n",
      "Epoch 6/120\n",
      " - 21s - loss: 0.1929 - accuracy: 0.1002 - val_loss: 0.1939 - val_accuracy: 0.1000\n",
      "Epoch 7/120\n",
      " - 23s - loss: 0.1938 - accuracy: 0.0986 - val_loss: 0.1913 - val_accuracy: 0.1000\n",
      "Epoch 8/120\n",
      " - 23s - loss: 0.1550 - accuracy: 0.1388 - val_loss: 0.0879 - val_accuracy: 0.2362\n",
      "Epoch 9/120\n",
      " - 22s - loss: 0.0872 - accuracy: 0.2617 - val_loss: 0.0865 - val_accuracy: 0.2810\n",
      "Epoch 10/120\n",
      " - 23s - loss: 0.0856 - accuracy: 0.2908 - val_loss: 0.0845 - val_accuracy: 0.3010\n",
      "Epoch 11/120\n",
      " - 22s - loss: 0.0835 - accuracy: 0.3197 - val_loss: 0.0824 - val_accuracy: 0.3401\n",
      "Epoch 12/120\n",
      " - 22s - loss: 0.0834 - accuracy: 0.3324 - val_loss: 0.0834 - val_accuracy: 0.3606\n",
      "Epoch 13/120\n",
      " - 22s - loss: 0.0800 - accuracy: 0.3692 - val_loss: 0.0794 - val_accuracy: 0.3710\n",
      "Epoch 14/120\n",
      " - 23s - loss: 0.0789 - accuracy: 0.3774 - val_loss: 0.0772 - val_accuracy: 0.4080\n",
      "Epoch 15/120\n",
      " - 24s - loss: 0.0797 - accuracy: 0.3792 - val_loss: 0.0764 - val_accuracy: 0.3941\n",
      "Epoch 16/120\n",
      " - 24s - loss: 0.0780 - accuracy: 0.3976 - val_loss: 0.0755 - val_accuracy: 0.4045\n",
      "Epoch 17/120\n",
      " - 23s - loss: 0.0778 - accuracy: 0.3983 - val_loss: 0.0759 - val_accuracy: 0.4128\n",
      "Epoch 18/120\n",
      " - 23s - loss: 0.0768 - accuracy: 0.4012 - val_loss: 0.0755 - val_accuracy: 0.4345\n",
      "Epoch 19/120\n",
      " - 24s - loss: 0.0765 - accuracy: 0.4096 - val_loss: 0.0767 - val_accuracy: 0.3923\n",
      "Epoch 20/120\n",
      " - 24s - loss: 0.0762 - accuracy: 0.4149 - val_loss: 0.0779 - val_accuracy: 0.4154\n",
      "Epoch 21/120\n",
      " - 22s - loss: 0.0763 - accuracy: 0.4118 - val_loss: 0.0798 - val_accuracy: 0.3662\n",
      "Epoch 22/120\n",
      " - 23s - loss: 0.0762 - accuracy: 0.4119 - val_loss: 0.0777 - val_accuracy: 0.3980\n",
      "Epoch 23/120\n",
      " - 23s - loss: 0.0752 - accuracy: 0.4211 - val_loss: 0.0786 - val_accuracy: 0.4237\n",
      "Epoch 24/120\n",
      " - 23s - loss: 0.0755 - accuracy: 0.4204 - val_loss: 0.0754 - val_accuracy: 0.4267\n",
      "Epoch 25/120\n",
      " - 23s - loss: 0.0754 - accuracy: 0.4212 - val_loss: 0.0744 - val_accuracy: 0.4376\n",
      "Epoch 26/120\n",
      " - 23s - loss: 0.0747 - accuracy: 0.4271 - val_loss: 0.0740 - val_accuracy: 0.4528\n",
      "Epoch 27/120\n",
      " - 23s - loss: 0.0747 - accuracy: 0.4310 - val_loss: 0.0761 - val_accuracy: 0.4302\n",
      "Epoch 28/120\n",
      " - 23s - loss: 0.0746 - accuracy: 0.4315 - val_loss: 0.0767 - val_accuracy: 0.4219\n",
      "Epoch 29/120\n",
      " - 24s - loss: 0.0741 - accuracy: 0.4371 - val_loss: 0.0745 - val_accuracy: 0.4245\n",
      "Epoch 30/120\n",
      " - 22s - loss: 0.0746 - accuracy: 0.4310 - val_loss: 0.0741 - val_accuracy: 0.4432\n",
      "Epoch 31/120\n",
      " - 24s - loss: 0.0740 - accuracy: 0.4372 - val_loss: 0.0768 - val_accuracy: 0.4141\n",
      "Epoch 32/120\n",
      " - 23s - loss: 0.0781 - accuracy: 0.4153 - val_loss: 0.0742 - val_accuracy: 0.4354\n",
      "Epoch 33/120\n",
      " - 23s - loss: 0.0740 - accuracy: 0.4338 - val_loss: 0.0770 - val_accuracy: 0.4071\n",
      "Epoch 34/120\n",
      " - 22s - loss: 0.0738 - accuracy: 0.4381 - val_loss: 0.0753 - val_accuracy: 0.4406\n",
      "Epoch 35/120\n",
      " - 23s - loss: 0.0736 - accuracy: 0.4410 - val_loss: 0.0757 - val_accuracy: 0.4067\n",
      "Epoch 36/120\n",
      " - 21s - loss: 0.0735 - accuracy: 0.4479 - val_loss: 0.0750 - val_accuracy: 0.4193\n",
      "Epoch 37/120\n",
      " - 22s - loss: 0.0733 - accuracy: 0.4444 - val_loss: 0.0765 - val_accuracy: 0.4150\n",
      "Epoch 38/120\n",
      " - 22s - loss: 0.0732 - accuracy: 0.4442 - val_loss: 0.0740 - val_accuracy: 0.4280\n",
      "Epoch 39/120\n",
      " - 23s - loss: 0.0733 - accuracy: 0.4482 - val_loss: 0.0748 - val_accuracy: 0.4450\n",
      "Epoch 40/120\n",
      " - 21s - loss: 0.0727 - accuracy: 0.4544 - val_loss: 0.0768 - val_accuracy: 0.4124\n",
      "Epoch 41/120\n",
      " - 23s - loss: 0.0734 - accuracy: 0.4486 - val_loss: 0.0734 - val_accuracy: 0.4528\n",
      "Epoch 42/120\n",
      " - 22s - loss: 0.0727 - accuracy: 0.4509 - val_loss: 0.0762 - val_accuracy: 0.3993\n",
      "Epoch 43/120\n",
      " - 22s - loss: 0.0730 - accuracy: 0.4493 - val_loss: 0.0746 - val_accuracy: 0.4350\n",
      "Epoch 44/120\n",
      " - 23s - loss: 0.0726 - accuracy: 0.4526 - val_loss: 0.0725 - val_accuracy: 0.4506\n",
      "Epoch 45/120\n",
      " - 22s - loss: 0.0727 - accuracy: 0.4510 - val_loss: 0.0733 - val_accuracy: 0.4502\n",
      "Epoch 46/120\n",
      " - 24s - loss: 0.0728 - accuracy: 0.4546 - val_loss: 0.0735 - val_accuracy: 0.4506\n",
      "Epoch 47/120\n",
      " - 23s - loss: 0.0727 - accuracy: 0.4531 - val_loss: 0.0744 - val_accuracy: 0.4476\n",
      "Epoch 48/120\n",
      " - 22s - loss: 0.0727 - accuracy: 0.4496 - val_loss: 0.0743 - val_accuracy: 0.4389\n",
      "Epoch 49/120\n",
      " - 22s - loss: 0.0725 - accuracy: 0.4567 - val_loss: 0.0741 - val_accuracy: 0.4428\n",
      "Epoch 50/120\n",
      " - 23s - loss: 0.0720 - accuracy: 0.4605 - val_loss: 0.0723 - val_accuracy: 0.4637\n",
      "Epoch 51/120\n",
      " - 23s - loss: 0.0722 - accuracy: 0.4593 - val_loss: 0.0744 - val_accuracy: 0.4445\n",
      "Epoch 52/120\n",
      " - 22s - loss: 0.0722 - accuracy: 0.4598 - val_loss: 0.0745 - val_accuracy: 0.4406\n",
      "Epoch 53/120\n",
      " - 22s - loss: 0.0724 - accuracy: 0.4641 - val_loss: 0.0728 - val_accuracy: 0.4585\n",
      "Epoch 54/120\n",
      " - 23s - loss: 0.0719 - accuracy: 0.4620 - val_loss: 0.0739 - val_accuracy: 0.4511\n",
      "Epoch 55/120\n",
      " - 22s - loss: 0.0721 - accuracy: 0.4642 - val_loss: 0.0730 - val_accuracy: 0.4559\n",
      "Epoch 56/120\n",
      " - 22s - loss: 0.0721 - accuracy: 0.4616 - val_loss: 0.0729 - val_accuracy: 0.4463\n",
      "Epoch 57/120\n",
      " - 23s - loss: 0.0717 - accuracy: 0.4622 - val_loss: 0.0741 - val_accuracy: 0.4485\n",
      "Epoch 58/120\n",
      " - 22s - loss: 0.0718 - accuracy: 0.4677 - val_loss: 0.0749 - val_accuracy: 0.4567\n",
      "Epoch 59/120\n",
      " - 23s - loss: 0.0717 - accuracy: 0.4680 - val_loss: 0.0739 - val_accuracy: 0.4567\n",
      "Epoch 60/120\n",
      " - 23s - loss: 0.0718 - accuracy: 0.4667 - val_loss: 0.0733 - val_accuracy: 0.4519\n",
      "Epoch 61/120\n",
      " - 24s - loss: 0.0715 - accuracy: 0.4696 - val_loss: 0.0727 - val_accuracy: 0.4576\n",
      "Epoch 62/120\n",
      " - 23s - loss: 0.0716 - accuracy: 0.4671 - val_loss: 0.0742 - val_accuracy: 0.4480\n",
      "Epoch 63/120\n",
      " - 22s - loss: 0.0717 - accuracy: 0.4704 - val_loss: 0.0737 - val_accuracy: 0.4337\n",
      "Epoch 64/120\n",
      " - 23s - loss: 0.0719 - accuracy: 0.4662 - val_loss: 0.0744 - val_accuracy: 0.4358\n",
      "Epoch 65/120\n",
      " - 23s - loss: 0.0713 - accuracy: 0.4733 - val_loss: 0.0743 - val_accuracy: 0.4345\n",
      "Epoch 66/120\n",
      " - 24s - loss: 0.0715 - accuracy: 0.4705 - val_loss: 0.0746 - val_accuracy: 0.4545\n",
      "Epoch 67/120\n",
      " - 24s - loss: 0.0715 - accuracy: 0.4707 - val_loss: 0.0747 - val_accuracy: 0.4354\n",
      "Epoch 68/120\n",
      " - 23s - loss: 0.0713 - accuracy: 0.4716 - val_loss: 0.0744 - val_accuracy: 0.4402\n",
      "Epoch 69/120\n",
      " - 23s - loss: 0.0714 - accuracy: 0.4722 - val_loss: 0.0744 - val_accuracy: 0.4454\n",
      "Epoch 70/120\n",
      " - 23s - loss: 0.0719 - accuracy: 0.4688 - val_loss: 0.0740 - val_accuracy: 0.4437\n",
      "Epoch 71/120\n",
      " - 24s - loss: 0.0710 - accuracy: 0.4730 - val_loss: 0.0736 - val_accuracy: 0.4524\n",
      "Epoch 72/120\n",
      " - 23s - loss: 0.0714 - accuracy: 0.4734 - val_loss: 0.0757 - val_accuracy: 0.4328\n",
      "Epoch 73/120\n",
      " - 23s - loss: 0.0707 - accuracy: 0.4784 - val_loss: 0.0756 - val_accuracy: 0.4163\n",
      "Epoch 74/120\n",
      " - 23s - loss: 0.0712 - accuracy: 0.4739 - val_loss: 0.0733 - val_accuracy: 0.4589\n",
      "Epoch 75/120\n",
      " - 24s - loss: 0.0707 - accuracy: 0.4817 - val_loss: 0.0746 - val_accuracy: 0.4632\n",
      "Epoch 76/120\n",
      " - 23s - loss: 0.0713 - accuracy: 0.4720 - val_loss: 0.0744 - val_accuracy: 0.4385\n",
      "Epoch 77/120\n",
      " - 22s - loss: 0.0706 - accuracy: 0.4809 - val_loss: 0.0746 - val_accuracy: 0.4645\n",
      "Epoch 78/120\n",
      " - 22s - loss: 0.0707 - accuracy: 0.4805 - val_loss: 0.0739 - val_accuracy: 0.4611\n",
      "Epoch 79/120\n",
      " - 22s - loss: 0.0707 - accuracy: 0.4807 - val_loss: 0.0735 - val_accuracy: 0.4606\n",
      "Epoch 80/120\n",
      " - 22s - loss: 0.0707 - accuracy: 0.4804 - val_loss: 0.0740 - val_accuracy: 0.4371\n",
      "Epoch 81/120\n",
      " - 22s - loss: 0.0706 - accuracy: 0.4794 - val_loss: 0.0754 - val_accuracy: 0.4437\n",
      "Epoch 82/120\n",
      " - 23s - loss: 0.0705 - accuracy: 0.4800 - val_loss: 0.0763 - val_accuracy: 0.4319\n",
      "Epoch 83/120\n",
      " - 23s - loss: 0.0707 - accuracy: 0.4839 - val_loss: 0.0752 - val_accuracy: 0.4293\n",
      "Epoch 84/120\n",
      " - 24s - loss: 0.0709 - accuracy: 0.4790 - val_loss: 0.0742 - val_accuracy: 0.4515\n",
      "Epoch 85/120\n",
      " - 23s - loss: 0.0710 - accuracy: 0.4779 - val_loss: 0.0732 - val_accuracy: 0.4619\n",
      "Epoch 86/120\n",
      " - 23s - loss: 0.0704 - accuracy: 0.4871 - val_loss: 0.0754 - val_accuracy: 0.4358\n",
      "Epoch 87/120\n",
      " - 23s - loss: 0.0703 - accuracy: 0.4877 - val_loss: 0.0750 - val_accuracy: 0.4445\n",
      "Epoch 88/120\n",
      " - 23s - loss: 0.0702 - accuracy: 0.4858 - val_loss: 0.0737 - val_accuracy: 0.4589\n",
      "Epoch 89/120\n",
      " - 23s - loss: 0.0704 - accuracy: 0.4862 - val_loss: 0.0743 - val_accuracy: 0.4476\n",
      "Epoch 90/120\n",
      " - 23s - loss: 0.0702 - accuracy: 0.4859 - val_loss: 0.0755 - val_accuracy: 0.4415\n",
      "Epoch 91/120\n",
      " - 23s - loss: 0.0701 - accuracy: 0.4864 - val_loss: 0.0766 - val_accuracy: 0.4154\n",
      "Epoch 92/120\n",
      " - 22s - loss: 0.0703 - accuracy: 0.4868 - val_loss: 0.0747 - val_accuracy: 0.4567\n",
      "Epoch 93/120\n",
      " - 23s - loss: 0.0704 - accuracy: 0.4826 - val_loss: 0.0746 - val_accuracy: 0.4441\n",
      "Epoch 94/120\n",
      " - 23s - loss: 0.0700 - accuracy: 0.4887 - val_loss: 0.0726 - val_accuracy: 0.4519\n",
      "Epoch 95/120\n",
      " - 24s - loss: 0.0705 - accuracy: 0.4852 - val_loss: 0.0766 - val_accuracy: 0.4302\n",
      "Epoch 96/120\n",
      " - 24s - loss: 0.0700 - accuracy: 0.4885 - val_loss: 0.0738 - val_accuracy: 0.4545\n",
      "Epoch 97/120\n",
      " - 22s - loss: 0.0699 - accuracy: 0.4948 - val_loss: 0.0749 - val_accuracy: 0.4519\n",
      "Epoch 98/120\n",
      " - 22s - loss: 0.0702 - accuracy: 0.4876 - val_loss: 0.0745 - val_accuracy: 0.4659\n",
      "Epoch 99/120\n",
      " - 22s - loss: 0.0699 - accuracy: 0.4874 - val_loss: 0.0760 - val_accuracy: 0.4550\n",
      "Epoch 100/120\n",
      " - 22s - loss: 0.0699 - accuracy: 0.4944 - val_loss: 0.0761 - val_accuracy: 0.4354\n",
      "Epoch 101/120\n",
      " - 22s - loss: 0.0698 - accuracy: 0.4943 - val_loss: 0.0749 - val_accuracy: 0.4532\n",
      "Epoch 102/120\n",
      " - 23s - loss: 0.0699 - accuracy: 0.4908 - val_loss: 0.0755 - val_accuracy: 0.4432\n",
      "Epoch 103/120\n",
      " - 22s - loss: 0.0698 - accuracy: 0.4940 - val_loss: 0.0736 - val_accuracy: 0.4541\n",
      "Epoch 104/120\n",
      " - 23s - loss: 0.0695 - accuracy: 0.4953 - val_loss: 0.0750 - val_accuracy: 0.4411\n",
      "Epoch 105/120\n",
      " - 22s - loss: 0.0695 - accuracy: 0.4951 - val_loss: 0.0755 - val_accuracy: 0.4463\n",
      "Epoch 106/120\n",
      " - 22s - loss: 0.0697 - accuracy: 0.4947 - val_loss: 0.0743 - val_accuracy: 0.4563\n",
      "Epoch 107/120\n",
      " - 23s - loss: 0.0696 - accuracy: 0.4949 - val_loss: 0.0736 - val_accuracy: 0.4589\n",
      "Epoch 108/120\n",
      " - 22s - loss: 0.0695 - accuracy: 0.4966 - val_loss: 0.0756 - val_accuracy: 0.4411\n",
      "Epoch 109/120\n",
      " - 21s - loss: 0.0696 - accuracy: 0.4935 - val_loss: 0.0746 - val_accuracy: 0.4572\n",
      "Epoch 110/120\n",
      " - 22s - loss: 0.0696 - accuracy: 0.4988 - val_loss: 0.0737 - val_accuracy: 0.4541\n",
      "Epoch 111/120\n",
      " - 22s - loss: 0.0693 - accuracy: 0.5008 - val_loss: 0.0753 - val_accuracy: 0.4624\n",
      "Epoch 112/120\n",
      " - 22s - loss: 0.0693 - accuracy: 0.4990 - val_loss: 0.0751 - val_accuracy: 0.4511\n",
      "Epoch 113/120\n",
      " - 23s - loss: 0.0694 - accuracy: 0.4985 - val_loss: 0.0742 - val_accuracy: 0.4489\n",
      "Epoch 114/120\n",
      " - 22s - loss: 0.0695 - accuracy: 0.4933 - val_loss: 0.0753 - val_accuracy: 0.4393\n",
      "Epoch 115/120\n",
      " - 22s - loss: 0.0695 - accuracy: 0.4957 - val_loss: 0.0737 - val_accuracy: 0.4650\n",
      "Epoch 116/120\n",
      " - 22s - loss: 0.0691 - accuracy: 0.4995 - val_loss: 0.0744 - val_accuracy: 0.4489\n",
      "Epoch 117/120\n",
      " - 22s - loss: 0.0693 - accuracy: 0.4988 - val_loss: 0.0802 - val_accuracy: 0.4097\n",
      "Epoch 118/120\n",
      " - 22s - loss: 0.0691 - accuracy: 0.5031 - val_loss: 0.0741 - val_accuracy: 0.4493\n",
      "Epoch 119/120\n",
      " - 22s - loss: 0.0690 - accuracy: 0.5016 - val_loss: 0.0762 - val_accuracy: 0.4524\n",
      "Epoch 120/120\n",
      " - 22s - loss: 0.0693 - accuracy: 0.5006 - val_loss: 0.0739 - val_accuracy: 0.4563\n",
      "Train on 20691 samples, validate on 2299 samples\n",
      "Epoch 1/120\n",
      " - 24s - loss: 0.3850 - accuracy: 0.0979 - val_loss: 0.2110 - val_accuracy: 0.1000\n",
      "Epoch 2/120\n",
      " - 24s - loss: 0.2007 - accuracy: 0.1009 - val_loss: 0.1977 - val_accuracy: 0.1000\n",
      "Epoch 3/120\n",
      " - 23s - loss: 0.1969 - accuracy: 0.1006 - val_loss: 0.1994 - val_accuracy: 0.1000\n",
      "Epoch 4/120\n",
      " - 23s - loss: 0.1976 - accuracy: 0.1011 - val_loss: 0.1966 - val_accuracy: 0.1000\n",
      "Epoch 5/120\n",
      " - 24s - loss: 0.1925 - accuracy: 0.0992 - val_loss: 0.1911 - val_accuracy: 0.1000\n",
      "Epoch 6/120\n",
      " - 23s - loss: 0.1973 - accuracy: 0.1022 - val_loss: 0.1996 - val_accuracy: 0.1000\n",
      "Epoch 7/120\n",
      " - 24s - loss: 0.1961 - accuracy: 0.1027 - val_loss: 0.1958 - val_accuracy: 0.1000\n",
      "Epoch 8/120\n",
      " - 24s - loss: 0.1954 - accuracy: 0.1001 - val_loss: 0.1965 - val_accuracy: 0.1000\n",
      "Epoch 9/120\n",
      " - 24s - loss: 0.1933 - accuracy: 0.1018 - val_loss: 0.1925 - val_accuracy: 0.1000\n",
      "Epoch 10/120\n",
      " - 24s - loss: 0.1902 - accuracy: 0.0965 - val_loss: 0.1024 - val_accuracy: 0.1740\n",
      "Epoch 11/120\n",
      " - 24s - loss: 0.0881 - accuracy: 0.2603 - val_loss: 0.0840 - val_accuracy: 0.3097\n",
      "Epoch 12/120\n",
      " - 24s - loss: 0.0828 - accuracy: 0.3118 - val_loss: 0.0795 - val_accuracy: 0.3558\n",
      "Epoch 13/120\n",
      " - 23s - loss: 0.0818 - accuracy: 0.3397 - val_loss: 0.0800 - val_accuracy: 0.3506\n",
      "Epoch 14/120\n",
      " - 24s - loss: 0.0799 - accuracy: 0.3660 - val_loss: 0.0788 - val_accuracy: 0.3984\n",
      "Epoch 15/120\n",
      " - 24s - loss: 0.0796 - accuracy: 0.3757 - val_loss: 0.0776 - val_accuracy: 0.3780\n",
      "Epoch 16/120\n",
      " - 25s - loss: 0.0788 - accuracy: 0.3799 - val_loss: 0.0767 - val_accuracy: 0.4023\n",
      "Epoch 17/120\n",
      " - 24s - loss: 0.0780 - accuracy: 0.3891 - val_loss: 0.0759 - val_accuracy: 0.4163\n",
      "Epoch 18/120\n",
      " - 24s - loss: 0.0783 - accuracy: 0.3934 - val_loss: 0.0776 - val_accuracy: 0.3941\n",
      "Epoch 19/120\n",
      " - 24s - loss: 0.0772 - accuracy: 0.4014 - val_loss: 0.0750 - val_accuracy: 0.4215\n",
      "Epoch 20/120\n",
      " - 24s - loss: 0.0768 - accuracy: 0.4057 - val_loss: 0.0748 - val_accuracy: 0.4228\n",
      "Epoch 21/120\n",
      " - 23s - loss: 0.0771 - accuracy: 0.4051 - val_loss: 0.0804 - val_accuracy: 0.3662\n",
      "Epoch 22/120\n",
      " - 24s - loss: 0.0766 - accuracy: 0.4171 - val_loss: 0.0804 - val_accuracy: 0.3493\n",
      "Epoch 23/120\n",
      " - 24s - loss: 0.0762 - accuracy: 0.4196 - val_loss: 0.0778 - val_accuracy: 0.3980\n",
      "Epoch 24/120\n",
      " - 24s - loss: 0.0761 - accuracy: 0.4206 - val_loss: 0.0743 - val_accuracy: 0.4258\n",
      "Epoch 25/120\n",
      " - 24s - loss: 0.0757 - accuracy: 0.4246 - val_loss: 0.0731 - val_accuracy: 0.4445\n",
      "Epoch 26/120\n",
      " - 25s - loss: 0.0756 - accuracy: 0.4185 - val_loss: 0.0735 - val_accuracy: 0.4389\n",
      "Epoch 27/120\n",
      " - 23s - loss: 0.0751 - accuracy: 0.4262 - val_loss: 0.0744 - val_accuracy: 0.4150\n",
      "Epoch 28/120\n",
      " - 24s - loss: 0.0751 - accuracy: 0.4289 - val_loss: 0.0740 - val_accuracy: 0.4224\n",
      "Epoch 29/120\n",
      " - 24s - loss: 0.0748 - accuracy: 0.4349 - val_loss: 0.0748 - val_accuracy: 0.4319\n",
      "Epoch 30/120\n",
      " - 24s - loss: 0.0744 - accuracy: 0.4376 - val_loss: 0.0742 - val_accuracy: 0.4398\n",
      "Epoch 31/120\n",
      " - 25s - loss: 0.0747 - accuracy: 0.4292 - val_loss: 0.0733 - val_accuracy: 0.4324\n",
      "Epoch 32/120\n",
      " - 24s - loss: 0.0743 - accuracy: 0.4359 - val_loss: 0.0787 - val_accuracy: 0.4006\n",
      "Epoch 33/120\n",
      " - 24s - loss: 0.0744 - accuracy: 0.4390 - val_loss: 0.0742 - val_accuracy: 0.4298\n",
      "Epoch 34/120\n",
      " - 24s - loss: 0.0742 - accuracy: 0.4415 - val_loss: 0.0721 - val_accuracy: 0.4485\n",
      "Epoch 35/120\n",
      " - 24s - loss: 0.0739 - accuracy: 0.4420 - val_loss: 0.0726 - val_accuracy: 0.4419\n",
      "Epoch 36/120\n",
      " - 24s - loss: 0.0739 - accuracy: 0.4443 - val_loss: 0.0731 - val_accuracy: 0.4424\n",
      "Epoch 37/120\n",
      " - 24s - loss: 0.0737 - accuracy: 0.4453 - val_loss: 0.0725 - val_accuracy: 0.4428\n",
      "Epoch 38/120\n",
      " - 24s - loss: 0.0739 - accuracy: 0.4424 - val_loss: 0.0739 - val_accuracy: 0.4406\n",
      "Epoch 39/120\n",
      " - 24s - loss: 0.0738 - accuracy: 0.4475 - val_loss: 0.0886 - val_accuracy: 0.2949\n",
      "Epoch 40/120\n",
      " - 24s - loss: 0.0739 - accuracy: 0.4456 - val_loss: 0.0723 - val_accuracy: 0.4476\n",
      "Epoch 41/120\n",
      " - 24s - loss: 0.0733 - accuracy: 0.4521 - val_loss: 0.0730 - val_accuracy: 0.4489\n",
      "Epoch 42/120\n",
      " - 24s - loss: 0.0730 - accuracy: 0.4532 - val_loss: 0.0770 - val_accuracy: 0.3997\n",
      "Epoch 43/120\n",
      " - 25s - loss: 0.0736 - accuracy: 0.4464 - val_loss: 0.0746 - val_accuracy: 0.4245\n",
      "Epoch 44/120\n",
      " - 23s - loss: 0.0731 - accuracy: 0.4529 - val_loss: 0.0720 - val_accuracy: 0.4602\n",
      "Epoch 45/120\n",
      " - 24s - loss: 0.0729 - accuracy: 0.4561 - val_loss: 0.0743 - val_accuracy: 0.4358\n",
      "Epoch 46/120\n",
      " - 24s - loss: 0.0730 - accuracy: 0.4513 - val_loss: 0.0751 - val_accuracy: 0.4324\n",
      "Epoch 47/120\n",
      " - 25s - loss: 0.0734 - accuracy: 0.4506 - val_loss: 0.0729 - val_accuracy: 0.4472\n",
      "Epoch 48/120\n",
      " - 24s - loss: 0.0727 - accuracy: 0.4570 - val_loss: 0.0728 - val_accuracy: 0.4458\n",
      "Epoch 49/120\n",
      " - 25s - loss: 0.0726 - accuracy: 0.4585 - val_loss: 0.0742 - val_accuracy: 0.4258\n",
      "Epoch 50/120\n",
      " - 23s - loss: 0.0727 - accuracy: 0.4598 - val_loss: 0.0739 - val_accuracy: 0.4485\n",
      "Epoch 51/120\n",
      " - 24s - loss: 0.0725 - accuracy: 0.4602 - val_loss: 0.0736 - val_accuracy: 0.4419\n",
      "Epoch 52/120\n",
      " - 24s - loss: 0.0725 - accuracy: 0.4625 - val_loss: 0.0725 - val_accuracy: 0.4580\n",
      "Epoch 53/120\n",
      " - 24s - loss: 0.0725 - accuracy: 0.4600 - val_loss: 0.0741 - val_accuracy: 0.4367\n",
      "Epoch 54/120\n",
      " - 24s - loss: 0.0725 - accuracy: 0.4603 - val_loss: 0.0749 - val_accuracy: 0.4371\n",
      "Epoch 55/120\n",
      " - 24s - loss: 0.0719 - accuracy: 0.4640 - val_loss: 0.0762 - val_accuracy: 0.4197\n",
      "Epoch 56/120\n",
      " - 24s - loss: 0.0724 - accuracy: 0.4592 - val_loss: 0.0733 - val_accuracy: 0.4445\n",
      "Epoch 57/120\n",
      " - 24s - loss: 0.0717 - accuracy: 0.4683 - val_loss: 0.0747 - val_accuracy: 0.4376\n",
      "Epoch 58/120\n",
      " - 24s - loss: 0.0724 - accuracy: 0.4627 - val_loss: 0.0774 - val_accuracy: 0.4345\n",
      "Epoch 59/120\n",
      " - 23s - loss: 0.0722 - accuracy: 0.4671 - val_loss: 0.0750 - val_accuracy: 0.4389\n",
      "Epoch 60/120\n",
      " - 24s - loss: 0.0719 - accuracy: 0.4654 - val_loss: 0.0735 - val_accuracy: 0.4606\n",
      "Epoch 61/120\n",
      " - 24s - loss: 0.0717 - accuracy: 0.4711 - val_loss: 0.0719 - val_accuracy: 0.4593\n",
      "Epoch 62/120\n",
      " - 24s - loss: 0.0718 - accuracy: 0.4684 - val_loss: 0.0732 - val_accuracy: 0.4550\n",
      "Epoch 63/120\n",
      " - 24s - loss: 0.0719 - accuracy: 0.4677 - val_loss: 0.0740 - val_accuracy: 0.4363\n",
      "Epoch 64/120\n",
      " - 23s - loss: 0.0717 - accuracy: 0.4701 - val_loss: 0.0754 - val_accuracy: 0.4263\n",
      "Epoch 65/120\n",
      " - 24s - loss: 0.0718 - accuracy: 0.4702 - val_loss: 0.0721 - val_accuracy: 0.4498\n",
      "Epoch 66/120\n",
      " - 24s - loss: 0.0716 - accuracy: 0.4729 - val_loss: 0.0733 - val_accuracy: 0.4463\n",
      "Epoch 67/120\n",
      " - 24s - loss: 0.0715 - accuracy: 0.4747 - val_loss: 0.0729 - val_accuracy: 0.4515\n",
      "Epoch 68/120\n",
      " - 24s - loss: 0.0716 - accuracy: 0.4761 - val_loss: 0.0723 - val_accuracy: 0.4650\n",
      "Epoch 69/120\n",
      " - 24s - loss: 0.0715 - accuracy: 0.4762 - val_loss: 0.0725 - val_accuracy: 0.4637\n",
      "Epoch 70/120\n",
      " - 24s - loss: 0.0713 - accuracy: 0.4787 - val_loss: 0.0732 - val_accuracy: 0.4580\n",
      "Epoch 71/120\n",
      " - 23s - loss: 0.0713 - accuracy: 0.4731 - val_loss: 0.0727 - val_accuracy: 0.4585\n",
      "Epoch 72/120\n",
      " - 24s - loss: 0.0710 - accuracy: 0.4787 - val_loss: 0.0719 - val_accuracy: 0.4506\n",
      "Epoch 73/120\n",
      " - 23s - loss: 0.0710 - accuracy: 0.4776 - val_loss: 0.0720 - val_accuracy: 0.4563\n",
      "Epoch 74/120\n",
      " - 24s - loss: 0.0712 - accuracy: 0.4751 - val_loss: 0.0725 - val_accuracy: 0.4572\n",
      "Epoch 75/120\n",
      " - 24s - loss: 0.0712 - accuracy: 0.4783 - val_loss: 0.0731 - val_accuracy: 0.4493\n",
      "Epoch 76/120\n",
      " - 24s - loss: 0.0709 - accuracy: 0.4821 - val_loss: 0.0730 - val_accuracy: 0.4585\n",
      "Epoch 77/120\n",
      " - 25s - loss: 0.0710 - accuracy: 0.4817 - val_loss: 0.0737 - val_accuracy: 0.4332\n",
      "Epoch 78/120\n",
      " - 24s - loss: 0.0712 - accuracy: 0.4802 - val_loss: 0.0724 - val_accuracy: 0.4502\n",
      "Epoch 79/120\n",
      " - 23s - loss: 0.0709 - accuracy: 0.4802 - val_loss: 0.0721 - val_accuracy: 0.4602\n",
      "Epoch 80/120\n",
      " - 24s - loss: 0.0710 - accuracy: 0.4813 - val_loss: 0.0724 - val_accuracy: 0.4693\n",
      "Epoch 81/120\n",
      " - 24s - loss: 0.0709 - accuracy: 0.4824 - val_loss: 0.0744 - val_accuracy: 0.4419\n",
      "Epoch 82/120\n",
      " - 24s - loss: 0.0707 - accuracy: 0.4834 - val_loss: 0.0765 - val_accuracy: 0.4385\n",
      "Epoch 83/120\n",
      " - 24s - loss: 0.0707 - accuracy: 0.4819 - val_loss: 0.0726 - val_accuracy: 0.4467\n",
      "Epoch 84/120\n",
      " - 24s - loss: 0.0707 - accuracy: 0.4849 - val_loss: 0.0721 - val_accuracy: 0.4598\n",
      "Epoch 85/120\n",
      " - 24s - loss: 0.0705 - accuracy: 0.4899 - val_loss: 0.0722 - val_accuracy: 0.4698\n",
      "Epoch 86/120\n",
      " - 23s - loss: 0.0706 - accuracy: 0.4875 - val_loss: 0.0729 - val_accuracy: 0.4606\n",
      "Epoch 87/120\n",
      " - 24s - loss: 0.0704 - accuracy: 0.4860 - val_loss: 0.0724 - val_accuracy: 0.4550\n",
      "Epoch 88/120\n",
      " - 24s - loss: 0.0704 - accuracy: 0.4894 - val_loss: 0.0740 - val_accuracy: 0.4389\n",
      "Epoch 89/120\n",
      " - 24s - loss: 0.0705 - accuracy: 0.4868 - val_loss: 0.0721 - val_accuracy: 0.4702\n",
      "Epoch 90/120\n",
      " - 23s - loss: 0.0705 - accuracy: 0.4883 - val_loss: 0.0762 - val_accuracy: 0.4258\n",
      "Epoch 91/120\n",
      " - 24s - loss: 0.0703 - accuracy: 0.4880 - val_loss: 0.0752 - val_accuracy: 0.4580\n",
      "Epoch 92/120\n",
      " - 24s - loss: 0.0704 - accuracy: 0.4947 - val_loss: 0.0724 - val_accuracy: 0.4632\n",
      "Epoch 93/120\n",
      " - 24s - loss: 0.0704 - accuracy: 0.4936 - val_loss: 0.0729 - val_accuracy: 0.4519\n",
      "Epoch 94/120\n",
      " - 23s - loss: 0.0700 - accuracy: 0.4929 - val_loss: 0.0724 - val_accuracy: 0.4624\n",
      "Epoch 95/120\n",
      " - 24s - loss: 0.0701 - accuracy: 0.4932 - val_loss: 0.0730 - val_accuracy: 0.4611\n",
      "Epoch 96/120\n",
      " - 24s - loss: 0.0701 - accuracy: 0.4935 - val_loss: 0.0753 - val_accuracy: 0.4480\n",
      "Epoch 97/120\n",
      " - 24s - loss: 0.0703 - accuracy: 0.4913 - val_loss: 0.0727 - val_accuracy: 0.4602\n",
      "Epoch 98/120\n",
      " - 25s - loss: 0.0698 - accuracy: 0.4944 - val_loss: 0.0735 - val_accuracy: 0.4580\n",
      "Epoch 99/120\n",
      " - 24s - loss: 0.0699 - accuracy: 0.4974 - val_loss: 0.0737 - val_accuracy: 0.4598\n",
      "Epoch 100/120\n",
      " - 23s - loss: 0.0697 - accuracy: 0.5000 - val_loss: 0.0745 - val_accuracy: 0.4511\n",
      "Epoch 101/120\n",
      " - 24s - loss: 0.0699 - accuracy: 0.4950 - val_loss: 0.0725 - val_accuracy: 0.4619\n",
      "Epoch 102/120\n",
      " - 24s - loss: 0.0700 - accuracy: 0.4938 - val_loss: 0.0726 - val_accuracy: 0.4715\n",
      "Epoch 103/120\n",
      " - 24s - loss: 0.0700 - accuracy: 0.4958 - val_loss: 0.0733 - val_accuracy: 0.4593\n",
      "Epoch 104/120\n",
      " - 24s - loss: 0.0694 - accuracy: 0.5041 - val_loss: 0.0735 - val_accuracy: 0.4689\n",
      "Epoch 105/120\n",
      " - 25s - loss: 0.0695 - accuracy: 0.5005 - val_loss: 0.0758 - val_accuracy: 0.4450\n",
      "Epoch 106/120\n",
      " - 24s - loss: 0.0697 - accuracy: 0.5022 - val_loss: 0.0732 - val_accuracy: 0.4602\n",
      "Epoch 107/120\n",
      " - 23s - loss: 0.0696 - accuracy: 0.4993 - val_loss: 0.0753 - val_accuracy: 0.4480\n",
      "Epoch 108/120\n",
      " - 24s - loss: 0.0695 - accuracy: 0.4993 - val_loss: 0.0724 - val_accuracy: 0.4602\n",
      "Epoch 109/120\n",
      " - 25s - loss: 0.0694 - accuracy: 0.4978 - val_loss: 0.0750 - val_accuracy: 0.4519\n",
      "Epoch 110/120\n",
      " - 25s - loss: 0.0696 - accuracy: 0.5009 - val_loss: 0.0728 - val_accuracy: 0.4685\n",
      "Epoch 111/120\n",
      " - 25s - loss: 0.0697 - accuracy: 0.5007 - val_loss: 0.0742 - val_accuracy: 0.4506\n",
      "Epoch 112/120\n",
      " - 25s - loss: 0.0697 - accuracy: 0.5020 - val_loss: 0.0730 - val_accuracy: 0.4545\n",
      "Epoch 113/120\n",
      " - 24s - loss: 0.0689 - accuracy: 0.5073 - val_loss: 0.0773 - val_accuracy: 0.4241\n",
      "Epoch 114/120\n",
      " - 25s - loss: 0.0694 - accuracy: 0.5040 - val_loss: 0.0733 - val_accuracy: 0.4711\n",
      "Epoch 115/120\n",
      " - 26s - loss: 0.0695 - accuracy: 0.5009 - val_loss: 0.0725 - val_accuracy: 0.4654\n",
      "Epoch 116/120\n",
      " - 24s - loss: 0.0690 - accuracy: 0.5071 - val_loss: 0.0747 - val_accuracy: 0.4493\n",
      "Epoch 117/120\n",
      " - 26s - loss: 0.0688 - accuracy: 0.5083 - val_loss: 0.0756 - val_accuracy: 0.4532\n",
      "Epoch 118/120\n",
      " - 24s - loss: 0.0692 - accuracy: 0.5062 - val_loss: 0.0729 - val_accuracy: 0.4589\n",
      "Epoch 119/120\n",
      " - 24s - loss: 0.0689 - accuracy: 0.5112 - val_loss: 0.0734 - val_accuracy: 0.4489\n",
      "Epoch 120/120\n",
      " - 25s - loss: 0.0689 - accuracy: 0.5078 - val_loss: 0.0781 - val_accuracy: 0.4302\n",
      "Train on 20691 samples, validate on 2299 samples\n",
      "Epoch 1/120\n",
      " - 20s - loss: 0.3450 - accuracy: 0.1017 - val_loss: 0.1912 - val_accuracy: 0.1000\n",
      "Epoch 2/120\n",
      " - 21s - loss: 0.1910 - accuracy: 0.0993 - val_loss: 0.1924 - val_accuracy: 0.1000\n",
      "Epoch 3/120\n",
      " - 21s - loss: 0.1144 - accuracy: 0.1927 - val_loss: 0.0882 - val_accuracy: 0.2971\n",
      "Epoch 4/120\n",
      " - 22s - loss: 0.0878 - accuracy: 0.2668 - val_loss: 0.0896 - val_accuracy: 0.2658\n",
      "Epoch 5/120\n",
      " - 21s - loss: 0.0866 - accuracy: 0.2823 - val_loss: 0.0850 - val_accuracy: 0.3014\n",
      "Epoch 6/120\n",
      " - 20s - loss: 0.0857 - accuracy: 0.2884 - val_loss: 0.0834 - val_accuracy: 0.3206\n",
      "Epoch 7/120\n",
      " - 22s - loss: 0.0833 - accuracy: 0.3192 - val_loss: 0.0876 - val_accuracy: 0.2936\n",
      "Epoch 8/120\n",
      " - 21s - loss: 0.0825 - accuracy: 0.3237 - val_loss: 0.0794 - val_accuracy: 0.3602\n",
      "Epoch 9/120\n",
      " - 21s - loss: 0.0814 - accuracy: 0.3418 - val_loss: 0.0807 - val_accuracy: 0.3375\n",
      "Epoch 10/120\n",
      " - 21s - loss: 0.0883 - accuracy: 0.3176 - val_loss: 0.0799 - val_accuracy: 0.3549\n",
      "Epoch 11/120\n",
      " - 21s - loss: 0.0803 - accuracy: 0.3606 - val_loss: 0.0779 - val_accuracy: 0.3867\n",
      "Epoch 12/120\n",
      " - 19s - loss: 0.0791 - accuracy: 0.3685 - val_loss: 0.1261 - val_accuracy: 0.1805\n",
      "Epoch 13/120\n",
      " - 21s - loss: 0.0822 - accuracy: 0.3604 - val_loss: 0.0782 - val_accuracy: 0.4019\n",
      "Epoch 14/120\n",
      " - 22s - loss: 0.0845 - accuracy: 0.3571 - val_loss: 0.0888 - val_accuracy: 0.3667\n",
      "Epoch 15/120\n",
      " - 23s - loss: 0.0786 - accuracy: 0.3876 - val_loss: 0.0757 - val_accuracy: 0.4263\n",
      "Epoch 16/120\n",
      " - 20s - loss: 0.0776 - accuracy: 0.3894 - val_loss: 0.0741 - val_accuracy: 0.4415\n",
      "Epoch 17/120\n",
      " - 21s - loss: 0.0777 - accuracy: 0.3967 - val_loss: 0.0760 - val_accuracy: 0.4197\n",
      "Epoch 18/120\n",
      " - 21s - loss: 0.0771 - accuracy: 0.4024 - val_loss: 0.0771 - val_accuracy: 0.4010\n",
      "Epoch 19/120\n",
      " - 21s - loss: 0.0769 - accuracy: 0.4050 - val_loss: 0.0759 - val_accuracy: 0.4341\n",
      "Epoch 20/120\n",
      " - 21s - loss: 0.0767 - accuracy: 0.4062 - val_loss: 0.0753 - val_accuracy: 0.4280\n",
      "Epoch 21/120\n",
      " - 23s - loss: 0.0760 - accuracy: 0.4186 - val_loss: 0.0806 - val_accuracy: 0.3475\n",
      "Epoch 22/120\n",
      " - 19s - loss: 0.0766 - accuracy: 0.4104 - val_loss: 0.0785 - val_accuracy: 0.4067\n",
      "Epoch 23/120\n",
      " - 22s - loss: 0.0758 - accuracy: 0.4234 - val_loss: 0.0785 - val_accuracy: 0.3697\n",
      "Epoch 24/120\n",
      " - 21s - loss: 0.0756 - accuracy: 0.4187 - val_loss: 0.0756 - val_accuracy: 0.4445\n",
      "Epoch 25/120\n",
      " - 21s - loss: 0.0751 - accuracy: 0.4243 - val_loss: 0.0731 - val_accuracy: 0.4498\n",
      "Epoch 26/120\n",
      " - 22s - loss: 0.0748 - accuracy: 0.4311 - val_loss: 0.0744 - val_accuracy: 0.4432\n",
      "Epoch 27/120\n",
      " - 23s - loss: 0.0748 - accuracy: 0.4306 - val_loss: 0.0792 - val_accuracy: 0.3897\n",
      "Epoch 28/120\n",
      " - 20s - loss: 0.0755 - accuracy: 0.4260 - val_loss: 0.0737 - val_accuracy: 0.4493\n",
      "Epoch 29/120\n",
      " - 20s - loss: 0.0748 - accuracy: 0.4288 - val_loss: 0.0732 - val_accuracy: 0.4528\n",
      "Epoch 30/120\n",
      " - 22s - loss: 0.0752 - accuracy: 0.4277 - val_loss: 0.0746 - val_accuracy: 0.4367\n",
      "Epoch 31/120\n",
      " - 21s - loss: 0.0746 - accuracy: 0.4359 - val_loss: 0.0749 - val_accuracy: 0.4367\n",
      "Epoch 32/120\n",
      " - 21s - loss: 0.0742 - accuracy: 0.4388 - val_loss: 0.0721 - val_accuracy: 0.4698\n",
      "Epoch 33/120\n",
      " - 21s - loss: 0.0741 - accuracy: 0.4431 - val_loss: 0.0740 - val_accuracy: 0.4432\n",
      "Epoch 34/120\n",
      " - 21s - loss: 0.0743 - accuracy: 0.4389 - val_loss: 0.0741 - val_accuracy: 0.4324\n",
      "Epoch 35/120\n",
      " - 21s - loss: 0.0742 - accuracy: 0.4434 - val_loss: 0.0798 - val_accuracy: 0.4150\n",
      "Epoch 36/120\n",
      " - 22s - loss: 0.0741 - accuracy: 0.4437 - val_loss: 0.0741 - val_accuracy: 0.4476\n",
      "Epoch 37/120\n",
      " - 22s - loss: 0.0736 - accuracy: 0.4463 - val_loss: 0.0719 - val_accuracy: 0.4689\n",
      "Epoch 38/120\n",
      " - 21s - loss: 0.0737 - accuracy: 0.4452 - val_loss: 0.0747 - val_accuracy: 0.4467\n",
      "Epoch 39/120\n",
      " - 21s - loss: 0.0740 - accuracy: 0.4445 - val_loss: 0.0720 - val_accuracy: 0.4576\n",
      "Epoch 40/120\n",
      " - 20s - loss: 0.0736 - accuracy: 0.4507 - val_loss: 0.0732 - val_accuracy: 0.4550\n",
      "Epoch 41/120\n",
      " - 21s - loss: 0.0735 - accuracy: 0.4501 - val_loss: 0.0742 - val_accuracy: 0.4263\n",
      "Epoch 42/120\n",
      " - 21s - loss: 0.0732 - accuracy: 0.4530 - val_loss: 0.0735 - val_accuracy: 0.4476\n",
      "Epoch 43/120\n",
      " - 22s - loss: 0.0733 - accuracy: 0.4516 - val_loss: 0.0726 - val_accuracy: 0.4606\n",
      "Epoch 44/120\n",
      " - 20s - loss: 0.0733 - accuracy: 0.4530 - val_loss: 0.0724 - val_accuracy: 0.4624\n",
      "Epoch 45/120\n",
      " - 23s - loss: 0.0732 - accuracy: 0.4569 - val_loss: 0.0727 - val_accuracy: 0.4637\n",
      "Epoch 46/120\n",
      " - 22s - loss: 0.0731 - accuracy: 0.4542 - val_loss: 0.0722 - val_accuracy: 0.4685\n",
      "Epoch 47/120\n",
      " - 21s - loss: 0.0730 - accuracy: 0.4536 - val_loss: 0.0748 - val_accuracy: 0.4463\n",
      "Epoch 48/120\n",
      " - 21s - loss: 0.0738 - accuracy: 0.4557 - val_loss: 0.0767 - val_accuracy: 0.4106\n",
      "Epoch 49/120\n",
      " - 21s - loss: 0.0732 - accuracy: 0.4596 - val_loss: 0.0723 - val_accuracy: 0.4528\n",
      "Epoch 50/120\n",
      " - 21s - loss: 0.0730 - accuracy: 0.4598 - val_loss: 0.0729 - val_accuracy: 0.4358\n",
      "Epoch 51/120\n",
      " - 21s - loss: 0.0725 - accuracy: 0.4616 - val_loss: 0.0728 - val_accuracy: 0.4550\n",
      "Epoch 52/120\n",
      " - 21s - loss: 0.0728 - accuracy: 0.4575 - val_loss: 0.0737 - val_accuracy: 0.4576\n",
      "Epoch 53/120\n",
      " - 23s - loss: 0.0727 - accuracy: 0.4608 - val_loss: 0.0722 - val_accuracy: 0.4637\n",
      "Epoch 54/120\n",
      " - 23s - loss: 0.0725 - accuracy: 0.4624 - val_loss: 0.0744 - val_accuracy: 0.4554\n",
      "Epoch 55/120\n",
      " - 20s - loss: 0.0726 - accuracy: 0.4615 - val_loss: 0.0749 - val_accuracy: 0.4306\n",
      "Epoch 56/120\n",
      " - 21s - loss: 0.0724 - accuracy: 0.4654 - val_loss: 0.0715 - val_accuracy: 0.4724\n",
      "Epoch 57/120\n",
      " - 22s - loss: 0.0720 - accuracy: 0.4695 - val_loss: 0.0717 - val_accuracy: 0.4624\n",
      "Epoch 58/120\n",
      " - 20s - loss: 0.0720 - accuracy: 0.4699 - val_loss: 0.0765 - val_accuracy: 0.4480\n",
      "Epoch 59/120\n",
      " - 21s - loss: 0.0727 - accuracy: 0.4639 - val_loss: 0.0719 - val_accuracy: 0.4632\n",
      "Epoch 60/120\n",
      " - 22s - loss: 0.0722 - accuracy: 0.4652 - val_loss: 0.0758 - val_accuracy: 0.4228\n",
      "Epoch 61/120\n",
      " - 22s - loss: 0.0720 - accuracy: 0.4691 - val_loss: 0.0751 - val_accuracy: 0.4432\n",
      "Epoch 62/120\n",
      " - 19s - loss: 0.0720 - accuracy: 0.4687 - val_loss: 0.0744 - val_accuracy: 0.4445\n",
      "Epoch 63/120\n",
      " - 23s - loss: 0.0718 - accuracy: 0.4715 - val_loss: 0.0735 - val_accuracy: 0.4511\n",
      "Epoch 64/120\n",
      " - 20s - loss: 0.0718 - accuracy: 0.4727 - val_loss: 0.0720 - val_accuracy: 0.4698\n",
      "Epoch 65/120\n",
      " - 20s - loss: 0.0718 - accuracy: 0.4754 - val_loss: 0.0738 - val_accuracy: 0.4454\n",
      "Epoch 66/120\n",
      " - 21s - loss: 0.0718 - accuracy: 0.4715 - val_loss: 0.0739 - val_accuracy: 0.4572\n",
      "Epoch 67/120\n",
      " - 21s - loss: 0.0715 - accuracy: 0.4746 - val_loss: 0.0759 - val_accuracy: 0.4472\n",
      "Epoch 68/120\n",
      " - 18s - loss: 0.0715 - accuracy: 0.4711 - val_loss: 0.0729 - val_accuracy: 0.4624\n",
      "Epoch 69/120\n",
      " - 19s - loss: 0.0717 - accuracy: 0.4736 - val_loss: 0.0742 - val_accuracy: 0.4554\n",
      "Epoch 70/120\n",
      " - 21s - loss: 0.0716 - accuracy: 0.4723 - val_loss: 0.0725 - val_accuracy: 0.4545\n",
      "Epoch 71/120\n",
      " - 22s - loss: 0.0717 - accuracy: 0.4726 - val_loss: 0.0727 - val_accuracy: 0.4702\n",
      "Epoch 72/120\n",
      " - 21s - loss: 0.0714 - accuracy: 0.4780 - val_loss: 0.0721 - val_accuracy: 0.4645\n",
      "Epoch 73/120\n",
      " - 21s - loss: 0.0714 - accuracy: 0.4779 - val_loss: 0.0733 - val_accuracy: 0.4593\n",
      "Epoch 74/120\n",
      " - 21s - loss: 0.0713 - accuracy: 0.4782 - val_loss: 0.0721 - val_accuracy: 0.4589\n",
      "Epoch 75/120\n",
      " - 19s - loss: 0.0716 - accuracy: 0.4765 - val_loss: 0.0730 - val_accuracy: 0.4615\n",
      "Epoch 76/120\n",
      " - 20s - loss: 0.0711 - accuracy: 0.4803 - val_loss: 0.0766 - val_accuracy: 0.4489\n",
      "Epoch 77/120\n",
      " - 18s - loss: 0.0710 - accuracy: 0.4826 - val_loss: 0.0743 - val_accuracy: 0.4432\n",
      "Epoch 78/120\n",
      " - 20s - loss: 0.0713 - accuracy: 0.4823 - val_loss: 0.0731 - val_accuracy: 0.4524\n",
      "Epoch 79/120\n",
      " - 20s - loss: 0.0710 - accuracy: 0.4817 - val_loss: 0.0732 - val_accuracy: 0.4632\n",
      "Epoch 80/120\n",
      " - 21s - loss: 0.0708 - accuracy: 0.4832 - val_loss: 0.0720 - val_accuracy: 0.4567\n",
      "Epoch 81/120\n",
      " - 20s - loss: 0.0711 - accuracy: 0.4866 - val_loss: 0.0765 - val_accuracy: 0.4228\n",
      "Epoch 82/120\n",
      " - 20s - loss: 0.0730 - accuracy: 0.4748 - val_loss: 0.0735 - val_accuracy: 0.4567\n",
      "Epoch 83/120\n",
      " - 21s - loss: 0.0713 - accuracy: 0.4830 - val_loss: 0.0762 - val_accuracy: 0.4367\n",
      "Epoch 84/120\n",
      " - 21s - loss: 0.0710 - accuracy: 0.4811 - val_loss: 0.0756 - val_accuracy: 0.4485\n",
      "Epoch 85/120\n",
      " - 19s - loss: 0.0708 - accuracy: 0.4863 - val_loss: 0.0734 - val_accuracy: 0.4572\n",
      "Epoch 86/120\n",
      " - 21s - loss: 0.0708 - accuracy: 0.4848 - val_loss: 0.0734 - val_accuracy: 0.4559\n",
      "Epoch 87/120\n",
      " - 20s - loss: 0.0709 - accuracy: 0.4867 - val_loss: 0.0728 - val_accuracy: 0.4559\n",
      "Epoch 88/120\n",
      " - 20s - loss: 0.0703 - accuracy: 0.4873 - val_loss: 0.0725 - val_accuracy: 0.4624\n",
      "Epoch 89/120\n",
      " - 19s - loss: 0.0705 - accuracy: 0.4919 - val_loss: 0.0750 - val_accuracy: 0.4541\n",
      "Epoch 90/120\n",
      " - 21s - loss: 0.0706 - accuracy: 0.4872 - val_loss: 0.0740 - val_accuracy: 0.4498\n",
      "Epoch 91/120\n",
      " - 21s - loss: 0.0703 - accuracy: 0.4908 - val_loss: 0.0730 - val_accuracy: 0.4645\n",
      "Epoch 92/120\n",
      " - 20s - loss: 0.0703 - accuracy: 0.4927 - val_loss: 0.0767 - val_accuracy: 0.4241\n",
      "Epoch 93/120\n",
      " - 21s - loss: 0.0706 - accuracy: 0.4869 - val_loss: 0.0716 - val_accuracy: 0.4728\n",
      "Epoch 94/120\n",
      " - 20s - loss: 0.0703 - accuracy: 0.4903 - val_loss: 0.0746 - val_accuracy: 0.4563\n",
      "Epoch 95/120\n",
      " - 20s - loss: 0.0704 - accuracy: 0.4914 - val_loss: 0.0727 - val_accuracy: 0.4611\n",
      "Epoch 96/120\n",
      " - 19s - loss: 0.0707 - accuracy: 0.4889 - val_loss: 0.0751 - val_accuracy: 0.4393\n",
      "Epoch 97/120\n",
      " - 20s - loss: 0.0701 - accuracy: 0.4934 - val_loss: 0.0762 - val_accuracy: 0.4463\n",
      "Epoch 98/120\n",
      " - 20s - loss: 0.0702 - accuracy: 0.4927 - val_loss: 0.0742 - val_accuracy: 0.4524\n",
      "Epoch 99/120\n",
      " - 20s - loss: 0.0699 - accuracy: 0.4945 - val_loss: 0.0725 - val_accuracy: 0.4719\n",
      "Epoch 100/120\n",
      " - 22s - loss: 0.0699 - accuracy: 0.4968 - val_loss: 0.0737 - val_accuracy: 0.4524\n",
      "Epoch 101/120\n",
      " - 20s - loss: 0.0702 - accuracy: 0.4921 - val_loss: 0.0750 - val_accuracy: 0.4663\n",
      "Epoch 102/120\n",
      " - 21s - loss: 0.0696 - accuracy: 0.5010 - val_loss: 0.0748 - val_accuracy: 0.4498\n",
      "Epoch 103/120\n",
      " - 20s - loss: 0.0701 - accuracy: 0.4961 - val_loss: 0.0756 - val_accuracy: 0.4332\n",
      "Epoch 104/120\n",
      " - 20s - loss: 0.0700 - accuracy: 0.4949 - val_loss: 0.0737 - val_accuracy: 0.4602\n",
      "Epoch 105/120\n",
      " - 21s - loss: 0.0701 - accuracy: 0.4930 - val_loss: 0.0735 - val_accuracy: 0.4624\n",
      "Epoch 106/120\n",
      " - 21s - loss: 0.0709 - accuracy: 0.4937 - val_loss: 0.0794 - val_accuracy: 0.4228\n",
      "Epoch 107/120\n",
      " - 21s - loss: 0.0701 - accuracy: 0.5006 - val_loss: 0.0763 - val_accuracy: 0.4441\n",
      "Epoch 108/120\n",
      " - 21s - loss: 0.0701 - accuracy: 0.4964 - val_loss: 0.0747 - val_accuracy: 0.4559\n",
      "Epoch 109/120\n",
      " - 19s - loss: 0.0701 - accuracy: 0.4940 - val_loss: 0.0745 - val_accuracy: 0.4498\n",
      "Epoch 110/120\n",
      " - 21s - loss: 0.0691 - accuracy: 0.5068 - val_loss: 0.0768 - val_accuracy: 0.4328\n",
      "Epoch 111/120\n",
      " - 19s - loss: 0.0697 - accuracy: 0.5007 - val_loss: 0.0730 - val_accuracy: 0.4602\n",
      "Epoch 112/120\n",
      " - 20s - loss: 0.0696 - accuracy: 0.5029 - val_loss: 0.0739 - val_accuracy: 0.4650\n",
      "Epoch 113/120\n",
      " - 21s - loss: 0.0695 - accuracy: 0.5034 - val_loss: 0.0754 - val_accuracy: 0.4524\n",
      "Epoch 114/120\n",
      " - 21s - loss: 0.0695 - accuracy: 0.5032 - val_loss: 0.0761 - val_accuracy: 0.4480\n",
      "Epoch 115/120\n",
      " - 21s - loss: 0.0695 - accuracy: 0.5039 - val_loss: 0.0744 - val_accuracy: 0.4641\n",
      "Epoch 116/120\n",
      " - 21s - loss: 0.0694 - accuracy: 0.5032 - val_loss: 0.0754 - val_accuracy: 0.4537\n",
      "Epoch 117/120\n",
      " - 21s - loss: 0.0692 - accuracy: 0.5025 - val_loss: 0.0740 - val_accuracy: 0.4458\n",
      "Epoch 118/120\n",
      " - 20s - loss: 0.0693 - accuracy: 0.5046 - val_loss: 0.0752 - val_accuracy: 0.4537\n",
      "Epoch 119/120\n",
      " - 21s - loss: 0.0690 - accuracy: 0.5062 - val_loss: 0.0730 - val_accuracy: 0.4576\n",
      "Epoch 120/120\n",
      " - 21s - loss: 0.0692 - accuracy: 0.5082 - val_loss: 0.0742 - val_accuracy: 0.4685\n",
      "Train on 20691 samples, validate on 2299 samples\n",
      "Epoch 1/120\n",
      " - 21s - loss: 0.3719 - accuracy: 0.0986 - val_loss: 0.2016 - val_accuracy: 0.1000\n",
      "Epoch 2/120\n",
      " - 22s - loss: 0.1965 - accuracy: 0.0995 - val_loss: 0.1960 - val_accuracy: 0.1000\n",
      "Epoch 3/120\n",
      " - 22s - loss: 0.1925 - accuracy: 0.0996 - val_loss: 0.1941 - val_accuracy: 0.1000\n",
      "Epoch 4/120\n",
      " - 23s - loss: 0.1964 - accuracy: 0.0989 - val_loss: 0.1939 - val_accuracy: 0.1000\n",
      "Epoch 5/120\n",
      " - 23s - loss: 0.1968 - accuracy: 0.1006 - val_loss: 0.1943 - val_accuracy: 0.1000\n",
      "Epoch 6/120\n",
      " - 22s - loss: 0.1976 - accuracy: 0.0977 - val_loss: 0.1921 - val_accuracy: 0.1000\n",
      "Epoch 7/120\n",
      " - 23s - loss: 0.1932 - accuracy: 0.1031 - val_loss: 0.2012 - val_accuracy: 0.1000\n",
      "Epoch 8/120\n",
      " - 22s - loss: 0.1956 - accuracy: 0.1004 - val_loss: 0.1912 - val_accuracy: 0.1000\n",
      "Epoch 9/120\n",
      " - 22s - loss: 0.1938 - accuracy: 0.1018 - val_loss: 0.1959 - val_accuracy: 0.1000\n",
      "Epoch 10/120\n",
      " - 22s - loss: 0.1917 - accuracy: 0.0986 - val_loss: 0.1871 - val_accuracy: 0.1000\n",
      "Epoch 11/120\n",
      " - 22s - loss: 0.1383 - accuracy: 0.1407 - val_loss: 0.0858 - val_accuracy: 0.2166\n",
      "Epoch 12/120\n",
      " - 22s - loss: 0.0871 - accuracy: 0.2672 - val_loss: 0.0840 - val_accuracy: 0.2875\n",
      "Epoch 13/120\n",
      " - 22s - loss: 0.0848 - accuracy: 0.2915 - val_loss: 0.0828 - val_accuracy: 0.3167\n",
      "Epoch 14/120\n",
      " - 23s - loss: 0.0853 - accuracy: 0.3065 - val_loss: 0.0829 - val_accuracy: 0.3497\n",
      "Epoch 15/120\n",
      " - 22s - loss: 0.0825 - accuracy: 0.3257 - val_loss: 0.0825 - val_accuracy: 0.3306\n",
      "Epoch 16/120\n",
      " - 23s - loss: 0.0833 - accuracy: 0.3258 - val_loss: 0.0809 - val_accuracy: 0.3371\n",
      "Epoch 17/120\n",
      " - 22s - loss: 0.0809 - accuracy: 0.3488 - val_loss: 0.0804 - val_accuracy: 0.3719\n",
      "Epoch 18/120\n",
      " - 23s - loss: 0.0801 - accuracy: 0.3618 - val_loss: 0.0799 - val_accuracy: 0.3667\n",
      "Epoch 19/120\n",
      " - 23s - loss: 0.0801 - accuracy: 0.3636 - val_loss: 0.0798 - val_accuracy: 0.3941\n",
      "Epoch 20/120\n",
      " - 23s - loss: 0.0791 - accuracy: 0.3719 - val_loss: 0.0802 - val_accuracy: 0.3680\n",
      "Epoch 21/120\n",
      " - 23s - loss: 0.0790 - accuracy: 0.3787 - val_loss: 0.0791 - val_accuracy: 0.3732\n",
      "Epoch 22/120\n",
      " - 22s - loss: 0.0780 - accuracy: 0.3854 - val_loss: 0.0789 - val_accuracy: 0.3828\n",
      "Epoch 23/120\n",
      " - 23s - loss: 0.0779 - accuracy: 0.3922 - val_loss: 0.0759 - val_accuracy: 0.4097\n",
      "Epoch 24/120\n",
      " - 23s - loss: 0.0773 - accuracy: 0.3912 - val_loss: 0.0754 - val_accuracy: 0.4141\n",
      "Epoch 25/120\n",
      " - 22s - loss: 0.0774 - accuracy: 0.3964 - val_loss: 0.0845 - val_accuracy: 0.3167\n",
      "Epoch 26/120\n",
      " - 24s - loss: 0.0775 - accuracy: 0.3962 - val_loss: 0.0765 - val_accuracy: 0.4084\n",
      "Epoch 27/120\n",
      " - 23s - loss: 0.0768 - accuracy: 0.4079 - val_loss: 0.0756 - val_accuracy: 0.4171\n",
      "Epoch 28/120\n",
      " - 23s - loss: 0.0764 - accuracy: 0.4114 - val_loss: 0.0774 - val_accuracy: 0.3976\n",
      "Epoch 29/120\n",
      " - 23s - loss: 0.0769 - accuracy: 0.4065 - val_loss: 0.0756 - val_accuracy: 0.4154\n",
      "Epoch 30/120\n",
      " - 23s - loss: 0.0881 - accuracy: 0.3602 - val_loss: 0.0752 - val_accuracy: 0.4058\n",
      "Epoch 31/120\n",
      " - 22s - loss: 0.0759 - accuracy: 0.4133 - val_loss: 0.0748 - val_accuracy: 0.4180\n",
      "Epoch 32/120\n",
      " - 23s - loss: 0.0758 - accuracy: 0.4136 - val_loss: 0.0745 - val_accuracy: 0.4215\n",
      "Epoch 33/120\n",
      " - 23s - loss: 0.0758 - accuracy: 0.4185 - val_loss: 0.0764 - val_accuracy: 0.3915\n",
      "Epoch 34/120\n",
      " - 22s - loss: 0.0753 - accuracy: 0.4206 - val_loss: 0.0734 - val_accuracy: 0.4332\n",
      "Epoch 35/120\n",
      " - 23s - loss: 0.0753 - accuracy: 0.4218 - val_loss: 0.0747 - val_accuracy: 0.4015\n",
      "Epoch 36/120\n",
      " - 23s - loss: 0.0752 - accuracy: 0.4233 - val_loss: 0.0738 - val_accuracy: 0.4206\n",
      "Epoch 37/120\n",
      " - 24s - loss: 0.0750 - accuracy: 0.4304 - val_loss: 0.0764 - val_accuracy: 0.3980\n",
      "Epoch 38/120\n",
      " - 23s - loss: 0.0758 - accuracy: 0.4204 - val_loss: 0.0745 - val_accuracy: 0.4232\n",
      "Epoch 39/120\n",
      " - 22s - loss: 0.0747 - accuracy: 0.4305 - val_loss: 0.0732 - val_accuracy: 0.4432\n",
      "Epoch 40/120\n",
      " - 23s - loss: 0.0756 - accuracy: 0.4218 - val_loss: 0.0772 - val_accuracy: 0.4019\n",
      "Epoch 41/120\n",
      " - 24s - loss: 0.0751 - accuracy: 0.4231 - val_loss: 0.0737 - val_accuracy: 0.4276\n",
      "Epoch 42/120\n",
      " - 23s - loss: 0.0748 - accuracy: 0.4238 - val_loss: 0.0755 - val_accuracy: 0.4106\n",
      "Epoch 43/120\n",
      " - 23s - loss: 0.0744 - accuracy: 0.4330 - val_loss: 0.0742 - val_accuracy: 0.4380\n",
      "Epoch 44/120\n",
      " - 24s - loss: 0.0764 - accuracy: 0.4244 - val_loss: 0.0751 - val_accuracy: 0.4184\n",
      "Epoch 45/120\n",
      " - 23s - loss: 0.0743 - accuracy: 0.4337 - val_loss: 0.0733 - val_accuracy: 0.4311\n",
      "Epoch 46/120\n",
      " - 24s - loss: 0.0740 - accuracy: 0.4380 - val_loss: 0.0736 - val_accuracy: 0.4315\n",
      "Epoch 47/120\n",
      " - 24s - loss: 0.0744 - accuracy: 0.4370 - val_loss: 0.0727 - val_accuracy: 0.4358\n",
      "Epoch 48/120\n",
      " - 22s - loss: 0.0743 - accuracy: 0.4381 - val_loss: 0.0739 - val_accuracy: 0.4271\n",
      "Epoch 49/120\n",
      " - 23s - loss: 0.0741 - accuracy: 0.4363 - val_loss: 0.0730 - val_accuracy: 0.4358\n",
      "Epoch 50/120\n",
      " - 23s - loss: 0.0740 - accuracy: 0.4391 - val_loss: 0.0724 - val_accuracy: 0.4450\n",
      "Epoch 51/120\n",
      " - 22s - loss: 0.0739 - accuracy: 0.4390 - val_loss: 0.0733 - val_accuracy: 0.4350\n",
      "Epoch 52/120\n",
      " - 22s - loss: 0.0739 - accuracy: 0.4411 - val_loss: 0.0744 - val_accuracy: 0.4289\n",
      "Epoch 53/120\n",
      " - 24s - loss: 0.0737 - accuracy: 0.4407 - val_loss: 0.0729 - val_accuracy: 0.4358\n",
      "Epoch 54/120\n",
      " - 24s - loss: 0.0734 - accuracy: 0.4450 - val_loss: 0.0732 - val_accuracy: 0.4411\n",
      "Epoch 55/120\n",
      " - 24s - loss: 0.0733 - accuracy: 0.4477 - val_loss: 0.0738 - val_accuracy: 0.4411\n",
      "Epoch 56/120\n",
      " - 23s - loss: 0.0735 - accuracy: 0.4436 - val_loss: 0.0737 - val_accuracy: 0.4380\n",
      "Epoch 57/120\n",
      " - 21s - loss: 0.0732 - accuracy: 0.4472 - val_loss: 0.0744 - val_accuracy: 0.4224\n",
      "Epoch 58/120\n",
      " - 22s - loss: 0.0732 - accuracy: 0.4507 - val_loss: 0.0738 - val_accuracy: 0.4393\n",
      "Epoch 59/120\n",
      " - 24s - loss: 0.0733 - accuracy: 0.4489 - val_loss: 0.0773 - val_accuracy: 0.3958\n",
      "Epoch 60/120\n",
      " - 23s - loss: 0.0731 - accuracy: 0.4502 - val_loss: 0.0727 - val_accuracy: 0.4493\n",
      "Epoch 61/120\n",
      " - 24s - loss: 0.0737 - accuracy: 0.4474 - val_loss: 0.0733 - val_accuracy: 0.4454\n",
      "Epoch 62/120\n",
      " - 25s - loss: 0.0727 - accuracy: 0.4576 - val_loss: 0.0743 - val_accuracy: 0.4328\n",
      "Epoch 63/120\n",
      " - 25s - loss: 0.0734 - accuracy: 0.4507 - val_loss: 0.0743 - val_accuracy: 0.4284\n",
      "Epoch 64/120\n",
      " - 25s - loss: 0.0732 - accuracy: 0.4501 - val_loss: 0.0727 - val_accuracy: 0.4580\n",
      "Epoch 65/120\n",
      " - 24s - loss: 0.0728 - accuracy: 0.4564 - val_loss: 0.0721 - val_accuracy: 0.4445\n",
      "Epoch 66/120\n",
      " - 24s - loss: 0.0729 - accuracy: 0.4572 - val_loss: 0.0730 - val_accuracy: 0.4489\n",
      "Epoch 67/120\n",
      " - 23s - loss: 0.0726 - accuracy: 0.4566 - val_loss: 0.0750 - val_accuracy: 0.4271\n",
      "Epoch 68/120\n",
      " - 24s - loss: 0.0725 - accuracy: 0.4597 - val_loss: 0.0837 - val_accuracy: 0.3384\n",
      "Epoch 69/120\n",
      " - 25s - loss: 0.0730 - accuracy: 0.4554 - val_loss: 0.0728 - val_accuracy: 0.4519\n",
      "Epoch 70/120\n",
      " - 24s - loss: 0.0725 - accuracy: 0.4594 - val_loss: 0.0729 - val_accuracy: 0.4519\n",
      "Epoch 71/120\n",
      " - 24s - loss: 0.0726 - accuracy: 0.4594 - val_loss: 0.0742 - val_accuracy: 0.4302\n",
      "Epoch 72/120\n",
      " - 24s - loss: 0.0727 - accuracy: 0.4590 - val_loss: 0.0729 - val_accuracy: 0.4437\n",
      "Epoch 73/120\n",
      " - 25s - loss: 0.0723 - accuracy: 0.4622 - val_loss: 0.0734 - val_accuracy: 0.4419\n",
      "Epoch 74/120\n",
      " - 23s - loss: 0.0726 - accuracy: 0.4585 - val_loss: 0.0732 - val_accuracy: 0.4402\n",
      "Epoch 75/120\n",
      " - 24s - loss: 0.0725 - accuracy: 0.4602 - val_loss: 0.0740 - val_accuracy: 0.4354\n",
      "Epoch 76/120\n",
      " - 23s - loss: 0.0724 - accuracy: 0.4618 - val_loss: 0.0743 - val_accuracy: 0.4389\n",
      "Epoch 77/120\n",
      " - 23s - loss: 0.0724 - accuracy: 0.4586 - val_loss: 0.0748 - val_accuracy: 0.4250\n",
      "Epoch 78/120\n",
      " - 25s - loss: 0.0724 - accuracy: 0.4610 - val_loss: 0.0731 - val_accuracy: 0.4406\n",
      "Epoch 79/120\n",
      " - 25s - loss: 0.0722 - accuracy: 0.4638 - val_loss: 0.0738 - val_accuracy: 0.4424\n",
      "Epoch 80/120\n",
      " - 25s - loss: 0.0719 - accuracy: 0.4670 - val_loss: 0.0726 - val_accuracy: 0.4489\n",
      "Epoch 81/120\n",
      " - 24s - loss: 0.0721 - accuracy: 0.4640 - val_loss: 0.0726 - val_accuracy: 0.4585\n",
      "Epoch 82/120\n",
      " - 24s - loss: 0.0723 - accuracy: 0.4654 - val_loss: 0.0731 - val_accuracy: 0.4393\n",
      "Epoch 83/120\n",
      " - 24s - loss: 0.0718 - accuracy: 0.4681 - val_loss: 0.0730 - val_accuracy: 0.4328\n",
      "Epoch 84/120\n",
      " - 24s - loss: 0.0723 - accuracy: 0.4620 - val_loss: 0.0728 - val_accuracy: 0.4532\n",
      "Epoch 85/120\n",
      " - 24s - loss: 0.0721 - accuracy: 0.4638 - val_loss: 0.0733 - val_accuracy: 0.4441\n",
      "Epoch 86/120\n",
      " - 24s - loss: 0.0720 - accuracy: 0.4668 - val_loss: 0.0745 - val_accuracy: 0.4393\n",
      "Epoch 87/120\n",
      " - 25s - loss: 0.0719 - accuracy: 0.4714 - val_loss: 0.0746 - val_accuracy: 0.4289\n",
      "Epoch 88/120\n",
      " - 24s - loss: 0.0721 - accuracy: 0.4646 - val_loss: 0.0732 - val_accuracy: 0.4437\n",
      "Epoch 89/120\n",
      " - 25s - loss: 0.0717 - accuracy: 0.4683 - val_loss: 0.0727 - val_accuracy: 0.4463\n",
      "Epoch 90/120\n",
      " - 24s - loss: 0.0718 - accuracy: 0.4708 - val_loss: 0.0739 - val_accuracy: 0.4350\n",
      "Epoch 91/120\n",
      " - 24s - loss: 0.0719 - accuracy: 0.4675 - val_loss: 0.0731 - val_accuracy: 0.4619\n",
      "Epoch 92/120\n",
      " - 25s - loss: 0.0717 - accuracy: 0.4701 - val_loss: 0.0737 - val_accuracy: 0.4393\n",
      "Epoch 93/120\n",
      " - 23s - loss: 0.0717 - accuracy: 0.4653 - val_loss: 0.0742 - val_accuracy: 0.4493\n",
      "Epoch 94/120\n",
      " - 24s - loss: 0.0716 - accuracy: 0.4693 - val_loss: 0.0727 - val_accuracy: 0.4515\n",
      "Epoch 95/120\n",
      " - 24s - loss: 0.0716 - accuracy: 0.4714 - val_loss: 0.0722 - val_accuracy: 0.4641\n",
      "Epoch 96/120\n",
      " - 24s - loss: 0.0718 - accuracy: 0.4693 - val_loss: 0.0717 - val_accuracy: 0.4667\n",
      "Epoch 97/120\n",
      " - 24s - loss: 0.0728 - accuracy: 0.4643 - val_loss: 0.0725 - val_accuracy: 0.4585\n",
      "Epoch 98/120\n",
      " - 24s - loss: 0.0714 - accuracy: 0.4726 - val_loss: 0.0744 - val_accuracy: 0.4354\n",
      "Epoch 99/120\n",
      " - 24s - loss: 0.0716 - accuracy: 0.4682 - val_loss: 0.0733 - val_accuracy: 0.4367\n",
      "Epoch 100/120\n",
      " - 24s - loss: 0.0731 - accuracy: 0.4599 - val_loss: 0.0756 - val_accuracy: 0.4345\n",
      "Epoch 101/120\n",
      " - 24s - loss: 0.0712 - accuracy: 0.4732 - val_loss: 0.0738 - val_accuracy: 0.4389\n",
      "Epoch 102/120\n",
      " - 24s - loss: 0.0714 - accuracy: 0.4706 - val_loss: 0.0738 - val_accuracy: 0.4554\n",
      "Epoch 103/120\n",
      " - 25s - loss: 0.0715 - accuracy: 0.4732 - val_loss: 0.0727 - val_accuracy: 0.4563\n",
      "Epoch 104/120\n",
      " - 23s - loss: 0.0715 - accuracy: 0.4739 - val_loss: 0.0743 - val_accuracy: 0.4419\n",
      "Epoch 105/120\n",
      " - 24s - loss: 0.0712 - accuracy: 0.4747 - val_loss: 0.0732 - val_accuracy: 0.4541\n",
      "Epoch 106/120\n",
      " - 24s - loss: 0.0709 - accuracy: 0.4769 - val_loss: 0.0726 - val_accuracy: 0.4572\n",
      "Epoch 107/120\n",
      " - 23s - loss: 0.0712 - accuracy: 0.4734 - val_loss: 0.0728 - val_accuracy: 0.4515\n",
      "Epoch 108/120\n",
      " - 24s - loss: 0.0710 - accuracy: 0.4801 - val_loss: 0.0765 - val_accuracy: 0.4411\n",
      "Epoch 109/120\n",
      " - 25s - loss: 0.0713 - accuracy: 0.4817 - val_loss: 0.0724 - val_accuracy: 0.4619\n",
      "Epoch 110/120\n",
      " - 24s - loss: 0.0711 - accuracy: 0.4778 - val_loss: 0.0732 - val_accuracy: 0.4550\n",
      "Epoch 111/120\n",
      " - 25s - loss: 0.0711 - accuracy: 0.4791 - val_loss: 0.0735 - val_accuracy: 0.4463\n",
      "Epoch 112/120\n",
      " - 24s - loss: 0.0710 - accuracy: 0.4788 - val_loss: 0.0732 - val_accuracy: 0.4463\n",
      "Epoch 113/120\n",
      " - 24s - loss: 0.0709 - accuracy: 0.4794 - val_loss: 0.0749 - val_accuracy: 0.4398\n",
      "Epoch 114/120\n",
      " - 23s - loss: 0.0711 - accuracy: 0.4810 - val_loss: 0.0755 - val_accuracy: 0.4467\n",
      "Epoch 115/120\n",
      " - 23s - loss: 0.0712 - accuracy: 0.4781 - val_loss: 0.0727 - val_accuracy: 0.4650\n",
      "Epoch 116/120\n",
      " - 23s - loss: 0.0711 - accuracy: 0.4799 - val_loss: 0.0726 - val_accuracy: 0.4628\n",
      "Epoch 117/120\n",
      " - 23s - loss: 0.0707 - accuracy: 0.4837 - val_loss: 0.0753 - val_accuracy: 0.4358\n",
      "Epoch 118/120\n",
      " - 22s - loss: 0.0707 - accuracy: 0.4783 - val_loss: 0.0738 - val_accuracy: 0.4428\n",
      "Epoch 119/120\n",
      " - 23s - loss: 0.0713 - accuracy: 0.4788 - val_loss: 0.0736 - val_accuracy: 0.4485\n",
      "Epoch 120/120\n",
      " - 24s - loss: 0.0709 - accuracy: 0.4834 - val_loss: 0.0742 - val_accuracy: 0.4441\n",
      "Train on 20691 samples, validate on 2299 samples\n",
      "Epoch 1/120\n",
      " - 24s - loss: 0.3692 - accuracy: 0.0985 - val_loss: 0.1952 - val_accuracy: 0.1000\n",
      "Epoch 2/120\n",
      " - 25s - loss: 0.1890 - accuracy: 0.1014 - val_loss: 0.1879 - val_accuracy: 0.1000\n",
      "Epoch 3/120\n",
      " - 25s - loss: 0.1937 - accuracy: 0.1019 - val_loss: 0.1932 - val_accuracy: 0.1000\n",
      "Epoch 4/120\n",
      " - 24s - loss: 0.1965 - accuracy: 0.1013 - val_loss: 0.2001 - val_accuracy: 0.0996\n",
      "Epoch 5/120\n",
      " - 24s - loss: 0.1968 - accuracy: 0.0984 - val_loss: 0.1937 - val_accuracy: 0.1000\n",
      "Epoch 6/120\n",
      " - 24s - loss: 0.1911 - accuracy: 0.0957 - val_loss: 0.1915 - val_accuracy: 0.0996\n",
      "Epoch 7/120\n",
      " - 24s - loss: 0.1894 - accuracy: 0.0974 - val_loss: 0.1858 - val_accuracy: 0.1000\n",
      "Epoch 8/120\n",
      " - 23s - loss: 0.1898 - accuracy: 0.1020 - val_loss: 0.1905 - val_accuracy: 0.1000\n",
      "Epoch 9/120\n",
      " - 24s - loss: 0.1917 - accuracy: 0.0975 - val_loss: 0.1972 - val_accuracy: 0.0996\n",
      "Epoch 10/120\n",
      " - 24s - loss: 0.1845 - accuracy: 0.0989 - val_loss: 0.0946 - val_accuracy: 0.1923\n",
      "Epoch 11/120\n",
      " - 25s - loss: 0.0936 - accuracy: 0.2322 - val_loss: 0.0914 - val_accuracy: 0.2710\n",
      "Epoch 12/120\n",
      " - 23s - loss: 0.0868 - accuracy: 0.2771 - val_loss: 0.0863 - val_accuracy: 0.2953\n",
      "Epoch 13/120\n",
      " - 23s - loss: 0.0875 - accuracy: 0.2746 - val_loss: 0.0836 - val_accuracy: 0.3245\n",
      "Epoch 14/120\n",
      " - 23s - loss: 0.0893 - accuracy: 0.2708 - val_loss: 0.0855 - val_accuracy: 0.3027\n",
      "Epoch 15/120\n",
      " - 25s - loss: 0.0851 - accuracy: 0.2973 - val_loss: 0.0827 - val_accuracy: 0.3428\n",
      "Epoch 16/120\n",
      " - 25s - loss: 0.0818 - accuracy: 0.3155 - val_loss: 0.0823 - val_accuracy: 0.3045\n",
      "Epoch 17/120\n",
      " - 24s - loss: 0.0819 - accuracy: 0.3259 - val_loss: 0.0796 - val_accuracy: 0.3684\n",
      "Epoch 18/120\n",
      " - 23s - loss: 0.0805 - accuracy: 0.3522 - val_loss: 0.0870 - val_accuracy: 0.3667\n",
      "Epoch 19/120\n",
      " - 25s - loss: 0.0798 - accuracy: 0.3604 - val_loss: 0.0779 - val_accuracy: 0.3841\n",
      "Epoch 20/120\n",
      " - 24s - loss: 0.0829 - accuracy: 0.3507 - val_loss: 0.0795 - val_accuracy: 0.4015\n",
      "Epoch 21/120\n",
      " - 25s - loss: 0.0785 - accuracy: 0.3822 - val_loss: 0.0764 - val_accuracy: 0.4063\n",
      "Epoch 22/120\n",
      " - 23s - loss: 0.0779 - accuracy: 0.3838 - val_loss: 0.0782 - val_accuracy: 0.3667\n",
      "Epoch 23/120\n",
      " - 25s - loss: 0.0780 - accuracy: 0.3883 - val_loss: 0.0828 - val_accuracy: 0.3227\n",
      "Epoch 24/120\n",
      " - 23s - loss: 0.0777 - accuracy: 0.3899 - val_loss: 0.0750 - val_accuracy: 0.4211\n",
      "Epoch 25/120\n",
      " - 24s - loss: 0.0801 - accuracy: 0.3906 - val_loss: 0.0770 - val_accuracy: 0.4163\n",
      "Epoch 26/120\n",
      " - 23s - loss: 0.0769 - accuracy: 0.3984 - val_loss: 0.0750 - val_accuracy: 0.4280\n",
      "Epoch 27/120\n",
      " - 23s - loss: 0.0766 - accuracy: 0.3995 - val_loss: 0.0755 - val_accuracy: 0.4267\n",
      "Epoch 28/120\n",
      " - 24s - loss: 0.0760 - accuracy: 0.4079 - val_loss: 0.0746 - val_accuracy: 0.4341\n",
      "Epoch 29/120\n",
      " - 24s - loss: 0.0763 - accuracy: 0.4112 - val_loss: 0.0754 - val_accuracy: 0.4189\n",
      "Epoch 30/120\n",
      " - 24s - loss: 0.0760 - accuracy: 0.4065 - val_loss: 0.0776 - val_accuracy: 0.3763\n",
      "Epoch 31/120\n",
      " - 24s - loss: 0.0759 - accuracy: 0.4122 - val_loss: 0.0733 - val_accuracy: 0.4324\n",
      "Epoch 32/120\n",
      " - 23s - loss: 0.0754 - accuracy: 0.4218 - val_loss: 0.0738 - val_accuracy: 0.4545\n",
      "Epoch 33/120\n",
      " - 24s - loss: 0.0754 - accuracy: 0.4215 - val_loss: 0.0736 - val_accuracy: 0.4424\n",
      "Epoch 34/120\n",
      " - 24s - loss: 0.0752 - accuracy: 0.4213 - val_loss: 0.0742 - val_accuracy: 0.4411\n",
      "Epoch 35/120\n",
      " - 23s - loss: 0.0749 - accuracy: 0.4244 - val_loss: 0.0737 - val_accuracy: 0.4380\n",
      "Epoch 36/120\n",
      " - 24s - loss: 0.0756 - accuracy: 0.4209 - val_loss: 0.0741 - val_accuracy: 0.4445\n",
      "Epoch 37/120\n",
      " - 24s - loss: 0.0747 - accuracy: 0.4241 - val_loss: 0.0756 - val_accuracy: 0.4102\n",
      "Epoch 38/120\n",
      " - 25s - loss: 0.0748 - accuracy: 0.4300 - val_loss: 0.0743 - val_accuracy: 0.4302\n",
      "Epoch 39/120\n",
      " - 24s - loss: 0.0745 - accuracy: 0.4304 - val_loss: 0.0751 - val_accuracy: 0.4124\n",
      "Epoch 40/120\n",
      " - 24s - loss: 0.0742 - accuracy: 0.4305 - val_loss: 0.0727 - val_accuracy: 0.4515\n",
      "Epoch 41/120\n",
      " - 24s - loss: 0.0748 - accuracy: 0.4237 - val_loss: 0.0746 - val_accuracy: 0.4354\n",
      "Epoch 42/120\n",
      " - 23s - loss: 0.0744 - accuracy: 0.4285 - val_loss: 0.0727 - val_accuracy: 0.4559\n",
      "Epoch 43/120\n",
      " - 23s - loss: 0.0739 - accuracy: 0.4362 - val_loss: 0.0765 - val_accuracy: 0.4232\n",
      "Epoch 44/120\n",
      " - 24s - loss: 0.0745 - accuracy: 0.4350 - val_loss: 0.0720 - val_accuracy: 0.4515\n",
      "Epoch 45/120\n",
      " - 24s - loss: 0.0745 - accuracy: 0.4296 - val_loss: 0.0795 - val_accuracy: 0.4406\n",
      "Epoch 46/120\n",
      " - 24s - loss: 0.0740 - accuracy: 0.4414 - val_loss: 0.0721 - val_accuracy: 0.4519\n",
      "Epoch 47/120\n",
      " - 23s - loss: 0.0738 - accuracy: 0.4431 - val_loss: 0.0738 - val_accuracy: 0.4276\n",
      "Epoch 48/120\n",
      " - 24s - loss: 0.0739 - accuracy: 0.4366 - val_loss: 0.0715 - val_accuracy: 0.4685\n",
      "Epoch 49/120\n",
      " - 25s - loss: 0.0735 - accuracy: 0.4390 - val_loss: 0.0738 - val_accuracy: 0.4550\n",
      "Epoch 50/120\n",
      " - 26s - loss: 0.0737 - accuracy: 0.4441 - val_loss: 0.0829 - val_accuracy: 0.4206\n",
      "Epoch 51/120\n",
      " - 25s - loss: 0.0740 - accuracy: 0.4431 - val_loss: 0.0725 - val_accuracy: 0.4498\n",
      "Epoch 52/120\n",
      " - 24s - loss: 0.0741 - accuracy: 0.4373 - val_loss: 0.0728 - val_accuracy: 0.4537\n",
      "Epoch 53/120\n",
      " - 24s - loss: 0.0733 - accuracy: 0.4467 - val_loss: 0.0737 - val_accuracy: 0.4454\n",
      "Epoch 54/120\n",
      " - 25s - loss: 0.0735 - accuracy: 0.4435 - val_loss: 0.0740 - val_accuracy: 0.4406\n",
      "Epoch 55/120\n",
      " - 25s - loss: 0.0736 - accuracy: 0.4446 - val_loss: 0.0713 - val_accuracy: 0.4563\n",
      "Epoch 56/120\n",
      " - 23s - loss: 0.0730 - accuracy: 0.4482 - val_loss: 0.0738 - val_accuracy: 0.4298\n",
      "Epoch 57/120\n",
      " - 25s - loss: 0.0741 - accuracy: 0.4429 - val_loss: 0.0715 - val_accuracy: 0.4624\n",
      "Epoch 58/120\n",
      " - 25s - loss: 0.0729 - accuracy: 0.4471 - val_loss: 0.0739 - val_accuracy: 0.4298\n",
      "Epoch 59/120\n",
      " - 24s - loss: 0.0737 - accuracy: 0.4456 - val_loss: 0.0726 - val_accuracy: 0.4659\n",
      "Epoch 60/120\n",
      " - 24s - loss: 0.0729 - accuracy: 0.4547 - val_loss: 0.0741 - val_accuracy: 0.4432\n",
      "Epoch 61/120\n",
      " - 25s - loss: 0.0728 - accuracy: 0.4524 - val_loss: 0.0718 - val_accuracy: 0.4567\n",
      "Epoch 62/120\n",
      " - 24s - loss: 0.0728 - accuracy: 0.4546 - val_loss: 0.0737 - val_accuracy: 0.4345\n",
      "Epoch 63/120\n",
      " - 24s - loss: 0.0730 - accuracy: 0.4520 - val_loss: 0.0745 - val_accuracy: 0.4358\n",
      "Epoch 64/120\n",
      " - 24s - loss: 0.0730 - accuracy: 0.4503 - val_loss: 0.0724 - val_accuracy: 0.4498\n",
      "Epoch 65/120\n",
      " - 24s - loss: 0.0728 - accuracy: 0.4517 - val_loss: 0.0722 - val_accuracy: 0.4545\n",
      "Epoch 66/120\n",
      " - 24s - loss: 0.0727 - accuracy: 0.4498 - val_loss: 0.0733 - val_accuracy: 0.4502\n",
      "Epoch 67/120\n",
      " - 24s - loss: 0.0727 - accuracy: 0.4549 - val_loss: 0.0723 - val_accuracy: 0.4580\n",
      "Epoch 68/120\n",
      " - 24s - loss: 0.0725 - accuracy: 0.4587 - val_loss: 0.0730 - val_accuracy: 0.4567\n",
      "Epoch 69/120\n",
      " - 25s - loss: 0.0725 - accuracy: 0.4576 - val_loss: 0.0714 - val_accuracy: 0.4632\n",
      "Epoch 70/120\n",
      " - 23s - loss: 0.0724 - accuracy: 0.4579 - val_loss: 0.0722 - val_accuracy: 0.4432\n",
      "Epoch 71/120\n",
      " - 25s - loss: 0.0725 - accuracy: 0.4558 - val_loss: 0.0726 - val_accuracy: 0.4580\n",
      "Epoch 72/120\n",
      " - 25s - loss: 0.0725 - accuracy: 0.4540 - val_loss: 0.0754 - val_accuracy: 0.4319\n",
      "Epoch 73/120\n",
      " - 25s - loss: 0.0724 - accuracy: 0.4548 - val_loss: 0.0717 - val_accuracy: 0.4615\n",
      "Epoch 74/120\n",
      " - 25s - loss: 0.0720 - accuracy: 0.4615 - val_loss: 0.0761 - val_accuracy: 0.4197\n",
      "Epoch 75/120\n",
      " - 25s - loss: 0.0721 - accuracy: 0.4599 - val_loss: 0.0736 - val_accuracy: 0.4454\n",
      "Epoch 76/120\n",
      " - 24s - loss: 0.0722 - accuracy: 0.4620 - val_loss: 0.0751 - val_accuracy: 0.4367\n",
      "Epoch 77/120\n",
      " - 25s - loss: 0.0718 - accuracy: 0.4622 - val_loss: 0.0746 - val_accuracy: 0.4293\n",
      "Epoch 78/120\n",
      " - 23s - loss: 0.0722 - accuracy: 0.4618 - val_loss: 0.0725 - val_accuracy: 0.4632\n",
      "Epoch 79/120\n",
      " - 24s - loss: 0.0717 - accuracy: 0.4659 - val_loss: 0.0756 - val_accuracy: 0.4358\n",
      "Epoch 80/120\n",
      " - 24s - loss: 0.0721 - accuracy: 0.4641 - val_loss: 0.0741 - val_accuracy: 0.4515\n",
      "Epoch 81/120\n",
      " - 24s - loss: 0.0716 - accuracy: 0.4626 - val_loss: 0.0731 - val_accuracy: 0.4524\n",
      "Epoch 82/120\n",
      " - 24s - loss: 0.0724 - accuracy: 0.4576 - val_loss: 0.0722 - val_accuracy: 0.4693\n",
      "Epoch 83/120\n",
      " - 23s - loss: 0.0714 - accuracy: 0.4663 - val_loss: 0.0713 - val_accuracy: 0.4802\n",
      "Epoch 84/120\n",
      " - 23s - loss: 0.0719 - accuracy: 0.4652 - val_loss: 0.0722 - val_accuracy: 0.4559\n",
      "Epoch 85/120\n",
      " - 23s - loss: 0.0717 - accuracy: 0.4646 - val_loss: 0.0716 - val_accuracy: 0.4611\n",
      "Epoch 86/120\n",
      " - 24s - loss: 0.0718 - accuracy: 0.4586 - val_loss: 0.0735 - val_accuracy: 0.4563\n",
      "Epoch 87/120\n",
      " - 24s - loss: 0.0716 - accuracy: 0.4655 - val_loss: 0.0742 - val_accuracy: 0.4576\n",
      "Epoch 88/120\n",
      " - 23s - loss: 0.0721 - accuracy: 0.4650 - val_loss: 0.0735 - val_accuracy: 0.4324\n",
      "Epoch 89/120\n",
      " - 24s - loss: 0.0717 - accuracy: 0.4655 - val_loss: 0.0731 - val_accuracy: 0.4489\n",
      "Epoch 90/120\n",
      " - 23s - loss: 0.0717 - accuracy: 0.4662 - val_loss: 0.0731 - val_accuracy: 0.4498\n",
      "Epoch 91/120\n",
      " - 24s - loss: 0.0711 - accuracy: 0.4705 - val_loss: 0.0734 - val_accuracy: 0.4554\n",
      "Epoch 92/120\n",
      " - 23s - loss: 0.0714 - accuracy: 0.4672 - val_loss: 0.0751 - val_accuracy: 0.4432\n",
      "Epoch 93/120\n",
      " - 23s - loss: 0.0721 - accuracy: 0.4638 - val_loss: 0.0718 - val_accuracy: 0.4545\n",
      "Epoch 94/120\n",
      " - 24s - loss: 0.0712 - accuracy: 0.4728 - val_loss: 0.0712 - val_accuracy: 0.4628\n",
      "Epoch 95/120\n",
      " - 22s - loss: 0.0713 - accuracy: 0.4702 - val_loss: 0.0737 - val_accuracy: 0.4580\n",
      "Epoch 96/120\n",
      " - 23s - loss: 0.0710 - accuracy: 0.4738 - val_loss: 0.0724 - val_accuracy: 0.4580\n",
      "Epoch 97/120\n",
      " - 24s - loss: 0.0713 - accuracy: 0.4673 - val_loss: 0.0720 - val_accuracy: 0.4650\n",
      "Epoch 98/120\n",
      " - 23s - loss: 0.0711 - accuracy: 0.4703 - val_loss: 0.0715 - val_accuracy: 0.4846\n",
      "Epoch 99/120\n",
      " - 24s - loss: 0.0708 - accuracy: 0.4763 - val_loss: 0.0748 - val_accuracy: 0.4176\n",
      "Epoch 100/120\n",
      " - 24s - loss: 0.0720 - accuracy: 0.4697 - val_loss: 0.0737 - val_accuracy: 0.4541\n",
      "Epoch 101/120\n",
      " - 24s - loss: 0.0705 - accuracy: 0.4772 - val_loss: 0.0748 - val_accuracy: 0.4332\n",
      "Epoch 102/120\n",
      " - 25s - loss: 0.0713 - accuracy: 0.4746 - val_loss: 0.0715 - val_accuracy: 0.4741\n",
      "Epoch 103/120\n",
      " - 24s - loss: 0.0709 - accuracy: 0.4730 - val_loss: 0.0733 - val_accuracy: 0.4437\n",
      "Epoch 104/120\n",
      " - 23s - loss: 0.0712 - accuracy: 0.4689 - val_loss: 0.0718 - val_accuracy: 0.4663\n",
      "Epoch 105/120\n",
      " - 24s - loss: 0.0707 - accuracy: 0.4776 - val_loss: 0.0729 - val_accuracy: 0.4415\n",
      "Epoch 106/120\n",
      " - 24s - loss: 0.0711 - accuracy: 0.4746 - val_loss: 0.0713 - val_accuracy: 0.4663\n",
      "Epoch 107/120\n",
      " - 24s - loss: 0.0709 - accuracy: 0.4727 - val_loss: 0.0766 - val_accuracy: 0.4211\n",
      "Epoch 108/120\n",
      " - 24s - loss: 0.0708 - accuracy: 0.4771 - val_loss: 0.0719 - val_accuracy: 0.4615\n",
      "Epoch 109/120\n",
      " - 24s - loss: 0.0708 - accuracy: 0.4733 - val_loss: 0.0722 - val_accuracy: 0.4645\n",
      "Epoch 110/120\n",
      " - 25s - loss: 0.0705 - accuracy: 0.4817 - val_loss: 0.0730 - val_accuracy: 0.4632\n",
      "Epoch 111/120\n",
      " - 24s - loss: 0.0708 - accuracy: 0.4790 - val_loss: 0.0725 - val_accuracy: 0.4754\n",
      "Epoch 112/120\n",
      " - 24s - loss: 0.0708 - accuracy: 0.4769 - val_loss: 0.0725 - val_accuracy: 0.4437\n",
      "Epoch 113/120\n",
      " - 24s - loss: 0.0706 - accuracy: 0.4782 - val_loss: 0.0722 - val_accuracy: 0.4698\n",
      "Epoch 114/120\n",
      " - 25s - loss: 0.0705 - accuracy: 0.4770 - val_loss: 0.0721 - val_accuracy: 0.4650\n",
      "Epoch 115/120\n",
      " - 23s - loss: 0.0703 - accuracy: 0.4829 - val_loss: 0.0735 - val_accuracy: 0.4415\n",
      "Epoch 116/120\n",
      " - 25s - loss: 0.0711 - accuracy: 0.4756 - val_loss: 0.0726 - val_accuracy: 0.4576\n",
      "Epoch 117/120\n",
      " - 24s - loss: 0.0704 - accuracy: 0.4852 - val_loss: 0.0746 - val_accuracy: 0.4537\n",
      "Epoch 118/120\n",
      " - 24s - loss: 0.0713 - accuracy: 0.4737 - val_loss: 0.0749 - val_accuracy: 0.4467\n",
      "Epoch 119/120\n",
      " - 24s - loss: 0.0702 - accuracy: 0.4813 - val_loss: 0.0761 - val_accuracy: 0.4215\n",
      "Epoch 120/120\n",
      " - 24s - loss: 0.0709 - accuracy: 0.4760 - val_loss: 0.0729 - val_accuracy: 0.4563\n",
      "Train on 20691 samples, validate on 2299 samples\n",
      "Epoch 1/120\n",
      " - 24s - loss: 0.3782 - accuracy: 0.1011 - val_loss: 0.1961 - val_accuracy: 0.1000\n",
      "Epoch 2/120\n",
      " - 23s - loss: 0.1910 - accuracy: 0.0979 - val_loss: 0.1908 - val_accuracy: 0.0996\n",
      "Epoch 3/120\n",
      " - 23s - loss: 0.1920 - accuracy: 0.1019 - val_loss: 0.1934 - val_accuracy: 0.1000\n",
      "Epoch 4/120\n",
      " - 23s - loss: 0.1704 - accuracy: 0.1149 - val_loss: 0.0919 - val_accuracy: 0.2275\n",
      "Epoch 5/120\n",
      " - 23s - loss: 0.0870 - accuracy: 0.2607 - val_loss: 0.0836 - val_accuracy: 0.3110\n",
      "Epoch 6/120\n",
      " - 23s - loss: 0.0862 - accuracy: 0.2995 - val_loss: 0.0817 - val_accuracy: 0.3306\n",
      "Epoch 7/120\n",
      " - 22s - loss: 0.0837 - accuracy: 0.3268 - val_loss: 0.0803 - val_accuracy: 0.3684\n",
      "Epoch 8/120\n",
      " - 23s - loss: 0.0810 - accuracy: 0.3535 - val_loss: 0.0792 - val_accuracy: 0.3906\n",
      "Epoch 9/120\n",
      " - 23s - loss: 0.0806 - accuracy: 0.3638 - val_loss: 0.0805 - val_accuracy: 0.3697\n",
      "Epoch 10/120\n",
      " - 23s - loss: 0.0815 - accuracy: 0.3685 - val_loss: 0.0815 - val_accuracy: 0.3841\n",
      "Epoch 11/120\n",
      " - 23s - loss: 0.0791 - accuracy: 0.3885 - val_loss: 0.0825 - val_accuracy: 0.3723\n",
      "Epoch 12/120\n",
      " - 23s - loss: 0.0783 - accuracy: 0.3934 - val_loss: 0.0781 - val_accuracy: 0.4045\n",
      "Epoch 13/120\n",
      " - 23s - loss: 0.0783 - accuracy: 0.3957 - val_loss: 0.0770 - val_accuracy: 0.4245\n",
      "Epoch 14/120\n",
      " - 23s - loss: 0.0773 - accuracy: 0.3994 - val_loss: 0.0777 - val_accuracy: 0.4180\n",
      "Epoch 15/120\n",
      " - 23s - loss: 0.0768 - accuracy: 0.4062 - val_loss: 0.0759 - val_accuracy: 0.4180\n",
      "Epoch 16/120\n",
      " - 24s - loss: 0.0764 - accuracy: 0.4109 - val_loss: 0.0756 - val_accuracy: 0.4354\n",
      "Epoch 17/120\n",
      " - 23s - loss: 0.0763 - accuracy: 0.4166 - val_loss: 0.0749 - val_accuracy: 0.4197\n",
      "Epoch 18/120\n",
      " - 24s - loss: 0.0759 - accuracy: 0.4241 - val_loss: 0.0794 - val_accuracy: 0.4037\n",
      "Epoch 19/120\n",
      " - 23s - loss: 0.0760 - accuracy: 0.4181 - val_loss: 0.0769 - val_accuracy: 0.4254\n",
      "Epoch 20/120\n",
      " - 23s - loss: 0.0750 - accuracy: 0.4268 - val_loss: 0.0779 - val_accuracy: 0.4023\n",
      "Epoch 21/120\n",
      " - 24s - loss: 0.0749 - accuracy: 0.4287 - val_loss: 0.0762 - val_accuracy: 0.4193\n",
      "Epoch 22/120\n",
      " - 23s - loss: 0.0763 - accuracy: 0.4258 - val_loss: 0.0771 - val_accuracy: 0.4315\n",
      "Epoch 23/120\n",
      " - 23s - loss: 0.0746 - accuracy: 0.4397 - val_loss: 0.0738 - val_accuracy: 0.4402\n",
      "Epoch 24/120\n",
      " - 23s - loss: 0.0744 - accuracy: 0.4348 - val_loss: 0.0783 - val_accuracy: 0.3971\n",
      "Epoch 25/120\n",
      " - 23s - loss: 0.0745 - accuracy: 0.4353 - val_loss: 0.0750 - val_accuracy: 0.4219\n",
      "Epoch 26/120\n",
      " - 22s - loss: 0.0743 - accuracy: 0.4376 - val_loss: 0.0769 - val_accuracy: 0.4180\n",
      "Epoch 27/120\n",
      " - 22s - loss: 0.0739 - accuracy: 0.4418 - val_loss: 0.0775 - val_accuracy: 0.4211\n",
      "Epoch 28/120\n",
      " - 22s - loss: 0.0742 - accuracy: 0.4422 - val_loss: 0.0739 - val_accuracy: 0.4393\n",
      "Epoch 29/120\n",
      " - 22s - loss: 0.0739 - accuracy: 0.4435 - val_loss: 0.0759 - val_accuracy: 0.4167\n",
      "Epoch 30/120\n",
      " - 22s - loss: 0.0739 - accuracy: 0.4429 - val_loss: 0.0769 - val_accuracy: 0.4132\n",
      "Epoch 31/120\n",
      " - 22s - loss: 0.0738 - accuracy: 0.4415 - val_loss: 0.0729 - val_accuracy: 0.4441\n",
      "Epoch 32/120\n",
      " - 22s - loss: 0.0736 - accuracy: 0.4458 - val_loss: 0.0762 - val_accuracy: 0.4150\n",
      "Epoch 33/120\n",
      " - 22s - loss: 0.0734 - accuracy: 0.4481 - val_loss: 0.0743 - val_accuracy: 0.4406\n",
      "Epoch 34/120\n",
      " - 23s - loss: 0.0733 - accuracy: 0.4471 - val_loss: 0.0784 - val_accuracy: 0.3863\n",
      "Epoch 35/120\n",
      " - 24s - loss: 0.0734 - accuracy: 0.4500 - val_loss: 0.0740 - val_accuracy: 0.4354\n",
      "Epoch 36/120\n",
      " - 24s - loss: 0.0731 - accuracy: 0.4502 - val_loss: 0.0747 - val_accuracy: 0.4385\n",
      "Epoch 37/120\n",
      " - 23s - loss: 0.0732 - accuracy: 0.4495 - val_loss: 0.0761 - val_accuracy: 0.4124\n",
      "Epoch 38/120\n",
      " - 24s - loss: 0.0731 - accuracy: 0.4522 - val_loss: 0.0741 - val_accuracy: 0.4315\n",
      "Epoch 39/120\n",
      " - 24s - loss: 0.0732 - accuracy: 0.4515 - val_loss: 0.0731 - val_accuracy: 0.4498\n",
      "Epoch 40/120\n",
      " - 23s - loss: 0.0731 - accuracy: 0.4520 - val_loss: 0.0737 - val_accuracy: 0.4367\n",
      "Epoch 41/120\n",
      " - 24s - loss: 0.0730 - accuracy: 0.4534 - val_loss: 0.0748 - val_accuracy: 0.4358\n",
      "Epoch 42/120\n",
      " - 23s - loss: 0.0729 - accuracy: 0.4567 - val_loss: 0.0759 - val_accuracy: 0.4197\n",
      "Epoch 43/120\n",
      " - 23s - loss: 0.0727 - accuracy: 0.4568 - val_loss: 0.0822 - val_accuracy: 0.3997\n",
      "Epoch 44/120\n",
      " - 23s - loss: 0.0729 - accuracy: 0.4517 - val_loss: 0.0770 - val_accuracy: 0.4089\n",
      "Epoch 45/120\n",
      " - 23s - loss: 0.0723 - accuracy: 0.4628 - val_loss: 0.0760 - val_accuracy: 0.4271\n",
      "Epoch 46/120\n",
      " - 22s - loss: 0.0728 - accuracy: 0.4528 - val_loss: 0.0751 - val_accuracy: 0.4215\n",
      "Epoch 47/120\n",
      " - 23s - loss: 0.0726 - accuracy: 0.4585 - val_loss: 0.0750 - val_accuracy: 0.4624\n",
      "Epoch 48/120\n",
      " - 24s - loss: 0.0724 - accuracy: 0.4612 - val_loss: 0.0745 - val_accuracy: 0.4276\n",
      "Epoch 49/120\n",
      " - 24s - loss: 0.0720 - accuracy: 0.4627 - val_loss: 0.0755 - val_accuracy: 0.4337\n",
      "Epoch 50/120\n",
      " - 23s - loss: 0.0722 - accuracy: 0.4622 - val_loss: 0.0743 - val_accuracy: 0.4445\n",
      "Epoch 51/120\n",
      " - 24s - loss: 0.0721 - accuracy: 0.4638 - val_loss: 0.0750 - val_accuracy: 0.4345\n",
      "Epoch 52/120\n",
      " - 26s - loss: 0.0720 - accuracy: 0.4680 - val_loss: 0.0747 - val_accuracy: 0.4398\n",
      "Epoch 53/120\n",
      " - 28s - loss: 0.0720 - accuracy: 0.4636 - val_loss: 0.0809 - val_accuracy: 0.4145\n",
      "Epoch 54/120\n",
      " - 28s - loss: 0.0720 - accuracy: 0.4646 - val_loss: 0.0748 - val_accuracy: 0.4328\n",
      "Epoch 55/120\n",
      " - 25s - loss: 0.0720 - accuracy: 0.4680 - val_loss: 0.0752 - val_accuracy: 0.4380\n",
      "Epoch 56/120\n",
      " - 23s - loss: 0.0716 - accuracy: 0.4659 - val_loss: 0.0735 - val_accuracy: 0.4432\n",
      "Epoch 57/120\n",
      " - 24s - loss: 0.0716 - accuracy: 0.4674 - val_loss: 0.0759 - val_accuracy: 0.4354\n",
      "Epoch 58/120\n",
      " - 22s - loss: 0.0719 - accuracy: 0.4674 - val_loss: 0.0748 - val_accuracy: 0.4350\n",
      "Epoch 59/120\n",
      " - 23s - loss: 0.0718 - accuracy: 0.4701 - val_loss: 0.0760 - val_accuracy: 0.4306\n",
      "Epoch 60/120\n",
      " - 23s - loss: 0.0711 - accuracy: 0.4744 - val_loss: 0.0785 - val_accuracy: 0.4202\n",
      "Epoch 61/120\n",
      " - 23s - loss: 0.0720 - accuracy: 0.4661 - val_loss: 0.0778 - val_accuracy: 0.4128\n",
      "Epoch 62/120\n",
      " - 23s - loss: 0.0711 - accuracy: 0.4737 - val_loss: 0.0730 - val_accuracy: 0.4493\n",
      "Epoch 63/120\n",
      " - 22s - loss: 0.0715 - accuracy: 0.4704 - val_loss: 0.0746 - val_accuracy: 0.4524\n",
      "Epoch 64/120\n",
      " - 22s - loss: 0.0710 - accuracy: 0.4763 - val_loss: 0.0754 - val_accuracy: 0.4354\n",
      "Epoch 65/120\n",
      " - 23s - loss: 0.0716 - accuracy: 0.4741 - val_loss: 0.0743 - val_accuracy: 0.4532\n",
      "Epoch 66/120\n",
      " - 23s - loss: 0.0710 - accuracy: 0.4782 - val_loss: 0.0764 - val_accuracy: 0.4406\n",
      "Epoch 67/120\n",
      " - 23s - loss: 0.0712 - accuracy: 0.4757 - val_loss: 0.0757 - val_accuracy: 0.4419\n",
      "Epoch 68/120\n",
      " - 23s - loss: 0.0713 - accuracy: 0.4796 - val_loss: 0.0738 - val_accuracy: 0.4450\n",
      "Epoch 69/120\n",
      " - 23s - loss: 0.0710 - accuracy: 0.4804 - val_loss: 0.0740 - val_accuracy: 0.4585\n",
      "Epoch 70/120\n",
      " - 23s - loss: 0.0708 - accuracy: 0.4791 - val_loss: 0.0775 - val_accuracy: 0.4371\n",
      "Epoch 71/120\n",
      " - 22s - loss: 0.0710 - accuracy: 0.4788 - val_loss: 0.0745 - val_accuracy: 0.4284\n",
      "Epoch 72/120\n",
      " - 22s - loss: 0.0710 - accuracy: 0.4799 - val_loss: 0.0740 - val_accuracy: 0.4537\n",
      "Epoch 73/120\n",
      " - 21s - loss: 0.0705 - accuracy: 0.4844 - val_loss: 0.0743 - val_accuracy: 0.4424\n",
      "Epoch 74/120\n",
      " - 23s - loss: 0.0709 - accuracy: 0.4817 - val_loss: 0.0750 - val_accuracy: 0.4532\n",
      "Epoch 75/120\n",
      " - 23s - loss: 0.0710 - accuracy: 0.4789 - val_loss: 0.0804 - val_accuracy: 0.3915\n",
      "Epoch 76/120\n",
      " - 23s - loss: 0.0706 - accuracy: 0.4790 - val_loss: 0.0735 - val_accuracy: 0.4567\n",
      "Epoch 77/120\n",
      " - 22s - loss: 0.0704 - accuracy: 0.4882 - val_loss: 0.0751 - val_accuracy: 0.4371\n",
      "Epoch 78/120\n",
      " - 23s - loss: 0.0707 - accuracy: 0.4833 - val_loss: 0.0776 - val_accuracy: 0.4311\n",
      "Epoch 79/120\n",
      " - 23s - loss: 0.0704 - accuracy: 0.4877 - val_loss: 0.0742 - val_accuracy: 0.4450\n",
      "Epoch 80/120\n",
      " - 24s - loss: 0.0704 - accuracy: 0.4846 - val_loss: 0.0781 - val_accuracy: 0.4271\n",
      "Epoch 81/120\n",
      " - 24s - loss: 0.0705 - accuracy: 0.4839 - val_loss: 0.0754 - val_accuracy: 0.4302\n",
      "Epoch 82/120\n",
      " - 22s - loss: 0.0705 - accuracy: 0.4871 - val_loss: 0.0768 - val_accuracy: 0.4345\n",
      "Epoch 83/120\n",
      " - 23s - loss: 0.0706 - accuracy: 0.4832 - val_loss: 0.0752 - val_accuracy: 0.4402\n",
      "Epoch 84/120\n",
      " - 23s - loss: 0.0702 - accuracy: 0.4886 - val_loss: 0.0763 - val_accuracy: 0.4241\n",
      "Epoch 85/120\n",
      " - 24s - loss: 0.0704 - accuracy: 0.4848 - val_loss: 0.0731 - val_accuracy: 0.4585\n",
      "Epoch 86/120\n",
      " - 24s - loss: 0.0701 - accuracy: 0.4864 - val_loss: 0.0753 - val_accuracy: 0.4219\n",
      "Epoch 87/120\n",
      " - 24s - loss: 0.0702 - accuracy: 0.4900 - val_loss: 0.0758 - val_accuracy: 0.4389\n",
      "Epoch 88/120\n",
      " - 23s - loss: 0.0705 - accuracy: 0.4866 - val_loss: 0.0767 - val_accuracy: 0.4306\n",
      "Epoch 89/120\n",
      " - 24s - loss: 0.0700 - accuracy: 0.4910 - val_loss: 0.0789 - val_accuracy: 0.4093\n",
      "Epoch 90/120\n",
      " - 24s - loss: 0.0699 - accuracy: 0.4892 - val_loss: 0.0739 - val_accuracy: 0.4493\n",
      "Epoch 91/120\n",
      " - 24s - loss: 0.0701 - accuracy: 0.4870 - val_loss: 0.0751 - val_accuracy: 0.4502\n",
      "Epoch 92/120\n",
      " - 25s - loss: 0.0702 - accuracy: 0.4897 - val_loss: 0.0772 - val_accuracy: 0.4376\n",
      "Epoch 93/120\n",
      " - 25s - loss: 0.0699 - accuracy: 0.4929 - val_loss: 0.0748 - val_accuracy: 0.4515\n",
      "Epoch 94/120\n",
      " - 24s - loss: 0.0696 - accuracy: 0.4971 - val_loss: 0.0769 - val_accuracy: 0.4258\n",
      "Epoch 95/120\n",
      " - 24s - loss: 0.0695 - accuracy: 0.4979 - val_loss: 0.0778 - val_accuracy: 0.4245\n",
      "Epoch 96/120\n",
      " - 24s - loss: 0.0697 - accuracy: 0.4930 - val_loss: 0.0812 - val_accuracy: 0.4371\n",
      "Epoch 97/120\n",
      " - 24s - loss: 0.0693 - accuracy: 0.4998 - val_loss: 0.0761 - val_accuracy: 0.4567\n",
      "Epoch 98/120\n",
      " - 24s - loss: 0.0698 - accuracy: 0.4934 - val_loss: 0.0743 - val_accuracy: 0.4554\n",
      "Epoch 99/120\n",
      " - 24s - loss: 0.0698 - accuracy: 0.4997 - val_loss: 0.0744 - val_accuracy: 0.4350\n",
      "Epoch 100/120\n",
      " - 25s - loss: 0.0695 - accuracy: 0.4955 - val_loss: 0.0755 - val_accuracy: 0.4458\n",
      "Epoch 101/120\n",
      " - 24s - loss: 0.0695 - accuracy: 0.4964 - val_loss: 0.0751 - val_accuracy: 0.4393\n",
      "Epoch 102/120\n",
      " - 24s - loss: 0.0692 - accuracy: 0.4995 - val_loss: 0.0734 - val_accuracy: 0.4624\n",
      "Epoch 103/120\n",
      " - 25s - loss: 0.0693 - accuracy: 0.5001 - val_loss: 0.0751 - val_accuracy: 0.4454\n",
      "Epoch 104/120\n",
      " - 25s - loss: 0.0698 - accuracy: 0.4955 - val_loss: 0.0747 - val_accuracy: 0.4419\n",
      "Epoch 105/120\n",
      " - 24s - loss: 0.0692 - accuracy: 0.5030 - val_loss: 0.0748 - val_accuracy: 0.4537\n",
      "Epoch 106/120\n",
      " - 24s - loss: 0.0696 - accuracy: 0.4935 - val_loss: 0.0749 - val_accuracy: 0.4441\n",
      "Epoch 107/120\n",
      " - 25s - loss: 0.0690 - accuracy: 0.5019 - val_loss: 0.0746 - val_accuracy: 0.4528\n",
      "Epoch 108/120\n",
      " - 25s - loss: 0.0691 - accuracy: 0.5010 - val_loss: 0.0796 - val_accuracy: 0.4228\n",
      "Epoch 109/120\n",
      " - 25s - loss: 0.0692 - accuracy: 0.4991 - val_loss: 0.0755 - val_accuracy: 0.4563\n",
      "Epoch 110/120\n",
      " - 24s - loss: 0.0691 - accuracy: 0.5022 - val_loss: 0.0751 - val_accuracy: 0.4428\n",
      "Epoch 111/120\n",
      " - 24s - loss: 0.0691 - accuracy: 0.5009 - val_loss: 0.0762 - val_accuracy: 0.4398\n",
      "Epoch 112/120\n",
      " - 24s - loss: 0.0689 - accuracy: 0.5029 - val_loss: 0.0829 - val_accuracy: 0.3767\n",
      "Epoch 113/120\n",
      " - 25s - loss: 0.0691 - accuracy: 0.5045 - val_loss: 0.0773 - val_accuracy: 0.4389\n",
      "Epoch 114/120\n",
      " - 25s - loss: 0.0689 - accuracy: 0.5046 - val_loss: 0.0777 - val_accuracy: 0.4306\n",
      "Epoch 115/120\n",
      " - 25s - loss: 0.0688 - accuracy: 0.5032 - val_loss: 0.0766 - val_accuracy: 0.4385\n",
      "Epoch 116/120\n",
      " - 25s - loss: 0.0689 - accuracy: 0.5034 - val_loss: 0.0774 - val_accuracy: 0.4311\n",
      "Epoch 117/120\n",
      " - 25s - loss: 0.0689 - accuracy: 0.5039 - val_loss: 0.0758 - val_accuracy: 0.4467\n",
      "Epoch 118/120\n",
      " - 23s - loss: 0.0687 - accuracy: 0.5045 - val_loss: 0.0780 - val_accuracy: 0.4354\n",
      "Epoch 119/120\n",
      " - 24s - loss: 0.0688 - accuracy: 0.5076 - val_loss: 0.0815 - val_accuracy: 0.4184\n",
      "Epoch 120/120\n",
      " - 25s - loss: 0.0685 - accuracy: 0.5075 - val_loss: 0.0746 - val_accuracy: 0.4467\n",
      "Train on 20691 samples, validate on 2299 samples\n",
      "Epoch 1/120\n",
      " - 28s - loss: 0.3691 - accuracy: 0.0982 - val_loss: 0.1945 - val_accuracy: 0.1000\n",
      "Epoch 2/120\n",
      " - 27s - loss: 0.1933 - accuracy: 0.0981 - val_loss: 0.1934 - val_accuracy: 0.1000\n",
      "Epoch 3/120\n",
      " - 28s - loss: 0.1934 - accuracy: 0.1007 - val_loss: 0.1909 - val_accuracy: 0.1000\n",
      "Epoch 4/120\n",
      " - 27s - loss: 0.1926 - accuracy: 0.1013 - val_loss: 0.1963 - val_accuracy: 0.1000\n",
      "Epoch 5/120\n",
      " - 29s - loss: 0.1942 - accuracy: 0.0983 - val_loss: 0.1939 - val_accuracy: 0.0996\n",
      "Epoch 6/120\n",
      " - 30s - loss: 0.1954 - accuracy: 0.1001 - val_loss: 0.1977 - val_accuracy: 0.1000\n",
      "Epoch 7/120\n",
      " - 27s - loss: 0.1973 - accuracy: 0.1017 - val_loss: 0.1982 - val_accuracy: 0.1000\n",
      "Epoch 8/120\n",
      " - 27s - loss: 0.1966 - accuracy: 0.0995 - val_loss: 0.1981 - val_accuracy: 0.0996\n",
      "Epoch 9/120\n",
      " - 27s - loss: 0.1972 - accuracy: 0.1001 - val_loss: 0.1972 - val_accuracy: 0.1000\n",
      "Epoch 10/120\n",
      " - 28s - loss: 0.1920 - accuracy: 0.0999 - val_loss: 0.1909 - val_accuracy: 0.1000\n",
      "Epoch 11/120\n",
      " - 27s - loss: 0.1573 - accuracy: 0.1266 - val_loss: 0.0887 - val_accuracy: 0.2714\n",
      "Epoch 12/120\n",
      " - 29s - loss: 0.0873 - accuracy: 0.2520 - val_loss: 0.0846 - val_accuracy: 0.2919\n",
      "Epoch 13/120\n",
      " - 29s - loss: 0.0889 - accuracy: 0.2692 - val_loss: 0.0809 - val_accuracy: 0.3214\n",
      "Epoch 14/120\n",
      " - 28s - loss: 0.0826 - accuracy: 0.3051 - val_loss: 0.0832 - val_accuracy: 0.3080\n",
      "Epoch 15/120\n",
      " - 28s - loss: 0.0822 - accuracy: 0.3236 - val_loss: 0.0866 - val_accuracy: 0.3549\n",
      "Epoch 16/120\n",
      " - 29s - loss: 0.0816 - accuracy: 0.3416 - val_loss: 0.0776 - val_accuracy: 0.3950\n",
      "Epoch 17/120\n",
      " - 28s - loss: 0.0831 - accuracy: 0.3480 - val_loss: 0.0774 - val_accuracy: 0.4041\n",
      "Epoch 18/120\n",
      " - 28s - loss: 0.0793 - accuracy: 0.3751 - val_loss: 0.0748 - val_accuracy: 0.4119\n",
      "Epoch 19/120\n",
      " - 28s - loss: 0.0801 - accuracy: 0.3698 - val_loss: 0.0762 - val_accuracy: 0.4089\n",
      "Epoch 20/120\n",
      " - 27s - loss: 0.0792 - accuracy: 0.3796 - val_loss: 0.0790 - val_accuracy: 0.3554\n",
      "Epoch 21/120\n",
      " - 29s - loss: 0.0781 - accuracy: 0.3898 - val_loss: 0.0755 - val_accuracy: 0.4032\n",
      "Epoch 22/120\n",
      " - 31s - loss: 0.0781 - accuracy: 0.3956 - val_loss: 0.0764 - val_accuracy: 0.3936\n",
      "Epoch 23/120\n",
      " - 30s - loss: 0.0777 - accuracy: 0.4005 - val_loss: 0.0742 - val_accuracy: 0.4324\n",
      "Epoch 24/120\n",
      " - 28s - loss: 0.0772 - accuracy: 0.4089 - val_loss: 0.0768 - val_accuracy: 0.4202\n",
      "Epoch 25/120\n",
      " - 27s - loss: 0.0773 - accuracy: 0.4084 - val_loss: 0.0771 - val_accuracy: 0.3980\n",
      "Epoch 26/120\n",
      " - 28s - loss: 0.0768 - accuracy: 0.4114 - val_loss: 0.0810 - val_accuracy: 0.3506\n",
      "Epoch 27/120\n",
      " - 27s - loss: 0.0768 - accuracy: 0.4118 - val_loss: 0.0751 - val_accuracy: 0.4341\n",
      "Epoch 28/120\n",
      " - 28s - loss: 0.0769 - accuracy: 0.4131 - val_loss: 0.0743 - val_accuracy: 0.4298\n",
      "Epoch 29/120\n",
      " - 27s - loss: 0.0764 - accuracy: 0.4179 - val_loss: 0.0759 - val_accuracy: 0.4106\n",
      "Epoch 30/120\n",
      " - 28s - loss: 0.0758 - accuracy: 0.4231 - val_loss: 0.0782 - val_accuracy: 0.4010\n",
      "Epoch 31/120\n",
      " - 28s - loss: 0.0762 - accuracy: 0.4205 - val_loss: 0.0729 - val_accuracy: 0.4485\n",
      "Epoch 32/120\n",
      " - 26s - loss: 0.0758 - accuracy: 0.4228 - val_loss: 0.0763 - val_accuracy: 0.4176\n",
      "Epoch 33/120\n",
      " - 28s - loss: 0.0764 - accuracy: 0.4256 - val_loss: 0.0748 - val_accuracy: 0.4354\n",
      "Epoch 34/120\n",
      " - 29s - loss: 0.0752 - accuracy: 0.4290 - val_loss: 0.0740 - val_accuracy: 0.4363\n",
      "Epoch 35/120\n",
      " - 28s - loss: 0.0754 - accuracy: 0.4285 - val_loss: 0.0743 - val_accuracy: 0.4311\n",
      "Epoch 36/120\n",
      " - 27s - loss: 0.0750 - accuracy: 0.4346 - val_loss: 0.0741 - val_accuracy: 0.4332\n",
      "Epoch 37/120\n",
      " - 28s - loss: 0.0752 - accuracy: 0.4297 - val_loss: 0.0768 - val_accuracy: 0.4280\n",
      "Epoch 38/120\n",
      " - 27s - loss: 0.0747 - accuracy: 0.4335 - val_loss: 0.0740 - val_accuracy: 0.4441\n",
      "Epoch 39/120\n",
      " - 27s - loss: 0.0744 - accuracy: 0.4380 - val_loss: 0.0738 - val_accuracy: 0.4476\n",
      "Epoch 40/120\n",
      " - 28s - loss: 0.0748 - accuracy: 0.4345 - val_loss: 0.0750 - val_accuracy: 0.4324\n",
      "Epoch 41/120\n",
      " - 27s - loss: 0.0744 - accuracy: 0.4373 - val_loss: 0.0739 - val_accuracy: 0.4354\n",
      "Epoch 42/120\n",
      " - 27s - loss: 0.0743 - accuracy: 0.4420 - val_loss: 0.0738 - val_accuracy: 0.4480\n",
      "Epoch 43/120\n",
      " - 28s - loss: 0.0743 - accuracy: 0.4393 - val_loss: 0.0740 - val_accuracy: 0.4319\n",
      "Epoch 44/120\n",
      " - 28s - loss: 0.0741 - accuracy: 0.4416 - val_loss: 0.0773 - val_accuracy: 0.4350\n",
      "Epoch 45/120\n",
      " - 27s - loss: 0.0739 - accuracy: 0.4444 - val_loss: 0.0735 - val_accuracy: 0.4506\n",
      "Epoch 46/120\n",
      " - 28s - loss: 0.0740 - accuracy: 0.4471 - val_loss: 0.0748 - val_accuracy: 0.4137\n",
      "Epoch 47/120\n",
      " - 28s - loss: 0.0746 - accuracy: 0.4385 - val_loss: 0.0723 - val_accuracy: 0.4502\n",
      "Epoch 48/120\n",
      " - 27s - loss: 0.0737 - accuracy: 0.4450 - val_loss: 0.0739 - val_accuracy: 0.4306\n",
      "Epoch 49/120\n",
      " - 27s - loss: 0.0738 - accuracy: 0.4447 - val_loss: 0.0732 - val_accuracy: 0.4576\n",
      "Epoch 50/120\n",
      " - 27s - loss: 0.0736 - accuracy: 0.4491 - val_loss: 0.0728 - val_accuracy: 0.4498\n",
      "Epoch 51/120\n",
      " - 27s - loss: 0.0735 - accuracy: 0.4528 - val_loss: 0.0734 - val_accuracy: 0.4480\n",
      "Epoch 52/120\n",
      " - 27s - loss: 0.0736 - accuracy: 0.4478 - val_loss: 0.0750 - val_accuracy: 0.4472\n",
      "Epoch 53/120\n",
      " - 28s - loss: 0.0736 - accuracy: 0.4466 - val_loss: 0.0753 - val_accuracy: 0.4367\n",
      "Epoch 54/120\n",
      " - 28s - loss: 0.0740 - accuracy: 0.4476 - val_loss: 0.0722 - val_accuracy: 0.4554\n",
      "Epoch 55/120\n",
      " - 27s - loss: 0.0734 - accuracy: 0.4519 - val_loss: 0.0728 - val_accuracy: 0.4419\n",
      "Epoch 56/120\n",
      " - 27s - loss: 0.0733 - accuracy: 0.4559 - val_loss: 0.0715 - val_accuracy: 0.4615\n",
      "Epoch 57/120\n",
      " - 28s - loss: 0.0734 - accuracy: 0.4520 - val_loss: 0.0732 - val_accuracy: 0.4550\n",
      "Epoch 58/120\n",
      " - 28s - loss: 0.0734 - accuracy: 0.4512 - val_loss: 0.0717 - val_accuracy: 0.4689\n",
      "Epoch 59/120\n",
      " - 27s - loss: 0.0731 - accuracy: 0.4528 - val_loss: 0.0722 - val_accuracy: 0.4645\n",
      "Epoch 60/120\n",
      " - 28s - loss: 0.0731 - accuracy: 0.4557 - val_loss: 0.0748 - val_accuracy: 0.4393\n",
      "Epoch 61/120\n",
      " - 28s - loss: 0.0730 - accuracy: 0.4527 - val_loss: 0.0736 - val_accuracy: 0.4406\n",
      "Epoch 62/120\n",
      " - 28s - loss: 0.0730 - accuracy: 0.4567 - val_loss: 0.0727 - val_accuracy: 0.4611\n",
      "Epoch 63/120\n",
      " - 27s - loss: 0.0728 - accuracy: 0.4559 - val_loss: 0.0716 - val_accuracy: 0.4532\n",
      "Epoch 64/120\n",
      " - 28s - loss: 0.0740 - accuracy: 0.4504 - val_loss: 0.0713 - val_accuracy: 0.4711\n",
      "Epoch 65/120\n",
      " - 28s - loss: 0.0727 - accuracy: 0.4606 - val_loss: 0.0723 - val_accuracy: 0.4615\n",
      "Epoch 66/120\n",
      " - 28s - loss: 0.0727 - accuracy: 0.4635 - val_loss: 0.0721 - val_accuracy: 0.4628\n",
      "Epoch 67/120\n",
      " - 27s - loss: 0.0728 - accuracy: 0.4607 - val_loss: 0.0710 - val_accuracy: 0.4650\n",
      "Epoch 68/120\n",
      " - 28s - loss: 0.0725 - accuracy: 0.4628 - val_loss: 0.0716 - val_accuracy: 0.4650\n",
      "Epoch 69/120\n",
      " - 27s - loss: 0.0730 - accuracy: 0.4601 - val_loss: 0.0730 - val_accuracy: 0.4515\n",
      "Epoch 70/120\n",
      " - 27s - loss: 0.0723 - accuracy: 0.4639 - val_loss: 0.0733 - val_accuracy: 0.4437\n",
      "Epoch 71/120\n",
      " - 28s - loss: 0.0725 - accuracy: 0.4615 - val_loss: 0.0732 - val_accuracy: 0.4506\n",
      "Epoch 72/120\n",
      " - 28s - loss: 0.0723 - accuracy: 0.4588 - val_loss: 0.0709 - val_accuracy: 0.4650\n",
      "Epoch 73/120\n",
      " - 26s - loss: 0.0723 - accuracy: 0.4616 - val_loss: 0.0721 - val_accuracy: 0.4611\n",
      "Epoch 74/120\n",
      " - 28s - loss: 0.0724 - accuracy: 0.4642 - val_loss: 0.0719 - val_accuracy: 0.4580\n",
      "Epoch 75/120\n",
      " - 27s - loss: 0.0726 - accuracy: 0.4648 - val_loss: 0.0728 - val_accuracy: 0.4598\n",
      "Epoch 76/120\n",
      " - 28s - loss: 0.0724 - accuracy: 0.4681 - val_loss: 0.0728 - val_accuracy: 0.4724\n",
      "Epoch 77/120\n",
      " - 27s - loss: 0.0722 - accuracy: 0.4669 - val_loss: 0.0780 - val_accuracy: 0.4171\n",
      "Epoch 78/120\n",
      " - 28s - loss: 0.0723 - accuracy: 0.4642 - val_loss: 0.0718 - val_accuracy: 0.4702\n",
      "Epoch 79/120\n",
      " - 28s - loss: 0.0719 - accuracy: 0.4717 - val_loss: 0.0750 - val_accuracy: 0.4411\n",
      "Epoch 80/120\n",
      " - 28s - loss: 0.0722 - accuracy: 0.4671 - val_loss: 0.0751 - val_accuracy: 0.4406\n",
      "Epoch 81/120\n",
      " - 26s - loss: 0.0720 - accuracy: 0.4702 - val_loss: 0.0714 - val_accuracy: 0.4602\n",
      "Epoch 82/120\n",
      " - 28s - loss: 0.0718 - accuracy: 0.4691 - val_loss: 0.0715 - val_accuracy: 0.4628\n",
      "Epoch 83/120\n",
      " - 26s - loss: 0.0719 - accuracy: 0.4733 - val_loss: 0.0742 - val_accuracy: 0.4502\n",
      "Epoch 84/120\n",
      " - 28s - loss: 0.0718 - accuracy: 0.4754 - val_loss: 0.0728 - val_accuracy: 0.4619\n",
      "Epoch 85/120\n",
      " - 28s - loss: 0.0720 - accuracy: 0.4684 - val_loss: 0.0728 - val_accuracy: 0.4698\n",
      "Epoch 86/120\n",
      " - 27s - loss: 0.0719 - accuracy: 0.4698 - val_loss: 0.0733 - val_accuracy: 0.4402\n",
      "Epoch 87/120\n",
      " - 27s - loss: 0.0720 - accuracy: 0.4709 - val_loss: 0.0724 - val_accuracy: 0.4554\n",
      "Epoch 88/120\n",
      " - 28s - loss: 0.0716 - accuracy: 0.4741 - val_loss: 0.0714 - val_accuracy: 0.4702\n",
      "Epoch 89/120\n",
      " - 27s - loss: 0.0719 - accuracy: 0.4725 - val_loss: 0.0751 - val_accuracy: 0.4363\n",
      "Epoch 90/120\n",
      " - 27s - loss: 0.0717 - accuracy: 0.4756 - val_loss: 0.0718 - val_accuracy: 0.4698\n",
      "Epoch 91/120\n",
      " - 28s - loss: 0.0718 - accuracy: 0.4700 - val_loss: 0.0741 - val_accuracy: 0.4506\n",
      "Epoch 92/120\n",
      " - 27s - loss: 0.0718 - accuracy: 0.4747 - val_loss: 0.0726 - val_accuracy: 0.4532\n",
      "Epoch 93/120\n",
      " - 27s - loss: 0.0715 - accuracy: 0.4734 - val_loss: 0.0743 - val_accuracy: 0.4576\n",
      "Epoch 94/120\n",
      " - 27s - loss: 0.0716 - accuracy: 0.4699 - val_loss: 0.0740 - val_accuracy: 0.4463\n",
      "Epoch 95/120\n",
      " - 27s - loss: 0.0713 - accuracy: 0.4697 - val_loss: 0.0727 - val_accuracy: 0.4580\n",
      "Epoch 96/120\n",
      " - 28s - loss: 0.0715 - accuracy: 0.4766 - val_loss: 0.0737 - val_accuracy: 0.4550\n",
      "Epoch 97/120\n",
      " - 28s - loss: 0.0712 - accuracy: 0.4771 - val_loss: 0.0743 - val_accuracy: 0.4445\n",
      "Epoch 98/120\n",
      " - 29s - loss: 0.0715 - accuracy: 0.4750 - val_loss: 0.0742 - val_accuracy: 0.4306\n",
      "Epoch 99/120\n",
      " - 29s - loss: 0.0715 - accuracy: 0.4769 - val_loss: 0.0717 - val_accuracy: 0.4672\n",
      "Epoch 100/120\n",
      " - 30s - loss: 0.0710 - accuracy: 0.4800 - val_loss: 0.0726 - val_accuracy: 0.4685\n",
      "Epoch 101/120\n",
      " - 31s - loss: 0.0714 - accuracy: 0.4753 - val_loss: 0.0722 - val_accuracy: 0.4593\n",
      "Epoch 102/120\n",
      " - 30s - loss: 0.0714 - accuracy: 0.4768 - val_loss: 0.0728 - val_accuracy: 0.4585\n",
      "Epoch 103/120\n",
      " - 30s - loss: 0.0713 - accuracy: 0.4793 - val_loss: 0.0728 - val_accuracy: 0.4545\n",
      "Epoch 104/120\n",
      " - 30s - loss: 0.0712 - accuracy: 0.4798 - val_loss: 0.0721 - val_accuracy: 0.4624\n",
      "Epoch 105/120\n",
      " - 30s - loss: 0.0714 - accuracy: 0.4786 - val_loss: 0.0724 - val_accuracy: 0.4598\n",
      "Epoch 106/120\n",
      " - 30s - loss: 0.0721 - accuracy: 0.4732 - val_loss: 0.0729 - val_accuracy: 0.4550\n",
      "Epoch 107/120\n",
      " - 30s - loss: 0.0709 - accuracy: 0.4802 - val_loss: 0.0724 - val_accuracy: 0.4663\n",
      "Epoch 108/120\n",
      " - 30s - loss: 0.0709 - accuracy: 0.4814 - val_loss: 0.0737 - val_accuracy: 0.4485\n",
      "Epoch 109/120\n",
      " - 30s - loss: 0.0710 - accuracy: 0.4846 - val_loss: 0.0728 - val_accuracy: 0.4489\n",
      "Epoch 110/120\n",
      " - 30s - loss: 0.0711 - accuracy: 0.4802 - val_loss: 0.0740 - val_accuracy: 0.4454\n",
      "Epoch 111/120\n",
      " - 31s - loss: 0.0712 - accuracy: 0.4818 - val_loss: 0.0733 - val_accuracy: 0.4593\n",
      "Epoch 112/120\n",
      " - 30s - loss: 0.0706 - accuracy: 0.4869 - val_loss: 0.0765 - val_accuracy: 0.4215\n",
      "Epoch 113/120\n",
      " - 31s - loss: 0.0710 - accuracy: 0.4841 - val_loss: 0.0727 - val_accuracy: 0.4732\n",
      "Epoch 114/120\n",
      " - 29s - loss: 0.0709 - accuracy: 0.4856 - val_loss: 0.0727 - val_accuracy: 0.4667\n",
      "Epoch 115/120\n",
      " - 30s - loss: 0.0709 - accuracy: 0.4838 - val_loss: 0.0734 - val_accuracy: 0.4524\n",
      "Epoch 116/120\n",
      " - 30s - loss: 0.0710 - accuracy: 0.4860 - val_loss: 0.0732 - val_accuracy: 0.4585\n",
      "Epoch 117/120\n",
      " - 30s - loss: 0.0708 - accuracy: 0.4869 - val_loss: 0.0782 - val_accuracy: 0.4041\n",
      "Epoch 118/120\n",
      " - 30s - loss: 0.0707 - accuracy: 0.4840 - val_loss: 0.0722 - val_accuracy: 0.4741\n",
      "Epoch 119/120\n",
      " - 30s - loss: 0.0706 - accuracy: 0.4815 - val_loss: 0.0755 - val_accuracy: 0.4271\n",
      "Epoch 120/120\n",
      " - 30s - loss: 0.0709 - accuracy: 0.4815 - val_loss: 0.0736 - val_accuracy: 0.4498\n",
      "Train on 20691 samples, validate on 2299 samples\n",
      "Epoch 1/120\n",
      " - 27s - loss: 0.3692 - accuracy: 0.0998 - val_loss: 0.2075 - val_accuracy: 0.1000\n",
      "Epoch 2/120\n",
      " - 25s - loss: 0.1951 - accuracy: 0.1012 - val_loss: 0.1844 - val_accuracy: 0.1000\n",
      "Epoch 3/120\n",
      " - 26s - loss: 0.1937 - accuracy: 0.1025 - val_loss: 0.1939 - val_accuracy: 0.1000\n",
      "Epoch 4/120\n",
      " - 25s - loss: 0.1911 - accuracy: 0.0992 - val_loss: 0.1918 - val_accuracy: 0.1000\n",
      "Epoch 5/120\n",
      " - 25s - loss: 0.1913 - accuracy: 0.1011 - val_loss: 0.1899 - val_accuracy: 0.1000\n",
      "Epoch 6/120\n",
      " - 25s - loss: 0.1925 - accuracy: 0.1017 - val_loss: 0.1980 - val_accuracy: 0.1000\n",
      "Epoch 7/120\n",
      " - 26s - loss: 0.1937 - accuracy: 0.0991 - val_loss: 0.1868 - val_accuracy: 0.1000\n",
      "Epoch 8/120\n",
      " - 25s - loss: 0.1912 - accuracy: 0.0992 - val_loss: 0.1513 - val_accuracy: 0.0953\n",
      "Epoch 9/120\n",
      " - 25s - loss: 0.1292 - accuracy: 0.1728 - val_loss: 0.0829 - val_accuracy: 0.2736\n",
      "Epoch 10/120\n",
      " - 25s - loss: 0.0864 - accuracy: 0.2618 - val_loss: 0.0808 - val_accuracy: 0.3149\n",
      "Epoch 11/120\n",
      " - 25s - loss: 0.0857 - accuracy: 0.2905 - val_loss: 0.0791 - val_accuracy: 0.3462\n",
      "Epoch 12/120\n",
      " - 25s - loss: 0.0825 - accuracy: 0.3211 - val_loss: 0.0797 - val_accuracy: 0.3575\n",
      "Epoch 13/120\n",
      " - 25s - loss: 0.0825 - accuracy: 0.3398 - val_loss: 0.0799 - val_accuracy: 0.3602\n",
      "Epoch 14/120\n",
      " - 26s - loss: 0.0799 - accuracy: 0.3594 - val_loss: 0.0756 - val_accuracy: 0.4032\n",
      "Epoch 15/120\n",
      " - 26s - loss: 0.0795 - accuracy: 0.3661 - val_loss: 0.0762 - val_accuracy: 0.4110\n",
      "Epoch 16/120\n",
      " - 26s - loss: 0.0782 - accuracy: 0.3814 - val_loss: 0.0783 - val_accuracy: 0.3684\n",
      "Epoch 17/120\n",
      " - 25s - loss: 0.0782 - accuracy: 0.3843 - val_loss: 0.0748 - val_accuracy: 0.4150\n",
      "Epoch 18/120\n",
      " - 25s - loss: 0.0774 - accuracy: 0.3923 - val_loss: 0.0784 - val_accuracy: 0.3615\n",
      "Epoch 19/120\n",
      " - 25s - loss: 0.0776 - accuracy: 0.3996 - val_loss: 0.0751 - val_accuracy: 0.4254\n",
      "Epoch 20/120\n",
      " - 25s - loss: 0.0769 - accuracy: 0.3976 - val_loss: 0.0750 - val_accuracy: 0.4193\n",
      "Epoch 21/120\n",
      " - 26s - loss: 0.0766 - accuracy: 0.4091 - val_loss: 0.0737 - val_accuracy: 0.4367\n",
      "Epoch 22/120\n",
      " - 25s - loss: 0.0777 - accuracy: 0.4027 - val_loss: 0.0752 - val_accuracy: 0.4276\n",
      "Epoch 23/120\n",
      " - 26s - loss: 0.0757 - accuracy: 0.4185 - val_loss: 0.0736 - val_accuracy: 0.4437\n",
      "Epoch 24/120\n",
      " - 25s - loss: 0.0756 - accuracy: 0.4135 - val_loss: 0.0738 - val_accuracy: 0.4254\n",
      "Epoch 25/120\n",
      " - 26s - loss: 0.0770 - accuracy: 0.4074 - val_loss: 0.0765 - val_accuracy: 0.4228\n",
      "Epoch 26/120\n",
      " - 26s - loss: 0.0762 - accuracy: 0.4222 - val_loss: 0.0726 - val_accuracy: 0.4428\n",
      "Epoch 27/120\n",
      " - 26s - loss: 0.0750 - accuracy: 0.4237 - val_loss: 0.0748 - val_accuracy: 0.4028\n",
      "Epoch 28/120\n",
      " - 25s - loss: 0.0753 - accuracy: 0.4228 - val_loss: 0.0720 - val_accuracy: 0.4580\n",
      "Epoch 29/120\n",
      " - 23s - loss: 0.0746 - accuracy: 0.4295 - val_loss: 0.0759 - val_accuracy: 0.4093\n",
      "Epoch 30/120\n",
      " - 23s - loss: 0.0749 - accuracy: 0.4314 - val_loss: 0.0737 - val_accuracy: 0.4245\n",
      "Epoch 31/120\n",
      " - 24s - loss: 0.0747 - accuracy: 0.4274 - val_loss: 0.0799 - val_accuracy: 0.3836\n",
      "Epoch 32/120\n",
      " - 24s - loss: 0.0745 - accuracy: 0.4305 - val_loss: 0.0749 - val_accuracy: 0.4315\n",
      "Epoch 33/120\n",
      " - 24s - loss: 0.0750 - accuracy: 0.4304 - val_loss: 0.0733 - val_accuracy: 0.4263\n",
      "Epoch 34/120\n",
      " - 23s - loss: 0.0742 - accuracy: 0.4347 - val_loss: 0.0730 - val_accuracy: 0.4371\n",
      "Epoch 35/120\n",
      " - 24s - loss: 0.0738 - accuracy: 0.4406 - val_loss: 0.0739 - val_accuracy: 0.4424\n",
      "Epoch 36/120\n",
      " - 23s - loss: 0.0744 - accuracy: 0.4315 - val_loss: 0.0714 - val_accuracy: 0.4528\n",
      "Epoch 37/120\n",
      " - 23s - loss: 0.0742 - accuracy: 0.4357 - val_loss: 0.0726 - val_accuracy: 0.4524\n",
      "Epoch 38/120\n",
      " - 23s - loss: 0.0745 - accuracy: 0.4362 - val_loss: 0.0725 - val_accuracy: 0.4545\n",
      "Epoch 39/120\n",
      " - 24s - loss: 0.0767 - accuracy: 0.4283 - val_loss: 0.0721 - val_accuracy: 0.4598\n",
      "Epoch 40/120\n",
      " - 23s - loss: 0.0742 - accuracy: 0.4407 - val_loss: 0.1024 - val_accuracy: 0.1966\n",
      "Epoch 41/120\n",
      " - 24s - loss: 0.0750 - accuracy: 0.4338 - val_loss: 0.0714 - val_accuracy: 0.4645\n",
      "Epoch 42/120\n",
      " - 23s - loss: 0.0737 - accuracy: 0.4450 - val_loss: 0.0725 - val_accuracy: 0.4419\n",
      "Epoch 43/120\n",
      " - 23s - loss: 0.0737 - accuracy: 0.4409 - val_loss: 0.0723 - val_accuracy: 0.4567\n",
      "Epoch 44/120\n",
      " - 22s - loss: 0.0739 - accuracy: 0.4386 - val_loss: 0.0738 - val_accuracy: 0.4367\n",
      "Epoch 45/120\n",
      " - 24s - loss: 0.0735 - accuracy: 0.4473 - val_loss: 0.0727 - val_accuracy: 0.4598\n",
      "Epoch 46/120\n",
      " - 24s - loss: 0.0733 - accuracy: 0.4499 - val_loss: 0.0735 - val_accuracy: 0.4419\n",
      "Epoch 47/120\n",
      " - 24s - loss: 0.0732 - accuracy: 0.4489 - val_loss: 0.0709 - val_accuracy: 0.4611\n",
      "Epoch 48/120\n",
      " - 24s - loss: 0.0731 - accuracy: 0.4495 - val_loss: 0.0725 - val_accuracy: 0.4563\n",
      "Epoch 49/120\n",
      " - 24s - loss: 0.0735 - accuracy: 0.4487 - val_loss: 0.0710 - val_accuracy: 0.4693\n",
      "Epoch 50/120\n",
      " - 23s - loss: 0.0729 - accuracy: 0.4531 - val_loss: 0.0777 - val_accuracy: 0.4128\n",
      "Epoch 51/120\n",
      " - 23s - loss: 0.0738 - accuracy: 0.4440 - val_loss: 0.0710 - val_accuracy: 0.4698\n",
      "Epoch 52/120\n",
      " - 24s - loss: 0.0730 - accuracy: 0.4526 - val_loss: 0.0706 - val_accuracy: 0.4706\n",
      "Epoch 53/120\n",
      " - 23s - loss: 0.0732 - accuracy: 0.4540 - val_loss: 0.0745 - val_accuracy: 0.4463\n",
      "Epoch 54/120\n",
      " - 23s - loss: 0.0730 - accuracy: 0.4525 - val_loss: 0.0707 - val_accuracy: 0.4741\n",
      "Epoch 55/120\n",
      " - 23s - loss: 0.0732 - accuracy: 0.4527 - val_loss: 0.0724 - val_accuracy: 0.4559\n",
      "Epoch 56/120\n",
      " - 23s - loss: 0.0726 - accuracy: 0.4533 - val_loss: 0.0716 - val_accuracy: 0.4580\n",
      "Epoch 57/120\n",
      " - 24s - loss: 0.0726 - accuracy: 0.4575 - val_loss: 0.0741 - val_accuracy: 0.4271\n",
      "Epoch 58/120\n",
      " - 24s - loss: 0.0748 - accuracy: 0.4474 - val_loss: 0.0729 - val_accuracy: 0.4511\n",
      "Epoch 59/120\n",
      " - 23s - loss: 0.0725 - accuracy: 0.4608 - val_loss: 0.0712 - val_accuracy: 0.4672\n",
      "Epoch 60/120\n",
      " - 23s - loss: 0.0726 - accuracy: 0.4526 - val_loss: 0.0774 - val_accuracy: 0.3997\n",
      "Epoch 61/120\n",
      " - 23s - loss: 0.0725 - accuracy: 0.4585 - val_loss: 0.0716 - val_accuracy: 0.4685\n",
      "Epoch 62/120\n",
      " - 24s - loss: 0.0725 - accuracy: 0.4626 - val_loss: 0.0716 - val_accuracy: 0.4411\n",
      "Epoch 63/120\n",
      " - 24s - loss: 0.0719 - accuracy: 0.4661 - val_loss: 0.0714 - val_accuracy: 0.4654\n",
      "Epoch 64/120\n",
      " - 23s - loss: 0.0718 - accuracy: 0.4684 - val_loss: 0.0712 - val_accuracy: 0.4685\n",
      "Epoch 65/120\n",
      " - 23s - loss: 0.0746 - accuracy: 0.4508 - val_loss: 0.0719 - val_accuracy: 0.4441\n",
      "Epoch 66/120\n",
      " - 23s - loss: 0.0719 - accuracy: 0.4647 - val_loss: 0.0730 - val_accuracy: 0.4271\n",
      "Epoch 67/120\n",
      " - 24s - loss: 0.0722 - accuracy: 0.4624 - val_loss: 0.0701 - val_accuracy: 0.4693\n",
      "Epoch 68/120\n",
      " - 24s - loss: 0.0724 - accuracy: 0.4624 - val_loss: 0.0767 - val_accuracy: 0.4110\n",
      "Epoch 69/120\n",
      " - 23s - loss: 0.0731 - accuracy: 0.4546 - val_loss: 0.0718 - val_accuracy: 0.4567\n",
      "Epoch 70/120\n",
      " - 23s - loss: 0.0725 - accuracy: 0.4640 - val_loss: 0.0727 - val_accuracy: 0.4580\n",
      "Epoch 71/120\n",
      " - 24s - loss: 0.0718 - accuracy: 0.4707 - val_loss: 0.0753 - val_accuracy: 0.4271\n",
      "Epoch 72/120\n",
      " - 23s - loss: 0.0722 - accuracy: 0.4667 - val_loss: 0.0706 - val_accuracy: 0.4837\n",
      "Epoch 73/120\n",
      " - 24s - loss: 0.0719 - accuracy: 0.4705 - val_loss: 0.0708 - val_accuracy: 0.4602\n",
      "Epoch 74/120\n",
      " - 24s - loss: 0.0717 - accuracy: 0.4709 - val_loss: 0.0733 - val_accuracy: 0.4598\n",
      "Epoch 75/120\n",
      " - 24s - loss: 0.0719 - accuracy: 0.4684 - val_loss: 0.0708 - val_accuracy: 0.4637\n",
      "Epoch 76/120\n",
      " - 24s - loss: 0.0716 - accuracy: 0.4780 - val_loss: 0.0703 - val_accuracy: 0.4732\n",
      "Epoch 77/120\n",
      " - 23s - loss: 0.0715 - accuracy: 0.4721 - val_loss: 0.0718 - val_accuracy: 0.4641\n",
      "Epoch 78/120\n",
      " - 23s - loss: 0.0715 - accuracy: 0.4743 - val_loss: 0.0750 - val_accuracy: 0.4519\n",
      "Epoch 79/120\n",
      " - 23s - loss: 0.0718 - accuracy: 0.4694 - val_loss: 0.0697 - val_accuracy: 0.4746\n",
      "Epoch 80/120\n",
      " - 22s - loss: 0.0718 - accuracy: 0.4726 - val_loss: 0.0728 - val_accuracy: 0.4537\n",
      "Epoch 81/120\n",
      " - 23s - loss: 0.0720 - accuracy: 0.4705 - val_loss: 0.0708 - val_accuracy: 0.4624\n",
      "Epoch 82/120\n",
      " - 23s - loss: 0.0712 - accuracy: 0.4743 - val_loss: 0.0751 - val_accuracy: 0.4428\n",
      "Epoch 83/120\n",
      " - 24s - loss: 0.0713 - accuracy: 0.4768 - val_loss: 0.0694 - val_accuracy: 0.4850\n",
      "Epoch 84/120\n",
      " - 23s - loss: 0.0713 - accuracy: 0.4753 - val_loss: 0.0719 - val_accuracy: 0.4450\n",
      "Epoch 85/120\n",
      " - 24s - loss: 0.0712 - accuracy: 0.4805 - val_loss: 0.0716 - val_accuracy: 0.4676\n",
      "Epoch 86/120\n",
      " - 24s - loss: 0.0718 - accuracy: 0.4748 - val_loss: 0.0716 - val_accuracy: 0.4672\n",
      "Epoch 87/120\n",
      " - 23s - loss: 0.0709 - accuracy: 0.4804 - val_loss: 0.0701 - val_accuracy: 0.4785\n",
      "Epoch 88/120\n",
      " - 24s - loss: 0.0710 - accuracy: 0.4787 - val_loss: 0.0719 - val_accuracy: 0.4615\n",
      "Epoch 89/120\n",
      " - 23s - loss: 0.0711 - accuracy: 0.4796 - val_loss: 0.0730 - val_accuracy: 0.4572\n",
      "Epoch 90/120\n",
      " - 24s - loss: 0.0713 - accuracy: 0.4789 - val_loss: 0.0711 - val_accuracy: 0.4672\n",
      "Epoch 91/120\n",
      " - 25s - loss: 0.0710 - accuracy: 0.4780 - val_loss: 0.0723 - val_accuracy: 0.4667\n",
      "Epoch 92/120\n",
      " - 25s - loss: 0.0709 - accuracy: 0.4818 - val_loss: 0.0717 - val_accuracy: 0.4763\n",
      "Epoch 93/120\n",
      " - 24s - loss: 0.0705 - accuracy: 0.4877 - val_loss: 0.0739 - val_accuracy: 0.4472\n",
      "Epoch 94/120\n",
      " - 24s - loss: 0.0708 - accuracy: 0.4826 - val_loss: 0.0718 - val_accuracy: 0.4615\n",
      "Epoch 95/120\n",
      " - 23s - loss: 0.0705 - accuracy: 0.4877 - val_loss: 0.0733 - val_accuracy: 0.4454\n",
      "Epoch 96/120\n",
      " - 24s - loss: 0.0707 - accuracy: 0.4819 - val_loss: 0.0719 - val_accuracy: 0.4606\n",
      "Epoch 97/120\n",
      " - 24s - loss: 0.0710 - accuracy: 0.4840 - val_loss: 0.0702 - val_accuracy: 0.4715\n",
      "Epoch 98/120\n",
      " - 23s - loss: 0.0703 - accuracy: 0.4892 - val_loss: 0.0716 - val_accuracy: 0.4602\n",
      "Epoch 99/120\n",
      " - 24s - loss: 0.0704 - accuracy: 0.4869 - val_loss: 0.0727 - val_accuracy: 0.4576\n",
      "Epoch 100/120\n",
      " - 24s - loss: 0.0705 - accuracy: 0.4908 - val_loss: 0.0731 - val_accuracy: 0.4559\n",
      "Epoch 101/120\n",
      " - 24s - loss: 0.0703 - accuracy: 0.4902 - val_loss: 0.0730 - val_accuracy: 0.4615\n",
      "Epoch 102/120\n",
      " - 23s - loss: 0.0706 - accuracy: 0.4876 - val_loss: 0.0725 - val_accuracy: 0.4589\n",
      "Epoch 103/120\n",
      " - 23s - loss: 0.0702 - accuracy: 0.4891 - val_loss: 0.0718 - val_accuracy: 0.4724\n",
      "Epoch 104/120\n",
      " - 24s - loss: 0.0703 - accuracy: 0.4891 - val_loss: 0.0707 - val_accuracy: 0.4776\n",
      "Epoch 105/120\n",
      " - 24s - loss: 0.0703 - accuracy: 0.4890 - val_loss: 0.0752 - val_accuracy: 0.4450\n",
      "Epoch 106/120\n",
      " - 23s - loss: 0.0701 - accuracy: 0.4924 - val_loss: 0.0746 - val_accuracy: 0.4432\n",
      "Epoch 107/120\n",
      " - 23s - loss: 0.0703 - accuracy: 0.4892 - val_loss: 0.0722 - val_accuracy: 0.4615\n",
      "Epoch 108/120\n",
      " - 23s - loss: 0.0704 - accuracy: 0.4914 - val_loss: 0.0733 - val_accuracy: 0.4585\n",
      "Epoch 109/120\n",
      " - 24s - loss: 0.0699 - accuracy: 0.4934 - val_loss: 0.0724 - val_accuracy: 0.4619\n",
      "Epoch 110/120\n",
      " - 24s - loss: 0.0702 - accuracy: 0.4898 - val_loss: 0.0748 - val_accuracy: 0.4580\n",
      "Epoch 111/120\n",
      " - 24s - loss: 0.0705 - accuracy: 0.4905 - val_loss: 0.0702 - val_accuracy: 0.4802\n",
      "Epoch 112/120\n",
      " - 24s - loss: 0.0699 - accuracy: 0.4942 - val_loss: 0.0714 - val_accuracy: 0.4619\n",
      "Epoch 113/120\n",
      " - 24s - loss: 0.0704 - accuracy: 0.4889 - val_loss: 0.0724 - val_accuracy: 0.4580\n",
      "Epoch 114/120\n",
      " - 24s - loss: 0.0709 - accuracy: 0.4854 - val_loss: 0.0710 - val_accuracy: 0.4776\n",
      "Epoch 115/120\n",
      " - 25s - loss: 0.0699 - accuracy: 0.4920 - val_loss: 0.0720 - val_accuracy: 0.4615\n",
      "Epoch 116/120\n",
      " - 24s - loss: 0.0697 - accuracy: 0.4934 - val_loss: 0.0732 - val_accuracy: 0.4524\n",
      "Epoch 117/120\n",
      " - 24s - loss: 0.0697 - accuracy: 0.4980 - val_loss: 0.0727 - val_accuracy: 0.4689\n",
      "Epoch 118/120\n",
      " - 25s - loss: 0.0700 - accuracy: 0.4949 - val_loss: 0.0720 - val_accuracy: 0.4589\n",
      "Epoch 119/120\n",
      " - 25s - loss: 0.0697 - accuracy: 0.4970 - val_loss: 0.0726 - val_accuracy: 0.4545\n",
      "Epoch 120/120\n",
      " - 25s - loss: 0.0698 - accuracy: 0.4925 - val_loss: 0.0739 - val_accuracy: 0.4506\n",
      "accuracy: [0.50248903, 0.50978684, 0.5005558, 0.50780535, 0.50819194, 0.48335025, 0.47595572, 0.50746703, 0.48146537, 0.492533] \n",
      "val_accuracy:  [0.45063069462776184, 0.467159628868103, 0.4562853276729584, 0.43018704652786255, 0.46846455335617065, 0.4441061317920685, 0.4562853276729584, 0.44671595096588135, 0.449760764837265, 0.45063069462776184] \n",
      "mean_acc:  0.4969600349664688 \n",
      "mean_val_acc:  0.45202261209487915\n"
     ]
    }
   ],
   "source": [
    "# MODEL\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "accuracy = []\n",
    "val_accuracy = []\n",
    "\n",
    "seed=7\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "for train, test in kfold.split(train_data, y_train_num):\n",
    "    \n",
    "    y_train_matrix = to_categorical(y_train_num)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), input_shape=train_data.shape[1:], strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), strides=1,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))# the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64, input_dim=64,\n",
    "                    kernel_regularizer=regularizers.l2(0.01),\n",
    "                    activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # COMPILE\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    final_model=model.fit(train_data[train],\n",
    "              y_train_matrix[train],\n",
    "              validation_data=(train_data[test], y_train_matrix[test]),\n",
    "              epochs=120,\n",
    "              batch_size=500,\n",
    "              verbose=2)\n",
    "    \n",
    "    accuracy.append(final_model.history['accuracy'][-1])\n",
    "    val_accuracy.append(final_model.history['val_accuracy'][-1])\n",
    "print('accuracy:', accuracy, \"\\nval_accuracy: \", val_accuracy, \n",
    "      \"\\nmean_acc: \", sum(accuracy)/len(accuracy),\n",
    "      \"\\nmean_val_acc: \", sum(val_accuracy)/len(val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save last model results to file\n",
    "model.save(\"Model_Weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For BMDC, 1639 were properly classified\n",
      "For Brain, 580 were properly classified\n",
      "For CD4, 856 were properly classified\n",
      "For CD4memory, 1750 were properly classified\n",
      "For CD8, 794 were properly classified\n",
      "For Haematopoietic, 2001 were properly classified\n",
      "For intestinal, 349 were properly classified\n",
      "For Lung, 224 were properly classified\n",
      "For Mammery, 217 were properly classified\n",
      "For Olfactory, 19 were properly classified\n"
     ]
    }
   ],
   "source": [
    "# Loop through categories. Check overall accuracy. \n",
    "for x, c in enumerate(categories):\n",
    "    count = 0\n",
    "    IMAGES = r\"C:\\Users\\drake\\Google Drive\\ILS Spring 2020 Semester\\CMSC 636 Deep Learning\\Project - Code\\02 Create Histograms\\20_04_18 10 categories large\"\n",
    "    IMAGES += \"\\\\\" + c\n",
    "    onlyfiles = [f for f in os.listdir(IMAGES) if os.path.isfile(os.path.join(IMAGES, f))]\n",
    "    \n",
    "\n",
    "    for i, name in enumerate(onlyfiles):\n",
    "        img_array= cv2.imread(os.path.join(DATADIR, c, onlyfiles[i]), cv2.IMREAD_GRAYSCALE)\n",
    "        reshaped_array=cv2.resize(img_array, (img_size, img_size))\n",
    "        reshaped_array=np.array(reshaped_array).reshape(-1,img_size, img_size,1)\n",
    "        pred=model.predict(reshaped_array)\n",
    "        if np.argmax(pred) == x:\n",
    "            count += 1\n",
    "    print(f\"For {c}, {count} were properly classified\")       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['BMDC' 'Brain' 'CD4' 'CD4memory' 'CD8' 'Haematopoietic' 'Lung' 'Mammery'\n",
      " 'Olfactory' 'intestinal']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Individually check histograms\n",
    "selected_category = 'BMDC'\n",
    "img_array= cv2.imread(os.path.join(DATADIR, selected_category, onlyfiles[random.randint(0,2300)]), cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img_array, cmap=\"gray\")\n",
    "reshaped_array=cv2.resize(img_array, (img_size, img_size))\n",
    "reshaped_array=np.array(reshaped_array).reshape(-1,img_size, img_size,1)\n",
    "pred=model.predict(reshaped_array)\n",
    "print(np.argmax(pred))\n",
    "print(convert_to_numeric.inverse_transform([0,1,2,3,4,5,6,7,8,9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clears GPU memory \n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_old",
   "language": "python",
   "name": "tf_old"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
